---
title: DevOps
date: 2021-06-10 10:57:43
tags:
---

# 持续交付: 发布可靠软件的系统方法

## 引言

​	部署流水线以持续集成过程为其理论基石，从本质上讲，它是采纳持续集成原理后的自然结果。

​	部署流水线的目标有三个。首先，它让软件构建、部署、测试和发布过程对所有人可见，促进了合作。其次，它改善了反馈，以便在整个过程中，我们能够更早地发现并解决问题。最后，它使团队能够通过一个完全自动化的过程在任意环境上部署和发布软件的任意版本。

## 一些常见的发布反模式

### 反模式: 手工部署软件

​	这种反模式的特征如下。

* 有一份非常详尽的文档，该文档描述了执行步骤及每个步骤中易出错的地方。
* 以手工测试来确认该应用程序是否运行正确。
* 在发布当天开发团队频繁地接到电话，客户要求解释部署为何会出错。
* 在发布时，常常会修正一些在发布过程中发现的问题。
* 如果是集群环境部署，常常发现在集群中各环境的配置都不相同，比如应用服务器的连接池设置不同或文件系统有不同的目录结构等。
* 发布过程需要较长的时间（超过几分钟）。
* 布结果不可预测，常常不得不回滚或遇到不可预见的问题。
* 发布之后凌晨两点还睡眼惺忪地坐在显示器前，绞尽脑汁想着怎么让刚刚部署的应用程序能够正常工作。



​	相反，随着时间的推移，部署应该走向完全自动化，即对于那些负责将应用程序部署到开发环境、测试环境或生产环境的人来说，应该只需要做两件事：（1）挑选版本及需要部署的环境，（2）按一下“部署”按钮。对于套装软件的发布来说，还应该有一个创建安装程序的自动化过程。

* 如果部署过程没有完全自动化，每次部署时都会发生错误。唯一的问题就是“该问题严重与否”而已。即便使用良好的部署测试，有些错误也很难追查。
* 如果部署过程不是自动化的，那么它就既不可重复也不可靠，就会在调试部署错误的过程中浪费很多时间。
* 手动部署流程不得不被写在文档里。可是文档维护是一项复杂而费时的任务，它涉及多人之间的协作，因此文档通常要么是不完整的，要么就是未及时更新的，而把一套自动化部署脚本作为文档，它就永远是最新且完整的，否则就无法进行部署工作了。
* 自动部署本质上也是鼓励协作的，因为所有内容都在一个脚本里，一览无遗。要读懂文档通常需要读者具备一定的知识水平。然而在现实中，文档通常只是为执行部署者写的备忘录，是难以被他人理解的。
* 以上几点引起的一个必然结果：手工部署过程依赖于部署专家。如果专家去度假或离职了，那你就有麻烦了。
* 尽管手工部署枯燥且极具重复性，但仍需要有相当程度的专业知识。若要求专家做这些无聊、重复，但有技术要求的任务则必定会出现各种我们可以预料到的人为失误，同时失眠，酗酒这种问题也会接踵而至。然而自动化部署可以把那些成本高昂的资深高技术人员从过度工作中解放出来，让他们投身于更高价值的工作活动当中。
* 对手工部署过程进行测试的唯一方法就是原封不动地做一次（或者几次）。这往往费时，还会造成高昂的金钱成本，而测试自动化的部署过程却是既便宜又容易。
* 另外，还有一种说法：自动化过程不如手工过程的可审计性好。我们对这个观点感到很疑惑。对于一个手工过程来说，没人能确保其执行者会非常严格地遵循文档完成操作。只有自动化过程是完全可审核的。有什么会比一个可工作的部署脚本更容易被审核的呢？
* 每个人都应该使用自动化部署过程，而且它应该是软件部署的唯一方式。这个准则可以确保：在需要部署时，部署脚本就能完成工作。在本书中我们会提到多个原则，而其中之一就是“使用相同的脚本将软件部署到各种环境上”。如果使用相同的脚本将软件部署到各类环境中，那么在发布当天需要向生产环境进行部署时，这个脚本已经被验证过成百上千次了。如果发布时出现任何问题的话，你可以百分百地确定是该环境的具体配置问题，而不是这个脚本的问题。

### 反模式: 开发完成之后才向类生产环境部署

​	在这一模式下，当软件被第一次部署到类生产环境（比如试运行环境）时，就是大部分开发工作完成时，至少是开发团队认为“该软件开发完成了”。这种模式中，经常出现下面这些情况。

* 如果测试人员一直参与了在此之前的过程，那么他们已在开发机器上对软件进行了测试。
* 只有在向试运行环境部署时，运维人员才第一次接触到这个新应用程序。在某些组织中，通常是由独立的运维团队负责将应用程序部署到试运行环境和生产环境。在这种工作方式下，运维人员只有在产品被发布到生产环境时才第一次见到这个软件。
* 有可能由于类生产环境非常昂贵，所以权限控制严格，操作人员自己无权对该环境进行操作，也有可能环境没有按时准备好，甚至也可能根本没人去准备环境。
* 开发团队将正确的安装程序、配置文件、数据库迁移脚本和部署文档一同交给那些真正执行部署任务的人员，而所有这些都没有在类生产环境或试运行环境中进行过测试
* 开发团队和真正执行部署任务的人员之间的协作非常少。



​	以下这些事情会使与发布相关的问题恶化。

* 假如一个应用程序是全新开发的，那么第一次将它部署到试运行环境时，可能会非常棘手。
* 发布周期越长，开发团队在部署前作出错误假设的时间就越长，修复这些问题的时间也就越长。
* 交付过程被划分到开发、DBA、运维、测试等部门的那些大型组织中，各部门之间的协作成本可能会非常高，有时甚至会将发布过程拖上“地狱列车”。此时为了完成某个部署任务（更糟糕的情况是，为了解决部署过程中出现的问题），开发人员、测试人员和运维人员总是高举着问题单（不断地互发电子邮件）。
* 开发环境与生产环境差异性越大，开发过程中所做的那些假设与现实之间的差距就越大。虽然很难量化，但我敢说，如果在Windows系统上开发软件，而最终要部署在Solaris集群上，那么你会遇到很多意想不到的事情。
* 如果应用程序是由用户自行安装的（你可能没有太多权限来对用户的环境进行操作），或者其中的某些组件不在企业控制范围之内，此时可能需要很多额外的测试工作。



​	我们的对策就是将测试、部署和发布活动也纳入到开发过程中，让它们成为开发流程正常的一部分。这样的话，当准备好进行系统发布时就几乎很少或不会有风险了，因为你已经在很多种环境，甚至类生产环境中重复过很多次，也就相当于测试过很多次了。

### 反模式：生产环境的手工配置管理

* 多次部署到试运行环境都非常成功，但当部署到生产环境时就失败。
* 集群中各节点的行为有所不同。例如，与其他节点相比，某个节点所承担的负载少一些，或者处理请求的时间花得多一些。
* 运维团队需要较长时间为每次发布准备环境。
* 系统无法回滚到之前部署的某个配置，这些配置包括操作系统、应用服务器、关系型数据库管理系统、Web服务器或其他基础设施设置。
* 不知道从什么时候起，集群中的某些服务器所用的操作系统、第三方基础设施、依赖库的版本或补丁级别就不同了。
* 直接修改生产环境上的配置来改变系统配置。



​	本书描述的关键实践之一就是配置管理，其责任之一就是让你能够重复地创建那些你开发的应用程序所依赖的每个基础设施。这意味着操作系统、补丁级别、操作系统配置、应用程序所依赖的其他软件及其配置、基础设施的配置等都应该处于受控状态。你应该具有重建生产环境的能力，最好是能通过自动化的方式重建生产环境。虚拟化技术在这一点上可能对你有所帮助。

​	你应该完全掌握生产环境中的任何信息。这意味着生产环境中的每次变更都应该被记录下来，而且做到今后可以查阅。部署失败经常是因为某个人在上次部署时为生产环境打了补丁，但却没有将这个修改记录下来。实际上，不应该允许手工改变测试环境、试运行环境和生产环境，而只允许通过自动化过程来改变这些环境。

​	应用软件之间通常会有一些依赖关系。我们应该很容易知道当前发布的是软件的哪个版本。

​	发布可能是一件令人兴奋的事情，也可能变成一件累人而又沉闷的工作。几乎在每次发布的最后都会有一些变更，比如修改数据库的登录账户或者更新所用外部服务的URL。我们应该使用某种方法来引入此类变更，以便这些变更可以被记录并测试。这里我们再次强调一下，自动化是关键。变更首先应该被提交到版本控制系统中，然后通过某个自动化过程对生产环境进行更新。

## 如何实现目标

​	我们来调整一下目标，即找到可以以一种高效、快速、可靠的方式交付高质量且有价值的软件的方法。

* 自动化。如果构建、部署、测试和发布流程不是自动化的，那它就是不可重复的。由于软件本身、系统配置、环境以及发布过程的不同，每次做完这些活动以后，其结果可能都会有所不同。由于每个步骤都是手工操作，所以出错的机会很大，而且无法确切地知道具体都做了什么。这意味着整个发布过程无法得到应有的控制来确保高质量。常常说软件发布像是一种艺术，但事实上，它应该是一种工程学科。
* 频繁做。如果能够做到频繁发布，每个发布版本之间的差异会很小。这会大大减少与发布相关的风险，且更容易回滚。频繁发布也会加快反馈速度，而客户也需要它。本书很多内容都聚焦于如何尽快得到对软件及其相关配置所做变化的反馈，这包括其环境、部署过程及数据等。



​	对于频繁地自动化发布来说，反馈是至关重要的。下面关于反馈的三个标准是很有用的：

* 无论什么样的修改都应该触发反馈流程；
* 反馈应该尽快发出；
* 交付团队必须接收反馈，并依据它作出相应的行动。

### 每次修改都应该触发反馈流程

​	一个可工作的软件可分成以下几个部分：可执行的代码、配置信息、运行环境和数据。如果其中任何一部分发生了变化，都可能导致软件的行为发生变化。所以我们要能够控制这四部分，并确保任何修改都会被验证。

​	什么是反馈流程？它是指完全以自动化方式尽可能地测试每一次变更。根据系统的不同，测试会有所不同，但通常至少包括下面的检测。

* 建可执行代码的流程必须是能奏效的。这用于验证源代码是否符合语法。
* 软件的单元测试必须是成功的。这可以检查应用程序的行为是否与期望相同。
* 软件应该满足一定的质量标准，比如测试覆盖率以及其他与技术相关的度量项。
* 软件的功能验收测试必须是成功的。这可以检查应用是否满足业务验收条件，交付了所期望的业务价值。
* 软件的非功能测试必须是成功的。这可以检查应用程序是否满足用户对性能、有效性、安全性等方面的要求。
* 软件必须通过了探索性测试，并给客户以及部分用户做过演示。这些通常在一个手工测试环境上完成。此时，产品负责人可能认为软件功能还有缺失，我们自己也可能发现需要修复的缺陷，还要为其写自动化测试来避免回归测试。



### 必须尽快接收反馈

​	实现这样的部署流水线是需要大量资源的，尤其是当有了全面的自动化测试套件之后。部署流水线的关键目的之一就是对人力资源利用率的优化：我们希望将人力释放出来做更有价值的工作，将那些重复性的体力活交给机器来做。

​	对于整个流水线中的提交（commit）阶段，其测试应具有如下特征。

* 运行速度快。
* 尽可能全面，即75%左右的代码库覆盖率。只有这样，这些测试通过以后，我们才对自己写的软件比较有信心。
* 如果有测试失败的话，就表明应用程序有严重问题，无论如何都不能发布。也就是说，像检查界面元素的颜色是否正确这类测试不应该包含在这个测试集合当中。
* 尽可能做到环境中立。这个环境没必要和生产环境一模一样，可以相对简单廉价一些。

​	

相对而言，提交阶段之后的测试一般有如下这些特点。

* 它们通常运行更慢一些，所以适合于并行执行。
* 即使某些测试有可能失败，但在某种场合下，我们还是会发布应用程序。比如某个即将发布的版本有一个不稳定的修复，会导致其性能低于预先定义的标准，但有时我们还是会决定发布这个版本。
* 它们的运行环境应该尽可能与生产环境相同。除了测试功能以外，它同时还会对部署过程以及对生产环境的任何修改进行测试。



​	这种方法的基础之一就是快速的反馈。为了确保对变更的快速反馈，我们就要注意开发软件的流程，特别是如何使用版本控制系统和如何组织代码。开发人员应该频繁提交代码到版本控制系统中，像管理大规模团队或分布式团队那样，将代码分成多个组件。

### 交付团队必须接收反馈并作出反应

​	想要能够根据反馈来调整行动，就要对信息进行广播。使用一个大且可视的仪表盘（并非一定要电子的），或者其他通知机制对于确保反馈送达到每一个人是极为重要的。这个仪表盘应该随处可见，而且至少每个团队的屋中都应放置一个。当然，如果最后没有引发什么改进行动，反馈也就没有什么用了。因此，这就要求纪律性和计划性。当需要采取行动时，整个团队有责任停下他们手中的事情，来决定接下来采取哪些行动。在完成此事之后，团队才能继续自己的工作

### 这个流程可以推广吗

​	略

## 收效

### 授权团队

​	我们常常看到在不同的环境中运行着不同的版本，而不同角色的人工作在其上。能够轻松地将任意版本的软件部署到任意环境的能力能带来很多好处。

* 测试人员可以选择性地部署较旧的版本，以验证新版本上的功能变化。
* 技术支持人员可以自己部署某个已发布的版本，用于重现缺陷。
* 技术支持人员可以自己部署某个已发布的版本，用于重现缺陷。
* 发布方式也变成一键式的了。

### 减少错误

​	我们可能从方方面面将错误引入到软件中。最初委托制作这个软件的人就可能出错，比如提出错误的需求。需求分析人员可能将需求理解错了，开发人员也可能写出了到处都是缺陷的程序，而我们在这里要说的错误是指由不良好的配置管理引入到生产环境的错误。我们将在第2章详细阐述配置管理。现在，让我们想一下到底需要哪些东西才可以让一个应用程序正确地工作，当然肯定需要正确版本的代码，除此之外呢？我们还需要数据库模式（schema）的正确版本、负载均衡器的正确配置信息、应用程序所依赖的Web服务（比如用于查阅价格的Web服务）的正确URL等。当我们说配置管理时，指的是让你识别并控制一组完整信息的流程与机制，这些信息包括每个字节和比特。

### 缓解压力

​		现在，让我们来设想一下。如果接下来的发布只需要单击一下按钮，而且只需要等上几分钟，甚至几秒钟内就可以完成。另外，假如发生了非常糟糕的事情，你只要花上相同的几分钟或几秒钟的时间就可以把刚部署的内容恢复到从前的老样子。再大胆地设想一下，假如你的软件发布周期总是很短，那么当前生产环境中的版本与新版本之间的差异应该非常小。如果上述设想都是事实的话，那么发布的风险一定会大大降低，那种将职业生涯压注在发布是否成功的不爽感觉也将大大减少。

### 部署的灵活性	

​	只要需要，就可以让软件运行在任何环境中”的能力使我们和客户对我们随时管理所有版本发布过程充满信心。

### 多加练习，使其完美

​	只有一种环境可以有多变性，那就是开发环境。开发人员应该在自己的开发环境中自行生成二进制文件，而不需要在别处构建生成。所以，对这种开发环境的部署流程要求太严格是没有必要的。虽然我们能够做到在开发人员的开发机器上也以同样的方式部署软件，但实际上对开发环境的部署没有必要严格要求

## 候选发布版本

​	大多数软件发布方法都是在其流程的最后阶段才能识别出可以发布的那些版本。当说到与跟踪（tracking）相关的工作时，这是有些意义的。在写作本书时，Wikipedia上对开发阶段的描述中将“候选发布版本”作为这一流程中的一个步骤进行了说明，如图1-2所示。我们的观点则稍有不同。

![](https://pic.imgdb.cn/item/60c1a418844ef46bb289ead2.jpg)

​	根据我们的经验，直到开发阶段之后才做测试的话，无疑会降低应用程序的质量。最好还是在缺陷被引入时，就发现并将其解决。发现得越晚，修复的成本越高。开发人员已经不记得他们是在实现哪个功能时把缺陷引入的，而这个功能很可能已经发生了变化。直到最后才做测试，这通常意味着没有足够的时间真正地修复缺陷，或者只能修复其中很少的一部分缺陷。因此，我们想尽早地发现并修正这些缺陷，最好是在将其提交到代码库之前。

**每次提交代码都可能产生一个可发布的版本**

​	我们应该频繁做集成，事实上应该在每次提交修改后都做集成。持续集成这个实践将频繁集成发挥到了极至，而“持续集成”转变了软件开发过程。持续集成会及时检测到任何一次破坏已有系统或者不满足客户验收测试的提交。一旦发生这种情况，团队就立刻去修复问题（这是持续集成的首要规则）。如果能够坚持这个实践，那么软件会一直处于可用状态。假如测试足够全面，且运行测试的环境与生产环境足够相近（甚至相同）的话，那么可以说，你的软件一直处于可发布状态。

##  软件交付的原则

### 为软件的发布创建一个可重复且可靠的过程

​	可重复性和可靠性来自于以下两个原则：

（1）几乎将所有事情自动化；

（2）将构建、部署、测试和发布软件所需的东西全部纳入到版本控制管理之中。

归根结底，软件部署包括三件事：

* 提供并管理你的软件所需要的运行环境，这包括硬件配置、所依赖的软件、基础设施以及所需的外部服务；
* 将你的应用程序的正确版本安装在其之上；
*  配置你的应用程序，包括它所需要的任何数据以及状态。

### 将几乎所有事情自动化

​	看上去自动化发布流程是一个令人怯步的工作，而手工完成这些事情显得更容易一些。如果我们只需要做一次这样的工作，通过手工执行的确非常容易，但如果需要执行这个流程数十次的话，就不是那么容易的事了，而且很可能在第三次或第四次的时候就感觉不那么容易了。

### 把所有的东西都纳入版本控制

​	将构建、部署、测试和发布的整个过程中所需的东西全部保存在某种形式的版本存储库中，包括需求文档、测试脚本、自动化测试用例、网络配置脚本、部署脚本、数据库创建、升级、回滚和初始化脚本、应用程序所依赖的软件集合的配置脚本、库文件、工具链以及技术文档等。所有这些内容都应该受到版本控制，与每次构建结果相关的版本都应可以识别。也就是说，这些变更集（change set）都应该有唯一标识，比如构建号、版本控制库中的版本号。

### 提前并频繁地做让你感到痛苦的事

​	这是最通用的原则，也是最有启发性的。在软件交付这个领域，它可能是最有用的一个启发式原则，我们所说的一切都可以归结到这一点上。集成通常是一个非常痛苦的过程。如果你的项目也是如此，那么就应该在每次有人提交代码后立刻进行集成，而且应该从项目一开始就这么做。如果测试是发布之前最痛苦的事情，那么就别拖到最后，而是应从项目一开始就不断地进行测试。

### 内建质量

​	越早发现缺陷，修复它们的成本越低。如果在没有提交代码到版本控制之前，我们就能发现并修复缺陷的话，代价是最小的。

​	“内建质量”还有另外两个推论

* 测试不是一个阶段，当然也不应该开发结束之后才开始。如果把测试留在最后，那就为时晚矣，因为可能根本没有时间修复那些刚被发现的问题。
* 测试也不纯粹或主要是测试人员的领域。交付团队的每个人都应该对应用程序的质量负责。

### “DONE”意味着“已发布”

​	我们认为，一个特性只有交到用户手中才能算“DONE”。这是持续部署实践背后的动机之一。

​	对于一些敏捷交付团队来说，“DONE”意味着软件已经部署到生产环境上。对于软件项目来说，这是一种理想状态。将其作为衡量是否完成的标准，并不总是合适的。对于那些第一次发布的软件系统来说，它可能需要一段时间才能达到“让外部用户真正从该软件身上获益”的状态。因此，我们可以暂且退让一步，只要某个功能在类生产环境上向客户代表做过演示，并且客户代表试用之后就认为是完成了。

​	根本没有“已经完成了80%”这一说法。任何事情要么是完成了，要么就是没完成。我们可以估计尚未完成的某件工作还需要多少工作量，但仅仅是估计而已。

### 交付过程是每个成员的责任

​	很多项目都是开发者开发后将困难转交给测试者，而测试者又在发布时将困难转嫁到运维团队。当出现问题时，人们花费大量的时间来修复错误，并用同等的时间来互相指责。

​	假如你工作于小规模团队或相对独立的部门，也许对发布软件所需的资源有绝对的控制能力。如果是这样，当然非常好啦。假如不是这样的话，你就要有思想准备，很可能需要长期的艰苦工作才能打破不同角色之间的壁垒。

​	这是DevOps运动的核心原则之一。DevOps运动的焦点和我们这本书的目标一致：为了更加快速且可靠地交付有价值的软件，鼓励所有参与软件交付整个过程中的人进行更好的协作。

### 持续改进

​	应用程序的首次发布只是其生命周期中的第一个阶段。随着应用程序的演进，更多的发布将会接踵而来。更重要的是，你的交付过程应该随之不断演进。

​	在交付过程中，整个团队应该定期地坐在一起，召开回顾会议，反思一下在过去一段时间里哪些方面做得比较好，应该继续保持，哪些方面做得不太好，需要改进，并讨论一下如何改进。每个改进点都应该有一个人负责跟踪，确保相应的改进活动能够被执行。当下一次团队坐在一起时，他们应该向大家汇报这些活动的结果。这就是众所周知的戴明环：计划-执行-检查-处理（PDCA）。

​	关键在于组织中的每个人都要参与到这个过程当中。如果只在自己所在角色的内部进行反馈环，而不是在整个团队范围内进行的话，就必将产生一种“顽疾”：以整体优化为代价的局部优化，最终导致互相指责。

# 配置管理

## 引言

​	假如项目中有良好的配置管理策略，那么你对下列所有问题的回答都应该是“YES”。

* 你能否完全再现你所需要的任何环境（这里的环境包括操作系统的版本及其补丁级别、网络配置、软件组合，以及部署在其上的软件应用及其配置）？
* 你能很轻松地对上述内容进行增量式修改，并将修改部署到任意一种或所有环境中吗？
* 你能否很容易地看到已被部署到某个具体环境中的某次修改，并能追溯到修改源，知道是谁做的修改，什么时候做的修改吗？
* 你能满足所有必须遵守的规程章则吗？
* 是否每个团队成员都能很容易地得到他们所需要的信息，并进行必要的修改呢？这个配置管理策略是否会妨碍高效交付，导致周期时间增加，反馈减少呢？



在本章中，我们将讨论三个问题。

* 为管理应用程序的构建、部署、测试和发布过程做好准备。我们从两个方面解决这个问题：对所有内容进行版本控制；管理依赖关系。
* 管理应用软件的配置信息。
* 整个环境的配置管理，这包括应用程序所依赖的软件、硬件和基础设施。另外还有环境管理背后的原则，包括操作系统、应用服务器、数据库和其他COTS（商业现货）软件。

## 使用版本控制

​	本质上来讲，版本控制系统的目的有两个。首先，它要保留每个文件的所有版本的历史信息，并使之易于查找。这种系统还提供一种基于元数据（这些元数据用于描述数据的存储信息）的访问方式，使元数据与某个单个文件或文件集合相链接。其次，它让分布式团队（无论是空间上不在一起，还是不同的时区）可以愉快地协作。

* 对于我们开发的应用软件，某个特定的版本是由哪些文件和配置组成的？如何再现一份与生产环境一模一样的软硬件环境？
* 什么时候修改了什么内容，是谁修改的，以及为什么要修改？因此，我们很容易知道应用软件在何时出了错，出错的过程，甚至出错的原因。

### 对所有内容进行版本控制

​	每个与所开发的软件相关的产物都应被置于版本控制之下。开发人员不但要用它来管理和控制源代码，还要把测试代码、数据库脚本、构建和部署脚本、文档、库文件和应用软件所用的配置文件都纳入到版本控制之中，甚至把编译器以及工具集等也放在里面，以便让新加入项目的成员可以很容易地从零开始工作。

​	为了重新搭建测试环境和生产环境，将所有必需的信息保存起来也是很重要的。这里必需的信息包括应用程序所需的支撑软件的配置信息、构成对应系统环境的操作系统配置信息、DNS区域文件和防火墙配置等。你至少要将那些用于重新创建应用程序的安装文件和安装环境所必需的所有信息保存在版本控制存储库之中。

​	我们的目标是能够随时获取软件在整个生命周期中任意时间点的文件状态。这样我们就可以选择从开发环境至生产环境整个环节中的任意时间点，并将系统恢复到该时间点的状态。我们甚至可以把开发团队所需的开发环境配置也置于版本控制中，如此一来，团队中的每个成员都能够轻松使用完全相同的设置。分析人员应该把需求文档保存到版本控制存储库中。测试人员也应该将自己的测试脚本和过程保存在版本控制存储库中。项目经理则应该将发布计划、进度表和风险日志也保存在这里。总之，每个成员都应该将与项目相关的任何文件及其修订状态保存在版本控制存储库之中。

​	除了存储源代码和配置信息，很多项目还将其应用服务器、编译器、虚拟机以及其他相关工具的二进制镜像也放在版本控制库中。

​	但我们并不推荐将源代码编译后得到的二进制文件也纳入到版本控制中，有以下几个理由。首先，它们通常比较大，而且（与编译程序不同）会让存储所需要的空间快速膨胀，因为我们每次签入代码，在编译和自动提交测试通过后，都会生成新的二进制文件。其次，如果有自动化构建系统，那么只要重新运行构建脚本，就可以利用源代码重新生成需要的二进制文件。这样的话，根本没有必要把这类二进制产物放在版本控制库中。请注意，我们并不推荐在同一个自动化构建过程中进行重复编译。因为如果需要二进制产物的话，我们只要通过构建系统把源代码再重新打包生成一次就可以了。最后，我们使用修订版本号来标识产品的版本。如果我们把构建生成的二进制文件也储存在版本控制库中，那么在存储库中的一个版本就会有两个不同的源，一个是源代码，另一个是二进制文件。尽管看上去这有点儿含糊，但创建部署流水线（本书的主要议题之一）时就显得极为重要了。

**版本控制：“删除”的自由**

​	版本控制库中包含每个文件的每一个版本，它的好处就是：可以随时删除你认为不必要的文件。只要有版本控制系统，对于“是否可以删除这个文件？”这个问题，你可以轻松地回答“Yes”。如果事实证明你的删除决定是错的，只要从早期版本中把它再找回来就行了。

​	这种“自由删除”是维护大型配置集合向前迈进的重要一步。保证大型团队能高效工作的关键就在于一致性和良好的组织性。“打破陈规”的能力使团队可以勇敢地尝试新的想法或实现方式，提高代码质量。

### 频繁提交代码到主干

​	首先，只有频繁提交代码，你才能享受版本控制所带来的众多好处，比如能够轻松地回滚到最近某个无错误的版本。

​	如果你频繁提交，其他人可以看到你的修改且可与之交互，你也可以清楚地知道你的修改是否破坏了应用程序，而且每次合并工作的工作量会一直很小，易于管理。

​	有些人解决这个两难问题的方法是，在版本控制系统中为新功能建立单独的分支。到某个时间点后，如果这些修改的质量令人满意，就将其合并到主干。这类似于“两阶段提交”。实际上，有些版本控制系统就是以这种方式工作的。

​	然而，我们对这样的做法持反对意见，除非是第14章提到的那三种例外情况。在这一点上有一些争议，尤其是在使用ClearCase以及相似工具的用户中。我们认为，这种方法存在以下几个问题。

* 它违背了持续集成的宗旨，因为创建分支的做法推迟了新功能的整合，只有当该分支被合并时才可能发现集成问题。
* 如果多个开发者同时分别创建了多个分支，问题会成指数增加，而合并过程也会极其复杂。
* 尽管有一些好用的工具有自动合并功能，但它们无法解决语义冲突。例如，某人在一个分支上重命名了一个方法，而另一个人在另一分支上对该方法增加了一次调用。
* 它让重构代码库变得非常困难，因为分支往往涉及多个文件，会让合并变得更加困难。



​	一个更好的解决方案是尽量使用增量方式开发新功能，并频繁且有规律地向版本控制系统提交代码。这会让软件能一直保持在集成以后的可工作状态。而且，你的软件会一直被测试，因为每次提交代码时，持续集成服务器就会从代码主干上运行自动测试。这会减小因重构引起的大规模合并导致冲突的可能性，确保集成问题能够被及时发现，此时修复这些问题的成本很低，从而提高软件开发质量。

​	为了确保提交代码时不破坏已有的应用程序，有两个实践非常有效。

* 一是在提交代码之前运行测试套件。这个测试套件应该是一个快速运转（一般少于10分钟）且相对比较全面的测试集合，以验证你没有引入明显的回归缺陷。很多持续集成服务器都提供名为“预测试提交”（pretested commit）的功能，让你在提交之前可以在类生产环境中执行这些测试。
* 增量式引入变化。我们建议每完成一个小功能或一次重构之后就提交代码。如果能正确地使用这一技术，你每天最少可以提交一次，通常能达到每天提交多次。如果你还未习惯于这种技术的话，肯定会以为是“天方夜谭”。但我们向你保证，这种技术能够带来相当高效的软件交付过程。

### 使用意义明显的提交注释

​	当构建失败以后，你知道是谁破坏了构建，以及他为什么破坏了构建。当然，这并不是唯一原因。很多时候，提交人没有写足够的描述信息，其原因通常是由于正在抓紧解决某个非常复杂的问题。我们可能常常遇到下面的场景。

* 你发现了一个缺陷，结果追溯到一行相当晦涩的代码。
* 你通过查看版本控制系统的日志，查找放入这行代码的人，以及他是什么时候放入的。
* 可是，放入这行代码的人去度假或者回家了，而他写的提交注释只有简单的几个字，即“已修复令人费解的缺陷”。
* 为了修复这个缺陷，你修改了这行晦涩代码。
* 但是却把其他功能破坏了。
* 你只能再花几个小时的时间，让软件恢复到可工作状态。

## 依赖管理

### 外部库文件管理

​	那么是否一定要把外部依赖库文件放在版本控制库中呢？其实，放与不放，各有利弊。如果放了，那我们更容易将软件的版本与正确的库文件版本相关联，但它也可能使源代码库的体积更大，并且签出时间也会变长

### 组件管理

​	将整个应用软件分成一系列的组件进行开发（小型应用除外）是个不错的实践。这能让某些变更的影响范围比较小，从而减少回归缺陷。另外，它还有利于重用，使大项目的开发过程更加高效

## 软件配置管理

### 配置与灵活性

​	灵活性也是有代价的。

​	对于软件灵活性的期望常常导致一种反模式，即“终极配置”，而这种反模式常被表述为对一个软件项目的需求。如果做得好，它没有什么坏处，但是如果搞不好的话，它会毁了一个项目。

​	根据我们的经验，“修改配置信息的风险要比修改代码的风险低”这句话就是个错觉。就拿“停止一个正在运行的应用系统”这个需求来说，通过修改代码或修改配置都很容易办到。如果使用修改源代码的方式，可以有多种方式来保证质量，比如编译器会帮我们查语法错误，自动化测试可以拦截很多其他方面的错误。然而，大多数配置信息是没有格式检查，且未经测试的。在大多数系统中，没有什么机制能阻止我们将一个URI“http://www.asciimation.co.nz/”改为“this is not a validURI”。大多数系统只有在运行时，才能发现这样的更改，此时用户不是惊喜地看到ASCII版的Star Wars，而是看到一堆系统异常报告，因为URI这个类无法解析“this is not a valid URI”。

在构建高度可配置的软件的道路上有很多陷阱，而最糟糕的可能莫过于下面这些。

* 经常导致分析瘫痪，即问题看上去很严重，而且很棘手，以至于团队花费很多时间思考如何解决它，但最终还是无法解决。
* 系统配置工作变得非常复杂，以至于抵消了其在灵活性上带来的好处。更有甚者，可能在配置灵活性上花费的成本与定制开发的成本相当。



​	可配置的软件并不总是像它看起来那么便宜。更好的方法几乎总是先专注于提供具有高价值且可配置程度较低的功能，然后在真正需要时再添加可配置选项。

*  在生成二进制文件时，构建脚本可以在构建时引入相关的配置，并将其写入新生成的二进制文件。
* 在打包时将配置信息一同打包到软件中，比如在创建程序集，以及打包ear或gem时。
* 在安装部署软件程序时，部署脚本或安装程序可以获取必要的配置信息，或者直接要求用户输入这些配置信息。
* 软件在启动或运行时可获取配置。



​	一般来说，我们并不赞同在构建或打包时就将配置信息植入的做法，而是应使用相同二进制安装包向所有的环境中部署，以确保这个发布的软件就是那个被测试过的软件。根据这一个原则，我们可以推出：在相临的两次部署之间，任何变更都应该作为配置项被捕获和记录，而不应该在编译或打包时植入。

### 配置的分类

* 在生成二进制文件时，构建脚本可以在构建时引入相关的配置，并将其写入新生成的二进制文件。
* 在打包时将配置信息一同打包到软件中，比如在创建程序集，以及打包ear或gem时
* 在安装部署软件程序时，部署脚本或安装程序可以获取必要的配置信息，或者直接要求用户输入这些配置信息。
* 软件在启动或运行时可获取配置。



​	一般来说，我们并不赞同在构建或打包时就将配置信息植入的做法，而是应使用相同二进制安装包向所有的环境中部署，以确保这个发布的软件就是那个被测试过的软件。根据这一个原则，我们可以推出：在相临的两次部署之间，任何变更都应该作为配置项被捕获和记录，而不应该在编译或打包时植入。

​	通常来说，能够在部署时对软件进行配置是非常重要的，这样就可以告诉应用程序在哪儿能找到所需服务，比如数据库、邮件服务器或外部系统。比如，当应用程序运行时的配置信息被存储在数据库中，你可能要在部署应用程序时将数据库的连接参数传入，使应用程序启动时可以从数据库中取到这些信息。

​	如果你有权限完全控制生产环境，就通常能让部署脚本自行获取这些配置并提供给应用。对于套装软件来说，安装包中通常都有默认的配置信息。做软件测试时，我们仍需要用某种方法在部署过程中修改某些配置信息。

​	当然，我们还可能要在启动或运行应用程序时修改某些配置。在系统启动时，我们可以通过命令参数或环境变量等形式提供配置信息。另外，你还可以使用同样的机制来做运行时的配置，比如注册表设置、数据库、配置文件，或者使用外部配置服务（比如通过SOAP或REST风格的接口访问）。

### 应用程序的配置管理

​	在管理应用程序的配置这个问题上，需要回答三个问题。

（1）如何描述配置信息？

（2）部署脚本如何存取这些配置信息？

（3）在环境、应用程序，以及应用程序各版本之间，每个配置信息有什么不同？



​	小提示：不要把密码签入到版本控制系统中，也不要把它硬编码到应用程序中。要是让运维人员知道你这么做，一定会让你卷铺盖走人的。所以，别给他们这样的机会。如果你坚持要将密码存在某处而不是自己记住的话，可以试着把它加密后放在用户主目录下。

​	这种方法的另一种极糟的使用方式是，将应用程序某一层上的密码保存在需要访问它的那层代码或文件系统中。实际上，用户在部署时应该每次都手工输入密码。对于多层应用系统来说，有多种方式来处理验证问题。比如，你可以使用证书、目录服务，或者一个单点登录系统。

**获取配置信息**

​	管理配置最有效的方法是让所有的应用程序通过一个中央服务系统得到它们所需要的配置信息。

**为配置项建模**

​	每个配置都是一个元组，所以应用程序的配置信息由一系列的元组构成。然而，这些元组及其值取决于三方面，即应用程序、该应用程序的版本、该版本所运行的环境（例如开发环境、用户验收测试环境、性能测试环境、试运行环境或生产环境）。

​	下面列举了一些在对配置信息建模时需要考虑的用例。

* 新增一个环境（比如一个新的开发工作站，或性能测试环境）。在这种情况下你要能为这个配置应用的新环境指定一套新的配置信息。
* 创建应用程序的一个新版本，通常需要添加一些配置设置，删除一些过时的配置设置。此时应该确保在部署新版本时，可以使用新的配置设置，但是一旦需要回滚时，还能够使用旧版本的配置设置。
* 将新版本从一个环境迁移到另一个环境，比如从测试环境挪到试运行环境。此时应该确保新环境上的新配置项都有效，而且为其设置了正确的值。
* 重定向到一个数据库服务器。应该只需要简单地修改所有配置设置，就能让它指向新的数据库服务器。
* 通过虚拟化技术管理环境。应该能够使用虚拟技术管理工具创建某种指定的环境，并且配置好所有的虚拟机。你也许需要将这种虚拟环境中的配置信息作为某特定版本的应用软件在虚拟环境中的标准配置信息。

**系统配置的测试**

​	与应用程序和构建脚本一样，配置设置也需要测试。对于系统配置测试来说，包括以下两部分。

​	一是要保证配置设置中对外部服务的引用是良好的。比如，作为部署脚本的一部分，我们要确保消息总线（messaging bus）在配置信息中所指定的地址已启动并运行，并确保应用程序所用的模拟订单执行服务在功能测试环境中能够正常工作。最起码，要保证能够与所有的外部服务相连通。如果应用程序所依赖的任何部分没有准备好，部署或安装脚本都应该报错，这相当于配置设置的冒烟测试。

​	二是当应用程序一旦安装好，就要在其上运行一些冒烟测试，以验证它运行正常。对于系统配置的测试，我们只要测试与配置有关的功能就可以了。在理想情况下，一旦测试结果与预期不符，这些测试应该能够自动停止软件的运行，并显示安装或部署失败。

### 跨应用的配置管理

​	大中型组织中，通常会同时管理很多应用程序，而软件配置管理的复杂性也会大大增加。这类组织中一般都会有遗留系统，而且很可能某个遗留系统的配置项让人很难搞得清楚明白。这种情况下，最重要的任务之一就是，要为每个应用程序维护一份所有配置选项的索引表，记录这些配置保存在什么地方，它们的生命周期是多长，以及如何修改它们。

​	如果应用程序之间有依赖关系，部署有先后次序的话，实时存取配置信息的能力就特别重要。很容易因配置信息设置不当而浪费很多时间，甚至导致整套服务无法正常运行，而这类问题是极难诊断的。

### 管理配置信息的原则

* 在应用程序的生命周期中，我们应该在什么时候注入哪类配置信息。是在打包的时候，还是在部署或安装的时候？是在软件启动时，还是在运行时？要与系统运维和支持团队一同讨论，看看他们有什么样的需求。
* 应该总是通过自动化的过程将配置项从保存配置信息的存储库中取出并设置好，这样就能很容易地掌握不同环境中的配置信息了。
* 配置系统应该能依据应用、应用软件的版本、将要部署的环境，为打包、安装以及部署脚本提供不同的配置值。每个人都应该能够非常容易地看到当前软件的某个特定版本部署到各种环境上的具体配置信息。
* 对每个配置项都应用明确的命名习惯，避免使用晦涩难懂的名称，使其他人不需要说明手册就能明白这些配置项的含义
* DRY（Don't Repeat Yourself）原则。定义好配置中的每个元素，使每个配置元素在整个系统中都是唯一的，其含义绝不与其他元素重叠。
* 最少化，即配置信息应尽可能简单且集中。除非有要求或必须使用，否则不要新增配置项。
* 避免对配置信息的过分设计，应尽可能简单。
* 保测试已覆盖到部署或安装时的配置操作。检查应用程序所依赖的其他服务是否有效，使用冒烟测试来诊断依赖于配置项的相关功能是否都能正常工作。

## 环境管理

​	没有哪个应用程序是孤岛。每个应用程序都依赖于硬件、软件、基础设施以及外部系统才能正常工作。

 	环境的配置和应用程序的配置同样重要。例如，如果应用程序需要用到消息总线，那么只有正确配置了这个消息总线，应用程序才能正常工作。操作系统的配置也同样重要。

​	这里把不良环境管理可能带来的问题总结如下。

* 配置信息的集合非常大；
*  一丁点变化就能让整个应用坏掉，或者严重降低它的性能。
*  一旦系统出现问题，需要资深人员花费不确定的时间来找到问题根源并修复它。
* 很难准确地再现那些手工配置的环境，因此给测试验证带来很大困难。
* 很难维护一个不使用配置信息的环境，因此维护这种环境下的行为也很难，尤其是不同的节点有不同的配置时。



​	重现环境的能力是非常必要的，原因如下。

* 可以避免知识遗失问题。比如某人离职且无法与他联系上，但只有他明白某个配置项所代表的意思。一旦这类配置项不能正常工作，通常都意味着较长的停机时间。这是一个很大却不必要的风险。
* 修复某个环境可能需要花费数小时的时间。所以，我们最好能在可预见的时间里重建环境，并将它恢复到某个已知的正常状态下。
* 创建一个和生产环境相同的测试环境是非常必要的。对于软件配置而言，测试环境应该和生产环境一模一样。这样，配置问题更容易被在早期发现。



​	需要考虑的环境配置信息如下：

* 环境中各种各样的操作系统，包括其版本、补丁级别以及配置设置；
* 应用程序所依赖的需要安装到每个环境中的软件包，以及这些软件包的具体版本和配置；
* 应用程序正常工作所必需的网络拓扑结构；
* 应用程序所依赖的所有外部服务，以及这些服务的版本和配置信息；
* 现有的数据以及其他相关信息（比如生产数据库）。



​	其实高效配置管理策略的两个基本原则是：

（1）将二进制文件与配置信息分离；

（2）将所有的配置信息保存在一处。如果应用了这两个基本原则，你就能将“在系统不停机的情况下，创建新环境、升级系统部分功能或增加新的配置项”等工作变成一个简单的自动化过程。

​	当评估第三方产品或服务时，应该问自己如下问题。

* 我们可以自行部署它吗？
* 可以自行部署它吗？
* 如何使它适应我们的自动化部署策略？

### 环境管理的工具

​	在以自动化方式管理操作系统配置的工具中，Puppet和CfEngine是两个代表。使用这些工具，你能以声明方式来定义一些事情，如哪些用户可以登录你的服务器，应该安装什么软件，而这些定义可以保存在版本控制库中。运行在系统中的代理（agent）会从版本控制库中取出最新的配置，更新操作系统以及安装在其之上的软件。对于应用了这些工具的系统来说，根本没必要登录到服务器上去操作，所有的修改都可能通过版本控制系统来发起，因而你也能够得到每次变化的完整记录，即谁在什么时候做了什么样的修改。

​	虚拟化技术也可以提高环境管理过程的效率。不必利用自动化过程从无到有地创建一个新环境，你可以轻易地得到一份环境副本，并把它作为一个基线保存起来。

### 变更过程管理

​	最后要强调的是，对环境的变更过程进行管理是必要的。应该严格控制生产环境，未经组织内部正式的变更管理过程，任何人不得对其进行修改。

​	如果配置管理流程比较好的话，对于下面的问题，你的回答都应该是肯定的。

* 是否仅依靠保存于版本控制系统中的数据（除了生产数据），就可以从无到有重建生产系统？
* 是否可以将应用程序回滚到以前某个正确的状态下？
* 是否能确保在测试、试运行和正式上线时以同样的方式创建部署环境？



​	如果回答是否定的，那么你的组织正处于风险之中。我们建议为下面的内容制定出一个保存基线和控制变更的策略:

* 应用程序的源代码、构建脚本、测试、文档、需求、数据库脚本、代码库以及配置文件；
* 用于开发、测试和运维的工具集；
* 用于开发、测试和生产运行的所有环境；
* 与应用程序相关的整个软件栈，包括二进制代码及相关配置；
* 在应用程序的整个生产周期（包括构建、部署、测试以及运维）的任意一种环境上，与该应用程序相关联的配置。

# 持续集成

## 引言

​	持续集成背后的思想是：既然经常对代码库进行集成对我们有好处，为什么不随时做集成呢？就集成而言，“随时”意思是指每当有人提交代码到版本控制库时。

## 实现持续集成

### 准备工作

​	在开始做持续集成之前，你需要做三件事情。

**版本控制**

​	与项目相关的所有内容都必须提交到一个版本控制库中，包括产品代码、测试代码、数据库脚本、构建与部署脚本，以及所有用于创建、安装、运行和测试该应用程序的东西。

**自动化构建**

​	你要能在命令行中启动构建过程。无论是通过命令行程序启动IDE来构建应用程序，然后再运行测试，还是使用多个复杂的构建脚本通过互相调用的方式来完成都行，但无论采用哪种机制，必须满足如下条件：人和计算机都能通过命令行自动执行应用的构建、测试以及部署过程。

* 要能在持续集成环境中以自动化的方式来执行整个构建过程，以便出现问题时能够审计。
* 应将构建脚本与代码库同等对待。应该对它进行测试，并不断地重构，以使它保持整洁且容易理解，而集成开发环境自动生成的构建过程基本上无法做到这一点。项目越复杂，这项工作就越重要。
* 使理解、维护和调试构建过程更容易，并有利于和运维人员更好地协作。

**团队共识**

​	持续集成不是一种工具，而是一种实践。它需要开发团队能够给予一定的投入并遵守一些准则，需要每个人都能以小步增量的方式频繁地将修改后的代码提交到主干上，并一致认同“修复破坏应用程序的任意修改是最高优先级的任务”。

### 一个基本的持续集成系统

​	现在的持续集成工具其安装和运行都极其简单。有几个开源工具可供选择，比如Hudson和受人尊敬的CruiseControl家族（CruiseControl、CruiseControl.NET和CruiseControl.rb）。其中，Hudson和CruiseControl.rb的启动和运行尤其简单。CruiseControl.rb是很轻量级的，而且掌握一些Ruby知识的人很容易对它进行扩展。Hudson的插件很多，这使它可以与构建和部署领域中的很多工具集成。

​	在此书编写之际，还有两种商业化持续集成服务器为小团队提供了免费版本，它们是ThoughtWorks Studios开发的Go以及JetBrains的TeamCity。其他流行的商业化持续集成服务器还包括Atlassian的Bamboo和Zutubi的Pulse。高端的发布管理以及构建加速系统还有UrbanCode的AntHillPro、ElectricCloud的ElectricCommander，以及IBM的BuildForge，它们都可以用于简单的持续集成。还有很多其他产品，完整列表可参见CI feature matrix[插图]。

​	第一次在持续集成工具上执行构建时，你很可能发现在运行持续集成工具的机器上缺少一些必需的软件和设置。这是一个独一无二的学习机会，请将接下来你所做的工作全部记录下来，并放在自己项目的知识共享库中。你应该花上一些时间将应用程序所依赖的所有软件和配置项提交到版本控制系统中，并将重建全新环境的整个活动变成一个自动化的过程。

​	一旦准备好要提交最新修改代码时，请遵循如下步骤。

* 查看一下是否有构建正在运行。如果有的话，你要等它运行完。如果它失败了，你要与团队中的其他人一起将其修复，然后再提交自己的代码。
* 一旦构建完成且测试全部通过，就从版本控制库中将该版本的代码更新到自己的开发环境上
* 在自己的开发机上执行构建脚本，运行测试，以确保在你机器上的所有代码都工作正常。当然你也可以利用持续集成工具中的个人构建功能来完成这一步骤。
* 如果本地构建成功，就将你的代码提交到版本控制库中。
* 然后等待包含你的这次提交的构建结果。
* 如果这次构建失败了，就停下手中做的事，在自己的开发机上立即修复这个问题，然后再转到步骤（3）。
* 如果这次构建成功，你可以小小地庆祝一下，并开始下一项任务。

## 持续集成的前提条件

### 频繁提交

​	对于持续集成来说，我们最重要的工作就是频繁提交代码到版本控制库。每天至少应该提交几次代码。

### 创建全面的自动化测试套件

​	如果没有一系列全面的自动化测试，那么构建成功只意味着应用程序能够编译并组装在一起。虽然对于某些团队来说，这已经是非常大的一个进步了，但是，假如能够有一定程度的自动化测试，会让你更有信心说：“我们的应用程序是可以工作的。”

​	单元测试用于单独测试应用程序中某些小单元的行为（比如一个方法、一个函数，或一小组方法或函数之间的交互）。

​	组件测试用于测试应用程序中几个组件的行为。与单元测试一样，它通常不必启动整个应用程序，但有可能需要连接数据库、访问文件系统或其他外部系统或接口（这些可以使用“桩”，即stub技术）。

​	验收测试的目的是验证应用程序是否满足业务需求所定义的验收条件，包括应用程序提供的功能，以及其他特定需求，比如容量、有效性、安全性等。验收测试最好采用将整个应用程序运行于类生产环境的运作方式。当然，验收测试的运行时间也较长。一个验收测试套件连续运行一整天是很平常的事儿。

###  保持较短的构建和测试过程

* 大家在提交代码之前不愿意在本地环境进行全量构建和运行测试，导致构建失败的几率越来越大。
* 持续集成过程需要花太长时间，从而导致再次运行构建时，该构建会包含很多次提交，所以很难确定到底是哪次提交破坏了本次构建。
* 大家提交的频率会变少，因为每运行一次构建和测试，都要坐在那儿等上一阵子。



​	理想情况下，提交前的预编译和测试过程，以及持续集成服务器上的编译和测试过程应该都能在几分钟内结束。我们认为，十分钟是一个极限了，最好是在五分钟以内，九十秒内完成是最理想的。十分钟对于那些惯于操作小项目的人来说，应该算是比较长的时间了，但对于那些经历过需要花数小时的编译的老前辈来说，却是非常短的时间。这段时间长度应该恰好能泡杯茶，快速聊几句，看一眼邮件，或伸展一下身体。

​	有很多技术可以帮助你减少构建时间。首先要考虑的事情是让测试执行得更快。

​	有时候需要将测试分成几个阶段，首先将其分成两个阶段。第一个阶段用于编译软件，运行所有类级别的单元测试，并创建用于部署的二进制文件。这个阶段叫做“提交阶段”。

​	第二个阶段应该利用第一个阶段所生成的二进制文件进行验收测试、集成测试。假如你有性能测试的话，也要一并运行。利用现代持续集成工具，很容易创建这种分阶段的构建流程，它们能够同时运行多个任务，并将运行结果收集在一起，以便很容易看到运行状态和结果。

​	另外，有时候把一个简单的冒烟测试套件加入到提交阶段，也是非常有用的。这个冒烟测试套件应该执行一些简单的验收和集成测试，用于确保最常见的功能没有被破坏。假如这些基本功能被破坏了，就能得到很快的反馈。

### 管理开发工作区

​	对于保证开发人员的开发效率与明晰思路来说，开发环境的管理是特别重要的。当开发人员刚开始新任务时，应该总是从一个已知正确的状态开始。他们应该能够运行构建、执行自动化测试，以及在其可控的环境上部署其开发的应用程序，通常是在他们自己的开发机上。只有在特殊的情况下，才应使用共享环境开发。在本地开发环境上运行应用程序时，应确保所使用的自动化过程与持续集成环境中的一致，与测试环境中也是一样的，且生产环境中也是一样的。

## 使用持续集成软件

​	持续集成工具最基本的功能就是轮询版本控制系统，查看是否有新的版本提交，如果有的话，则签出最新版本的软件，运行构建脚本来编译应用程序，再运行测试，最后将运行结果告知你。

### 基本操作

​	本质上，持续集成软件包括两个部分。第一部分是一个一直运行的进程，它每隔一定的时间就执行一个简单的工作流程。第二部分就是提供展现这个流程运行结果的视图，通知你构建和测试成功与否，让你可以找到测试报告，拿到生成的安装文件等。

### 铃声和口哨

​	这种可视化的唯一缺点就是，如果开发团队和客户在一起工作的话（对于大多数敏捷项目来说，的确是这样的），构建失败（流程中很自然的一部分）可能被认为是应用程序质量存在问题的信号。事实也正是如此，每次构建失败都表明发现了一个问题，但如果没有发现的话，它就会被带到生产环境中。然而，有时候很难向客户解释“为什么构建总是失败”。我们曾遇到过好几次这种状况，其中有一次构建失败持续了很长时间，期间我们与客户进行了一些艰难的对话，但唯一能做的事情就是让它高度可视化，并努力工作，向客户解释这样做的好处。当然，最佳解决方案是努力工作，让构建一直成功。

​	你还可以在构建过程中对源代码进行一些分析工作，包括分析测试覆盖率、重复代码、是否符合编码标准、圈复杂度，以及其他一些健康指标，并将结果显示在每个构建的总结报告中。你也可以运行一些程序来生成与代码相对应的对象模型图或数据库结构图。所有这些都是可视化的一部分。

​	持续集成前身:

* 每日构建。
* 增加自动化测试。
* rolling builds”过程，即持续不断地运行构建过程，而不是在夜间定时执行批处理过程。

## 必不可少的实践

### 构建失败之后不要提交新代码

​	续集成的第一忌就是明知构建已经失败了，还向版本控制库中提交新代码。如果构建失败，开发人员应该尽快找出失败的原因，并修复它。

### 提交前在本地运行所有的提交测试，或者让持续集成服务器完成此事

​	正如之前提过的，我们希望每次提交都可以产生一个可发布的候选版本。任何人以任何形式公布某个东西之前，都会检查一下自己的工作成果，而候选版本也是一个发行物，所以每次提交前也要做一下检查。

​	我们希望提交过程是一件轻量级的事儿，这样就可以每隔二十分钟左右提交一次了，但它也应该是一件非常严肃的事儿，这样在每次提交之前，我们都会停下来，仔细想一想是否应该提交。提交前在本地运行一次提交测试，就是做一下健全性检查（sanity check）。它也让我们能确信新增的代码的确是按期望的方式运行的。

​	你可能会问：“为什么在提交前还要运行本地提交测试呢？这样的话，我们的编译和提交测试不是要运行两次了吗？”这么做，有两个理由。

* 如果在你根据版本控制进行更新之前，其他人已经向版本控制库中提交了新代码，那么你的变更与那些新代码合并后，可能会导致测试失败。如果你自己先在本地更新代码并运行提交测试的话，假如有问题，就会在本地提前发现，提前修复，从而不会令持续集成服务器上的构建失败，不至于影响其他人及时提交。
* 在提交时经常犯的错误是，忘记提交那些刚刚新增加的东西到存储库中。如果遵守这个流程的话，当本地构建成功，而持续集成系统中的提交阶段失败了的话，那么你就知道要么是由于别人与你同时提交了代码，要么就是你遗漏了一部分类或配置文件没有提交到版本控制系统中。



​	很多现代持续集成服务器还提供这样一种功能，名字叫做预测试提交（pretestedcommit），也称为个人构建（personal build）或试飞构建（preflight build）。使用这种特性，就不必自己进行提交，持续集成服务器将拿到你的本地变更，把它放在构建网格中运行提交测试。一旦构建成功通过，持续集成服务器就替你将变更提交到版本控制库中。如果构建失败的话，它会通知你哪里出错了。

​	Pulse、TeamCity和 ElectricCommander这三种持续集成服务器都已经提供了这个功能。如果使用分布式版本控制系统的话，这个实践就更容易了，因为你可以将代码存储到自己的本地代码控制库中，而无需提交到团队的中央版本控制库中。通过这种方式，一旦个人构建失败的话，很容易通过创建补丁的方式将自己提交的修改搁置，恢复到你刚刚提交到持续集成服务器的那个版本上，将构建修复，再把补丁放上去。

### 等提交测试通过后再继续工作

​	在提交代码时，做出了这一代码的开发人员应该监视这个构建过程，直到该提交通过了编译和提交测试之后，他们才能开始做新任务。在这短短几分钟的提交阶段结束之前，他们不应该离开去吃午饭或开会，而应密切注意构建过程并在提交阶段完成的几秒钟内了解其结果。

### 回家之前，构建必须处于成功状态

​	不建议你工作到很晚来修复失败的构建，而是希望你有规律地尽早提交代码，给自己足够的时间处理可能出现的问题。或者，你可以第二天再提交。很多有经验的开发人员在下班前一小时内不再提交代码，而是把它作为第二天早上的第一件事情。

​	如果位于印度的团队破坏构建后就回家了，那么位于伦敦的团队一整天的工作都会受到极大影响。同样，如果位于伦敦的团队做了同样的事，那么位于美国的同事可能在接下来的八小时之内一直在他们的阴影下工作。

### 时刻准备着回滚到前一个版本

​	如果某次提交失败了，无论采取什么样的行动，最重要的是尽快让一切再次正常运转起来。如果无法快速修复问题，无论什么原因，我们都应该将它回滚到版本控制库中前一个可工作的版本上，之后再在本地环境中修复它。

### 在回滚之前要规定一个修复时间

​	建立一个团队规则：如果因某次提交而导致构建失败，必须在十分钟之内修复它。如果在十分钟内还没有找到解决方案的话，就将其回滚到版本控制系统中前一个好的版本。如果团队能够忍受，有时候也可以延长一段时间来修复它。

### 不要将失败的测试注释掉

​	一旦你决定执行前面所说的规则，有些开发人员常常为了能够提交代码，而将那些失败的测试注释掉。这种冲动是可以理解的，但却是无法被容忍的一种错误行为。那些已经成功运行了一段时间的测试失败时，失败的原因可能很难找。

### 为自己导致的问题负责

​	假如提交代码后，你写的测试都通过了，但其他人的测试失败了，构建结果还是会失败。通常这意味着，你引入了一个回归缺陷。你有责任修复因自己的修改导致失败的那些测试。在持续集成环境中这是理所当然的，但可惜的是，在很多项目中事实并不是这样的。

### 测试驱动的开发

​	关于测试驱动开发的话题超出了本书的范围。但值得注意的是，和所有其他此类实践一样，测试驱动开发也需要纪律性和实效性。在这里我们向读者推荐两本相关的书藉：Steve Freeman和Nat Pryce合著的Growing Object-Oriented Software,Guided by Tests,以及Gerard Meszaros写的xUnit Test Patterns:RefactoringTest Code。

## 推荐的实践

### 极限编程开发实践

​	对于任何团队，即使不采用其他实践，只用持续集成也会给项目开发带来很大改善，而若与其他实践相结合的话，它的作用会更大。尤其是，除了测试驱动开发和我们前面讲到的代码集体所有权，你还应该考虑把重构作为高效软件开发的基石。

​	重构是指通过一系列小的增量式修改来改善代码结构，而不会改变软件的外部行为。通过持续集成和测试驱动开发可以确保这些修改不会改变系统的行为，从而使重构成为可能。这样，你的团队就可以自由自在地修改代码，即使偶尔涉及较大范围的代码修改，也不用担心它会破坏系统了。这个实践也让频繁提交成为了可能，即开发人员在每次做了一个小的增量式修改后就提交代码。

### 若违背架构原则，就让构建失败

​	开发人员有时很容易忘记系统架构的一些原则。我们曾经使用过一种手段来解决这个问题，那就是写一些提交时测试，用于证明这些原则没有被破坏。

### 若测试运行变慢，就让构建失败

​	持续集成需要小步频繁提交。如果提交测试要运行很长时间的话，这种长时间的等待会严重损害团队的生产效率，他们将花费很长的时间等待构建和测试过程完成。而且，这样也无法做到频繁提交，结果会导致团队成员开始把每次要提交的内容都存在本地，而每多增加一次本地保存就会增加一些复杂性，同时也增加了与版本控制库的代码出现合并冲突的可能性，增加了引入错误的几率，最终可能导致测试失败。所有这些最终都会导致生产率下降。

​	为了让开发团队注意到快速测试的重要性，可以这样做：当某个测试运行超过一定时间后，就让这次提交测试失败。我们在上一个项目中使用的这一时间是两秒。

### 若有编译警告或代码风格问题，就让测试失败

​	编译器发出警告时，通常理由都足够充分。我们曾经用过一个比较成功的策略，即只要有编译警告，就让构建失败，但我们的开发团队常常把它叫做“纳粹代码”。这在某些场合可能有点儿苛刻，但作为强迫写好代码的一种实践，还是很有效的。你可以通过添加代码检查尽可能地强化这一技术。

​	我们成功使用过很多关于代码质量检查的开源工具，如下所示：

* Simian是一种可以识别大多数流行语言（包括纯文本）中重复代码的工具。
* JDepend是针对Java的免费版本，它有一个．NET的商业版本NDepend，它们拥有大量对设计质量进行评估的实用（和不太实用）的度量指标。
* CheckStyle可以对“烂代码”做一些检查，比如工具类中的公共构造函数、嵌套的代码块和比较长的代码行。它也能找到缺陷和安全漏洞的一些常见根源。它还很容易被扩展。FxCop是它的．NET版本。
* FindBugs是一个Java软件，它是CheckStyle的替代品，有一些相似的校验功能。

## 分布式团队

### 对流程的影响

​		对在同一时区内的分布式团队来说，持续集成流程基本是一样的。当然，你无法以实物的形式使用提交令牌。虽然有些持续集成服务器支持虚拟令牌，但它不具有人性化特点，所以当你提醒某人去修复构建时，容易导致大家的抵触心理。同时，类似“个人构建”这种功能会变得更加有用。但总地来说，流程是一样的。

​	对分布在不同时区的分布式团队来说，就需要多处理一些事情啦。如果在旧金山的团队在破坏构建以后回家了，那么，这对北京的团队可能就是个严重的阻碍。因为当旧金山的团队下班后，北京才刚上班。尽管流程没有什么变化，但不良影响会被放大。

### 集中式持续集成

​	一些功能更强大的持续集成服务器提供像“集中管理构建网格”和“高级授权机制”这种功能，用于把持续集成作为一个集中式服务，为大型分布式团队提供服务。这样的服务器让团队很容易建立自服务式的持续集成服务，而不需要自己管理硬件。它也会让运维团队将持续集成作为集中式服务，统筹服务器资源，管理持续集成和测试环境的配置，以确保这些环境的一致性以及与生产环境的相似性，还能巩固一些好的实践，比如第三方库的配置管理，预安装一些工具（用于收集代码覆盖率和质量的统一度量数据。最终，我们可以做到项目之间的统一度量数据的收集和监控，为管理者和交付团队提供程序级的代码质量监控方式。

​	虚拟化技术可以与集中式持续集成服务很好地结合，只需要单击一下按钮就能利用已保存好的基线镜像重建一个新的虚拟机。利用虚拟化技术，可以为开发团队提供一键式搭建新环境这样的自服务功能。这也可以确保构建和部署一直运行在一致的基线版的环境中。	

### 技术问题

​	当分布于世界各地的团队之间网络状况不佳时，依据选择的不同版本控制系统，团队间共享版本控制系统、构建和测试资源的做法有时候也会有很多麻烦。在持续集成运转良好时，整个团队都会有规律地提交代码。这意味着，与版本控制系统之间的交互通常保持在一个较高的合理水平上。由于提交和更新比较频繁，虽然每次交互通常都较小（甚至可以用字节来计算），劣质的通信仍会严重拖生产效率的后腿。因此，加大投入在各开发中心之间建立起足够高带宽的通信机制是非常必要的。考虑将集中式的版本控制库迁到某种分布式版本控制系统（比如Git或Mercurial）也是不错的选择。闻名知意，即使无法连接到主服务器，分布式版本控制系统也能让大家提交代码。

### 替代方法

​	如果由于某些不可克服的原因，无法再增加投入在开发中心间建立更高带宽的通信机制，各地团队还可以使用本地持续集成和测试系统（当然这不太理想），甚至在某些极端情况下，不得不用本地的版本控制系统。我们并不建议使用这种方法，但这种情况在现实中还是很有可能的。所以，我们要尽一切可能避免使用这种方法。这种方法在时间和人力上的成本都很高，而且根本无法做到团队间的共享访问和控制。

​	对于分布式团队来说，主要有两种方式来解决本地化版本控制系统的存取问题：一是将应用程序分成多个组件；二是使用那些分布式或支持多主库拓扑结构的版本控制系统。

## 分布式版本控制系统

​	DVCS（Distributed Version Control System，分布式版本控制系统）的兴起是团队合作方式的革命性改进。很多开源项目曾经使用电子邮件或论坛发帖的方式来提交补丁，而像Git和Mercurial这种工具让开发人员之间、团队之间以及分支与合并工作流时的打补丁变得极其简单。DVCS使你能够离线工作、本地提交，或在将修改提交给其他人之前把这些代码搁置起来或对其做rebase操作。DVCS的核心特性是每个仓库都包括项目的完整历史，这意味着除了团队约定之外，仓库是没有权限控制功能的。所以，与集中式系统相比，DVCS引入了一个中间层：在本地工作区的修改必须先提交到本地库，然后才能推送到其他仓库，而更新本地工作区时，必须先从其他仓库中将代码更新到本地库。

​	持续集成的以上这些替代方案可以创建高质量可工作的软件。然而，这必须满足以下条件才能成为事实。

* 有一个成员比较少，但都非常有经验提交团队。他们可以取每个补丁、照管自动化测试并确保软件的质量。
* 频繁地从分支上取被修改过的代码，以避免由于积累太多的代码使变更很难合并。如果发布的时间计划非常严格，则这个条件就非常重要，因为人们倾向于临在近发布时刻再合并，而此时的合并是极其痛苦的——这正是持续集成要解决的问题。
* 相对较少的核心开发人员，可能有一个贡献频率较低但人员较多的社区作为补充。这会让合并具有可追溯性。

## 小结

​	总之，一个好的持续集成系统是基石，在此之上你可以构建更多的基础设施：

* 一个巨大的可视化指示器，用于显示构建系统所收集到的信息，以提供高质量的反馈；
* 结果报告系统，以及针对自己测试团队的安装包；
* 为项目经理提供关于应用程序质量的数据的提供程序；
* 使用部署流水线，可以将其延展到生产环境，为测试人员和运维团队提供一键式部署系统。

# 测试策略的实现

## 引言

​	戴明14条之一就是：“停止依赖于大批量检查来保证质量的做法。改进过程，从一开始就将质量内嵌于产品之中。”

​	测试策略的设计主要是识别和评估项目风险的优先级，以及决定采用哪些行动来缓解风险的一个过程。好的测试策略会带来很多积极作用。测试会建立我们的信心，使我们相信软件可按预期正常运行。也就是说，软件的缺陷较少，技术支持所需的成本较低，客户认可度较高。测试还为开发流程提供了一种约束机制，鼓励团队采用一些好的开发实践。一个全面的自动化测试套件甚至可以提供最完整和最及时的应用软件说明文档，这个文档不仅是说明系统应该如何运行的需求规范，还能证明这个软件系统的确是按照需求来运行的。

## 测试的分类

![](https://pic.imgdb.cn/item/60c9b645844ef46bb227e617.jpg)

### 业务导向且支持开发过程的测试

​	这一象限的测试通常称作功能测试或验收测试。验收测试确保用户故事的验收条件得到满足。在开发一个用户故事之前，就应该写好验收测试，采取完美的自动化形式。

​	像验收条件一样，验收测试可以测试系统特性的方方面面，包括其功能（functionality）、容量（capacity）、易用性（usability）、安全性（security）、可变性（modifiability）和可用性（availability）等。关注于功能正确性的验收测试称作功能验收测试，而非功能验收测试归于图中的第四象限。如果对于功能与非功能测试有模糊认识且常常搞不清它们的区别，请参见技术导向且评估项目的象限。

​	时新的自动化功能测试工具，比如 Cucumber、JBehave、Concordion以及Twist，都旨在把测试脚本与实现分离，以达到这种理想状态，并提供某种机制方便地将二者进行同步。在这种方式下，由用户来写测试脚本是可能的，而开发人员和测试人员则要致力于实现这些测试脚本。

**自动化验收测试**

自动化验收测试有很多很有价值的特性。

* 它加快了反馈速度，因为开发人员可以通过运行自动化测试，来确认是否完成了一个特定需求，而不用去问测试人员。
* 它减少了测试人员的工作负荷。
* 它让测试人员集中精力做探索性测试和高价值的活动，而不是被无聊的重复性工作所累。
* 这些验收测试也是一组回归测试套件。当开发大型应用或者在大规模团队中工作时，由于采用了框架或许多模块，对应用某一部分的更改很可能会影响其余特性，所以这一点尤其重要。
* 就像行为驱动开发（BDD）所建议的那样，使用人类可读的测试以及测试套件名，我们就可以从这些测试中自动生成需求说明文档。像Cucumber和Twist这样的工具，就是为让分析人员可以把需求写成可执行的测试脚本而设计的。这种方法的好处在于通过验收测试生成的需求文档从来都不会过时，因为每次构建都会自动生成它。



​	自动化验收测试的维护成本可能很高。如果写得不好，它们会使交付团队付出极大的维护成本。由于这个原因，有些人不建议创建大而复杂的自动化测试集合，比如James Shore[插图][dsyXYv]就持这种观点。然而，通过使用正确的工具，并遵循好的实践原则，完全可以大大降低创建并维护自动化验收测试的成本，从而令收益大于付出。

​	同样需要记住的是，并不是所有的东西都需要自动化。对于某些方面的测试来说，用手工方法做更好。易用性测试及界面一致性等方面很难通过自动化测试来验证。尽管有时候测试人员会将自动操作作为探索性测试的一部分，比如初始化环境、准备测试数据等，但探索性测试不可能被完全自动化。很多情况下，手工测试就足够了，甚至优于自动化测试。总之，我们倾向于将自动化验收测试限于完全覆盖Happy Path的行为，并仅覆盖其他一些极其重要的部分。

​	更多关于何时做自动化的内容，参见BrianMarick的文章“When Should a Test Be Automated? ”[90NC1y]。

​	然而，大多数界面测试工具与界面本身总是紧紧耦合在一起，其后果就是，一旦界面改变了（哪怕是一点儿），测试也会被破坏。这会导致很多的假阳性，因为你会经常遇到这种情况，即测试被破坏的原因并不是应用功能不正确，而只是由于某个复选框的名字被修改了。在这种情况下，仅将这些测试与应用程序同步就会消耗相当多的时间，但却不会交付任何价值。最好不断地问自己这样一个问题：“我的验收测试有多少次是由于真正的缺陷才失败的，有多少次是因为需求的变更才失败的？”

​	有几种方法来解决这个问题。一种方法是在测试与用户界面之间增加一个抽象层，以便减少因用户界面变更而导致的工作量。另一种方法是通过公共API来运行这些验收测试，这些API就在用户界面层之下，而且用户界面也会使用这些API来执行真正的操作（当然，这就要求你的UI层不应该包含业务逻辑）。我们并不是说不需要用户界面测试了，而是说可以将用户界面本身的测试减少到最低限度，而不是减少对业务逻辑的测试。这样，验收测试套件可以直接验证业务逻辑。

### 技术导向且支持开发过程的测试

​	这些自动化测试单独由开发人员创建并维护。这些自动化测试单独由开发人员创建并维护。有三种测试属于这一分类：单元测试、组件测试和部署测试。

​	单元测试不应该访问数据库、使用文件系统、与外部系统交互。或者说，单元测试不应该有系统组件之间的交互。这会让单元测试运行非常快，因此可以得到更早的反馈，了解自己的修改是否破坏了现有的任何功能。这些测试也应该覆盖系统中每个代码分支路径（最少达到80%）。

​	然而，为了获得高速度，也有一些代价，即可能会错过应用系统不同部分之间交互时产生的一些缺陷。比如，通常某些对象（面向对象编程中的概念）或者应用程序数据的生命周期是非常不同的。此时，只有当对更大范围的代码进行测试时才能发现一些缺陷，这些缺陷出现的原因是你没有正确处理某些数据或对象的生命周期。

### 业务导向且评价项目的测试

​	这类手工测试可以验证我们实际交付给用户的应用软件是否符合其期望。这并不只是验证应用是否满足需求规格说明，还验证需求规格说明的正确性。我们从来没有接触或听说过哪个项目的需求规格说明在开发项目之前就已经写得非常完美。不可避免地，每当在现实生活中有用户试用一个应用，他们就会发现这个应用还有改进的空间。用户会破坏一些东西，因为他们会尝试执行从前没有人执行过的一系列操作。用户也会抱怨，认为应用程序应该能更好地帮助他们完成他们要经常做的工作。他们可能会从应用软件里得到一些启发，发现某种新功能能帮助他们更好地完成工作。软件开发是一个很自然的迭代过程，它建立在一个有效的反馈环之上，而我们却骗自己是否有其他方式来预见它。

​	一种非常重要的面向业务且评价项目的测试是演示。在每个迭代结束时敏捷开发团队都向用户演示其开发完成的新功能。

​	探索性测试被James Bach描述为一种手工测试，他说：“执行测试的同时，测试人员会积极地控制测试的设计并利用测试时获得的信息设计新的更好的测试。”

​	易用性测试是为了验证用户是否能很容易地使用该应用软件完成工作。在开发过程当中很容易发现问题，甚至那些定义软件需求的非技术人员也能轻易发现问题。因此，易用性测试是验证应用程序是否能交付价值给用户的最终测试。

### 技术导向且评价项目的测试

​	验收测试分为两类：功能测试和非功能测试。非功能测试是指除功能之外的系统其他方面的质量，比如容量、可用性、安全性等。

​	这类测试（用于检查这类验收条件是否都被满足了）和运行这类测试的工具可能与特定于功能验收条件的测试和工具有很大不同。这类测试常常需要很多的资源，比如需要比较特殊的环境来运行测试，并且可能需要专业知识来建立和实现测试，另外它们还通常需要花更长时间来运行（无论这些测试是否是自动化测试）。因此，这类测试的实现一般会比较靠后。即使所有非功能测试都被自动化了，与功能验收测试相比，其运行频率也会更低一些，而且很可能是在部署流水线的最后阶段进行。

### 测试替身

​	自动化测试的一个关键是在运行时用一个模拟对象来代替系统中的一部分。这样，应用程序中被测试的那部分与系统其他部分之间的交互可以被严格地掌控，从而更容易确定应用程序中这一特定部分的行为。这样的模拟对象常常就是mock、stub和dummy等。

* 哑对象（dummy object）是指那些被传递但不被真正使用的对象。通常这些哑对象只是用于添充参数列表。
* 假对象（fake object）是可以真正使用的实现，但是通常会利用一些捷径，所以不适合在生产环境中使用。一个很好的例子是内存数据库。
* 桩（stub）是在测试中为每个调用提供一个封装好的响应，它通常不会对测试之外的请求进行响应，只用于测试。
* spy是一种可记录一些关于它们如何被调用的信息的桩。这种形式的桩可能是记录它发出去了多少个消息的一个电子邮件服务。
* 模拟对象（mock）是一种在编程时就设定了它预期要接收的调用。如果收到了未预期的调用，它们会抛出异常，并且还会在验证时被检查是否收到了它们所预期的所有调用。

## 现实中的情况与应对策略

### 新项目

​	新项目有机会实现我们在本书中所描述的理想国。此时，变化的成本比较低，通过建立一些相对简单的基本规则，并创建一些相对简单的测试基础设施，就可以很顺利地开始你的持续集成之旅。在这种情况下，最重要的事情就是一开始就要写自动化验收测试。为了能做到这一点，你需要：

* 选择技术平台和测试工具；
*  建立一个简单的自动化构建；
* 制定遵守INVEST原则[即独立的（Independent）、可协商的（Negotiable）、有价值的（Valuable）、可估计的（Estimable）、小的（Small）且可测试的（Testable）]的用户故事[ddVMFH]及考虑其验收条件。

然后就可以严格遵守下面的流程：

* 客户、分析师和测试人员定义验收条件；
* 测试人员和开发人员一起基于验收条件实现验收测试的自动化；
* 开发人员编码来满足验收条件；
* 只要有自动化测试失败，无论是单元测试、组件测试还是验收测试，开发人员都应该把它定为高优先级并修复它。



​	当然，必须让团队的每个人（包括客户和项目经理在内）都接受这种做法。我们曾看到过一些项目取消这种做法，因为客户觉得写自动化验收测试花费了太多的时间。假如客户真的愿意以牺牲自动化验收测试套件的质量为代价达到快速将软件推向市场的目标，那么，作出这样的决定也无可厚非。当然，其后果也应该非常明显啦。

### 项目进行中

​	引入自动化测试最好的方式是选择应用程序中那些最常见、最重要且高价值的用例为起点。这就需要与客户沟通，以便清楚地识别真正的业务价值是什么，然后使用测试来做回归，以防止功能被破坏。基于这些沟通，你应该能把那些Happy Path的测试自动化，用于覆盖高价值的场景。

### 遗留系统

​	这种遗留系统的特点在于：代码通常没有标准组件化，结构比较差。所以修改系统某部分的代码却影响了另一部分代码的事情经常发生。此时，通常比较有效的策略是在测试结束后仔细地验证系统的状态。如果时间来得及，你可以再测试一下这个用户故事的Alternate Path。最后，你还可以写更多的验收测试来检查一些异常条件，或防御一些常见的失效模式（failure mode），或防止不良的副作用。

​	切记，只写那些有价值的自动化测试就行。基本上，可以将应用程序分成两部分。一部分是实现系统功能的具体代码，另一部分则是在这些代码之下，为实现系统功能提供支撑的框架代码。

### 集成测试

​	你可以利用写一般验收测试的方式来写集成测试。通常来说，集成测试应该在两种上下文中运行：首先是被测试的应用程序使用其真正依赖的外部系统来运行时，或者是使用由外部服务供应商所提供的替代系统；其次是应用程序运行于你自己创建的一个测试用具（test harness）之上，而且这些测试用具也是代码库的一部分。

* 在测试环境中使用一个“防火墙”将该应用程序与外部系统隔离开来，而在开发过程中，越早这么做越好。当外部系统不可用时，这也是测试应用程序行为的一个好方法
* 在应用程序中使用一组配置信息，让其与外部系统的模拟版本进行交互。



​	在理想情况下，服务提供商会提供一个复制版的测试服务，除了性能以外，它可以提供与真正的服务完全相同的行为。你可以在此之上进行测试。然而，在现实世界中，你常常需要开发一个测试用具。比如当：

* 外部系统还没有开发完成，但接口已经提前定义好了（此时你需要有心理准备，因为这些接口很可能会发生变化）
* 外部系统已经开发完了，但是还不能为了测试而部署它，或者用于测试目的的外部系统运行太慢，或缺陷太多，无法支持正常自动化测试的运行；
* 虽然有测试系统，但它的响应具有不确定性，从而导致无法对自动化测试结果进行验证（比如，某个股票市场的实时数据）；
* 外部系统很难安装或者需要通过用户界面进行手工干预；
* 自动化持续集成系统需要承担的工作量太大且其所需要的服务水平太高，远不是一个仅用于做手工探索性测试的轻量级测试环境所能承受或提供的。



每当增加一个外部系统集成点时，项目风险就会增加，集成风险如下。

* 测试服务是否准备好了？它是否能正常运行？
*  外部服务供应商是否有足够的资源和人力来回答我们遇到的问题、修改缺陷，添加我们提出的一些定制化功能？
* 我们是否能直接访问真实的生产环境，以便验证外部系统是否满足我们的容量要求或可用性要求？
* 外部服务提供的API是否很容易与我们自己开发应用软件时所采用的技术进行集成，我们的团队是否需要某些专业技能才能使用这些API？
* 是否要编写并维护我们自己的测试服务？
* 当外部系统的响应与我们所期望的行为不一致时，我们自己的应用程序是否能够正确地处理？

## 流程

​	如果团队成员之间的沟通不畅，写验收测试的成本可能很高，甚至成为一种乏味的体力活。很多项目依靠测试人员来检查收到的需求，遍历所有可能的场景，并设计复杂的测试脚本，作为后续工作的参照。这个流程的产物[插图]会让客户进行审批。批准后，测试人员就会依此来测试。

​	我们可以在该流程中的几个点做一些极简单的优化。最好的解决方案就是在每个迭代开始时，召集所有的项目干系人开个会。假如没有做迭代式开发，那么就在某个用户故事开始开发的前一周召开这样的会议。让客户、分析人员、测试人员坐在一起，找到最高优先级的测试场景。像Cucumber、JBehave、Concordion和Twist这类工具让你能在一个文本编辑器中用自然语言写验收条件，然后再写代码让这些验收条件变成可执行的测试，并且如果对这些测试代码进行重构，它们也会更新相应的测试规范。

​	另一种方法是为测试创立一种DSL（Domain-SpecificLanguage，领域专属语言），并用这种DSL来书写验收条件。

​	这些验收测试以及测试目标的简短描述就可以成为开发人员开发用户故事的起点。测试人员和开发人员在开发前应该尽早一起讨论这些验收测试。这会让开发人员更好地了解用户故事，并理解最重要的场景是什么样的。与开发完用户故事之后再沟通相比，这会大大减少开发人员和测试人员之间的反馈循环，有助于减小遗漏功能的几率，并有助于减少缺陷。

**管理待修复缺陷列表**

​	如果已经有一个待修复缺陷列表了，那么非常重要的一件事情就是将其可视化，让开发团队的每个人都认识到缩短待修复缺陷列表的责任。尤其当构建常常失败时，仅仅显示验收测试成功与否是不够的，还要显示测试通过的数量、失败的数量以及被忽略掉的测试数量，而且要放在比较显眼的位置。这样，可以让团队都关注这些问题。

​	还一种处理缺陷的方法，那就是像对待功能特性一样来对待缺陷。毕竟，修复缺陷和开发新功能一样，都需要花时间和精力。因此，客户可以将某个缺陷与要开发的新功能进行对比，得出它们的相对优先级。比如，一个出现概率很小的缺陷，只会影响少量用户，而且还有一个已知的临时解决方案，那么修复它的重要性可能要低于那些可以为用户带来收入的新功能。至少，我们可以把缺陷分为严重（critical）、阻塞（blocker）、中（medium）和低（low）四个级别。要想找到更全面的评估方法，我们可能还要考虑缺陷发生的频率，对用户的影响是什么，以及是否有临时解决方案等。

​	根据这种分类方式，就能在待修复缺陷列表中根据优先级将缺陷与用户故事按相同方式来排序，并可将二者一起放置。这样，除了可以避免“这是新功能，还是缺陷”的争论以外，还能一眼就看清楚还有多少工作要做，并相应地调整其优先级。低优先级的缺陷将被放在待修复缺陷列表中靠后的位置，就像对待低优先级的用户故事一样。客户也常常会选择不修复某些缺陷。因此，将缺陷和新特性一起放在待修复缺陷列表中也是管理它们的一种合乎逻辑的方法。