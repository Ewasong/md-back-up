---
title: DevOps
date: 2021-06-10 10:57:43
tags:
---

# 持续交付: 发布可靠软件的系统方法

## 引言

​	部署流水线以持续集成过程为其理论基石，从本质上讲，它是采纳持续集成原理后的自然结果。

​	部署流水线的目标有三个。首先，它让软件构建、部署、测试和发布过程对所有人可见，促进了合作。其次，它改善了反馈，以便在整个过程中，我们能够更早地发现并解决问题。最后，它使团队能够通过一个完全自动化的过程在任意环境上部署和发布软件的任意版本。

## 一些常见的发布反模式

### 反模式: 手工部署软件

​	这种反模式的特征如下。

* 有一份非常详尽的文档，该文档描述了执行步骤及每个步骤中易出错的地方。
* 以手工测试来确认该应用程序是否运行正确。
* 在发布当天开发团队频繁地接到电话，客户要求解释部署为何会出错。
* 在发布时，常常会修正一些在发布过程中发现的问题。
* 如果是集群环境部署，常常发现在集群中各环境的配置都不相同，比如应用服务器的连接池设置不同或文件系统有不同的目录结构等。
* 发布过程需要较长的时间（超过几分钟）。
* 布结果不可预测，常常不得不回滚或遇到不可预见的问题。
* 发布之后凌晨两点还睡眼惺忪地坐在显示器前，绞尽脑汁想着怎么让刚刚部署的应用程序能够正常工作。



​	相反，随着时间的推移，部署应该走向完全自动化，即对于那些负责将应用程序部署到开发环境、测试环境或生产环境的人来说，应该只需要做两件事：（1）挑选版本及需要部署的环境，（2）按一下“部署”按钮。对于套装软件的发布来说，还应该有一个创建安装程序的自动化过程。

* 如果部署过程没有完全自动化，每次部署时都会发生错误。唯一的问题就是“该问题严重与否”而已。即便使用良好的部署测试，有些错误也很难追查。
* 如果部署过程不是自动化的，那么它就既不可重复也不可靠，就会在调试部署错误的过程中浪费很多时间。
* 手动部署流程不得不被写在文档里。可是文档维护是一项复杂而费时的任务，它涉及多人之间的协作，因此文档通常要么是不完整的，要么就是未及时更新的，而把一套自动化部署脚本作为文档，它就永远是最新且完整的，否则就无法进行部署工作了。
* 自动部署本质上也是鼓励协作的，因为所有内容都在一个脚本里，一览无遗。要读懂文档通常需要读者具备一定的知识水平。然而在现实中，文档通常只是为执行部署者写的备忘录，是难以被他人理解的。
* 以上几点引起的一个必然结果：手工部署过程依赖于部署专家。如果专家去度假或离职了，那你就有麻烦了。
* 尽管手工部署枯燥且极具重复性，但仍需要有相当程度的专业知识。若要求专家做这些无聊、重复，但有技术要求的任务则必定会出现各种我们可以预料到的人为失误，同时失眠，酗酒这种问题也会接踵而至。然而自动化部署可以把那些成本高昂的资深高技术人员从过度工作中解放出来，让他们投身于更高价值的工作活动当中。
* 对手工部署过程进行测试的唯一方法就是原封不动地做一次（或者几次）。这往往费时，还会造成高昂的金钱成本，而测试自动化的部署过程却是既便宜又容易。
* 另外，还有一种说法：自动化过程不如手工过程的可审计性好。我们对这个观点感到很疑惑。对于一个手工过程来说，没人能确保其执行者会非常严格地遵循文档完成操作。只有自动化过程是完全可审核的。有什么会比一个可工作的部署脚本更容易被审核的呢？
* 每个人都应该使用自动化部署过程，而且它应该是软件部署的唯一方式。这个准则可以确保：在需要部署时，部署脚本就能完成工作。在本书中我们会提到多个原则，而其中之一就是“使用相同的脚本将软件部署到各种环境上”。如果使用相同的脚本将软件部署到各类环境中，那么在发布当天需要向生产环境进行部署时，这个脚本已经被验证过成百上千次了。如果发布时出现任何问题的话，你可以百分百地确定是该环境的具体配置问题，而不是这个脚本的问题。

### 反模式: 开发完成之后才向类生产环境部署

​	在这一模式下，当软件被第一次部署到类生产环境（比如试运行环境）时，就是大部分开发工作完成时，至少是开发团队认为“该软件开发完成了”。这种模式中，经常出现下面这些情况。

* 如果测试人员一直参与了在此之前的过程，那么他们已在开发机器上对软件进行了测试。
* 只有在向试运行环境部署时，运维人员才第一次接触到这个新应用程序。在某些组织中，通常是由独立的运维团队负责将应用程序部署到试运行环境和生产环境。在这种工作方式下，运维人员只有在产品被发布到生产环境时才第一次见到这个软件。
* 有可能由于类生产环境非常昂贵，所以权限控制严格，操作人员自己无权对该环境进行操作，也有可能环境没有按时准备好，甚至也可能根本没人去准备环境。
* 开发团队将正确的安装程序、配置文件、数据库迁移脚本和部署文档一同交给那些真正执行部署任务的人员，而所有这些都没有在类生产环境或试运行环境中进行过测试
* 开发团队和真正执行部署任务的人员之间的协作非常少。



​	以下这些事情会使与发布相关的问题恶化。

* 假如一个应用程序是全新开发的，那么第一次将它部署到试运行环境时，可能会非常棘手。
* 发布周期越长，开发团队在部署前作出错误假设的时间就越长，修复这些问题的时间也就越长。
* 交付过程被划分到开发、DBA、运维、测试等部门的那些大型组织中，各部门之间的协作成本可能会非常高，有时甚至会将发布过程拖上“地狱列车”。此时为了完成某个部署任务（更糟糕的情况是，为了解决部署过程中出现的问题），开发人员、测试人员和运维人员总是高举着问题单（不断地互发电子邮件）。
* 开发环境与生产环境差异性越大，开发过程中所做的那些假设与现实之间的差距就越大。虽然很难量化，但我敢说，如果在Windows系统上开发软件，而最终要部署在Solaris集群上，那么你会遇到很多意想不到的事情。
* 如果应用程序是由用户自行安装的（你可能没有太多权限来对用户的环境进行操作），或者其中的某些组件不在企业控制范围之内，此时可能需要很多额外的测试工作。



​	我们的对策就是将测试、部署和发布活动也纳入到开发过程中，让它们成为开发流程正常的一部分。这样的话，当准备好进行系统发布时就几乎很少或不会有风险了，因为你已经在很多种环境，甚至类生产环境中重复过很多次，也就相当于测试过很多次了。

### 反模式：生产环境的手工配置管理

* 多次部署到试运行环境都非常成功，但当部署到生产环境时就失败。
* 集群中各节点的行为有所不同。例如，与其他节点相比，某个节点所承担的负载少一些，或者处理请求的时间花得多一些。
* 运维团队需要较长时间为每次发布准备环境。
* 系统无法回滚到之前部署的某个配置，这些配置包括操作系统、应用服务器、关系型数据库管理系统、Web服务器或其他基础设施设置。
* 不知道从什么时候起，集群中的某些服务器所用的操作系统、第三方基础设施、依赖库的版本或补丁级别就不同了。
* 直接修改生产环境上的配置来改变系统配置。



​	本书描述的关键实践之一就是配置管理，其责任之一就是让你能够重复地创建那些你开发的应用程序所依赖的每个基础设施。这意味着操作系统、补丁级别、操作系统配置、应用程序所依赖的其他软件及其配置、基础设施的配置等都应该处于受控状态。你应该具有重建生产环境的能力，最好是能通过自动化的方式重建生产环境。虚拟化技术在这一点上可能对你有所帮助。

​	你应该完全掌握生产环境中的任何信息。这意味着生产环境中的每次变更都应该被记录下来，而且做到今后可以查阅。部署失败经常是因为某个人在上次部署时为生产环境打了补丁，但却没有将这个修改记录下来。实际上，不应该允许手工改变测试环境、试运行环境和生产环境，而只允许通过自动化过程来改变这些环境。

​	应用软件之间通常会有一些依赖关系。我们应该很容易知道当前发布的是软件的哪个版本。

​	发布可能是一件令人兴奋的事情，也可能变成一件累人而又沉闷的工作。几乎在每次发布的最后都会有一些变更，比如修改数据库的登录账户或者更新所用外部服务的URL。我们应该使用某种方法来引入此类变更，以便这些变更可以被记录并测试。这里我们再次强调一下，自动化是关键。变更首先应该被提交到版本控制系统中，然后通过某个自动化过程对生产环境进行更新。

## 如何实现目标

​	我们来调整一下目标，即找到可以以一种高效、快速、可靠的方式交付高质量且有价值的软件的方法。

* 自动化。如果构建、部署、测试和发布流程不是自动化的，那它就是不可重复的。由于软件本身、系统配置、环境以及发布过程的不同，每次做完这些活动以后，其结果可能都会有所不同。由于每个步骤都是手工操作，所以出错的机会很大，而且无法确切地知道具体都做了什么。这意味着整个发布过程无法得到应有的控制来确保高质量。常常说软件发布像是一种艺术，但事实上，它应该是一种工程学科。
* 频繁做。如果能够做到频繁发布，每个发布版本之间的差异会很小。这会大大减少与发布相关的风险，且更容易回滚。频繁发布也会加快反馈速度，而客户也需要它。本书很多内容都聚焦于如何尽快得到对软件及其相关配置所做变化的反馈，这包括其环境、部署过程及数据等。



​	对于频繁地自动化发布来说，反馈是至关重要的。下面关于反馈的三个标准是很有用的：

* 无论什么样的修改都应该触发反馈流程；
* 反馈应该尽快发出；
* 交付团队必须接收反馈，并依据它作出相应的行动。

### 每次修改都应该触发反馈流程

​	一个可工作的软件可分成以下几个部分：可执行的代码、配置信息、运行环境和数据。如果其中任何一部分发生了变化，都可能导致软件的行为发生变化。所以我们要能够控制这四部分，并确保任何修改都会被验证。

​	什么是反馈流程？它是指完全以自动化方式尽可能地测试每一次变更。根据系统的不同，测试会有所不同，但通常至少包括下面的检测。

* 建可执行代码的流程必须是能奏效的。这用于验证源代码是否符合语法。
* 软件的单元测试必须是成功的。这可以检查应用程序的行为是否与期望相同。
* 软件应该满足一定的质量标准，比如测试覆盖率以及其他与技术相关的度量项。
* 软件的功能验收测试必须是成功的。这可以检查应用是否满足业务验收条件，交付了所期望的业务价值。
* 软件的非功能测试必须是成功的。这可以检查应用程序是否满足用户对性能、有效性、安全性等方面的要求。
* 软件必须通过了探索性测试，并给客户以及部分用户做过演示。这些通常在一个手工测试环境上完成。此时，产品负责人可能认为软件功能还有缺失，我们自己也可能发现需要修复的缺陷，还要为其写自动化测试来避免回归测试。



### 必须尽快接收反馈

​	实现这样的部署流水线是需要大量资源的，尤其是当有了全面的自动化测试套件之后。部署流水线的关键目的之一就是对人力资源利用率的优化：我们希望将人力释放出来做更有价值的工作，将那些重复性的体力活交给机器来做。

​	对于整个流水线中的提交（commit）阶段，其测试应具有如下特征。

* 运行速度快。
* 尽可能全面，即75%左右的代码库覆盖率。只有这样，这些测试通过以后，我们才对自己写的软件比较有信心。
* 如果有测试失败的话，就表明应用程序有严重问题，无论如何都不能发布。也就是说，像检查界面元素的颜色是否正确这类测试不应该包含在这个测试集合当中。
* 尽可能做到环境中立。这个环境没必要和生产环境一模一样，可以相对简单廉价一些。

​	

相对而言，提交阶段之后的测试一般有如下这些特点。

* 它们通常运行更慢一些，所以适合于并行执行。
* 即使某些测试有可能失败，但在某种场合下，我们还是会发布应用程序。比如某个即将发布的版本有一个不稳定的修复，会导致其性能低于预先定义的标准，但有时我们还是会决定发布这个版本。
* 它们的运行环境应该尽可能与生产环境相同。除了测试功能以外，它同时还会对部署过程以及对生产环境的任何修改进行测试。



​	这种方法的基础之一就是快速的反馈。为了确保对变更的快速反馈，我们就要注意开发软件的流程，特别是如何使用版本控制系统和如何组织代码。开发人员应该频繁提交代码到版本控制系统中，像管理大规模团队或分布式团队那样，将代码分成多个组件。

### 交付团队必须接收反馈并作出反应

​	想要能够根据反馈来调整行动，就要对信息进行广播。使用一个大且可视的仪表盘（并非一定要电子的），或者其他通知机制对于确保反馈送达到每一个人是极为重要的。这个仪表盘应该随处可见，而且至少每个团队的屋中都应放置一个。当然，如果最后没有引发什么改进行动，反馈也就没有什么用了。因此，这就要求纪律性和计划性。当需要采取行动时，整个团队有责任停下他们手中的事情，来决定接下来采取哪些行动。在完成此事之后，团队才能继续自己的工作

### 这个流程可以推广吗

​	略

## 收效

### 授权团队

​	我们常常看到在不同的环境中运行着不同的版本，而不同角色的人工作在其上。能够轻松地将任意版本的软件部署到任意环境的能力能带来很多好处。

* 测试人员可以选择性地部署较旧的版本，以验证新版本上的功能变化。
* 技术支持人员可以自己部署某个已发布的版本，用于重现缺陷。
* 技术支持人员可以自己部署某个已发布的版本，用于重现缺陷。
* 发布方式也变成一键式的了。

### 减少错误

​	我们可能从方方面面将错误引入到软件中。最初委托制作这个软件的人就可能出错，比如提出错误的需求。需求分析人员可能将需求理解错了，开发人员也可能写出了到处都是缺陷的程序，而我们在这里要说的错误是指由不良好的配置管理引入到生产环境的错误。我们将在第2章详细阐述配置管理。现在，让我们想一下到底需要哪些东西才可以让一个应用程序正确地工作，当然肯定需要正确版本的代码，除此之外呢？我们还需要数据库模式（schema）的正确版本、负载均衡器的正确配置信息、应用程序所依赖的Web服务（比如用于查阅价格的Web服务）的正确URL等。当我们说配置管理时，指的是让你识别并控制一组完整信息的流程与机制，这些信息包括每个字节和比特。

### 缓解压力

​		现在，让我们来设想一下。如果接下来的发布只需要单击一下按钮，而且只需要等上几分钟，甚至几秒钟内就可以完成。另外，假如发生了非常糟糕的事情，你只要花上相同的几分钟或几秒钟的时间就可以把刚部署的内容恢复到从前的老样子。再大胆地设想一下，假如你的软件发布周期总是很短，那么当前生产环境中的版本与新版本之间的差异应该非常小。如果上述设想都是事实的话，那么发布的风险一定会大大降低，那种将职业生涯压注在发布是否成功的不爽感觉也将大大减少。

### 部署的灵活性	

​	只要需要，就可以让软件运行在任何环境中”的能力使我们和客户对我们随时管理所有版本发布过程充满信心。

### 多加练习，使其完美

​	只有一种环境可以有多变性，那就是开发环境。开发人员应该在自己的开发环境中自行生成二进制文件，而不需要在别处构建生成。所以，对这种开发环境的部署流程要求太严格是没有必要的。虽然我们能够做到在开发人员的开发机器上也以同样的方式部署软件，但实际上对开发环境的部署没有必要严格要求

## 候选发布版本

​	大多数软件发布方法都是在其流程的最后阶段才能识别出可以发布的那些版本。当说到与跟踪（tracking）相关的工作时，这是有些意义的。在写作本书时，Wikipedia上对开发阶段的描述中将“候选发布版本”作为这一流程中的一个步骤进行了说明，如图1-2所示。我们的观点则稍有不同。

![](https://pic.imgdb.cn/item/60c1a418844ef46bb289ead2.jpg)

​	根据我们的经验，直到开发阶段之后才做测试的话，无疑会降低应用程序的质量。最好还是在缺陷被引入时，就发现并将其解决。发现得越晚，修复的成本越高。开发人员已经不记得他们是在实现哪个功能时把缺陷引入的，而这个功能很可能已经发生了变化。直到最后才做测试，这通常意味着没有足够的时间真正地修复缺陷，或者只能修复其中很少的一部分缺陷。因此，我们想尽早地发现并修正这些缺陷，最好是在将其提交到代码库之前。

**每次提交代码都可能产生一个可发布的版本**

​	我们应该频繁做集成，事实上应该在每次提交修改后都做集成。持续集成这个实践将频繁集成发挥到了极至，而“持续集成”转变了软件开发过程。持续集成会及时检测到任何一次破坏已有系统或者不满足客户验收测试的提交。一旦发生这种情况，团队就立刻去修复问题（这是持续集成的首要规则）。如果能够坚持这个实践，那么软件会一直处于可用状态。假如测试足够全面，且运行测试的环境与生产环境足够相近（甚至相同）的话，那么可以说，你的软件一直处于可发布状态。

##  软件交付的原则

### 为软件的发布创建一个可重复且可靠的过程

​	可重复性和可靠性来自于以下两个原则：

（1）几乎将所有事情自动化；

（2）将构建、部署、测试和发布软件所需的东西全部纳入到版本控制管理之中。

归根结底，软件部署包括三件事：

* 提供并管理你的软件所需要的运行环境，这包括硬件配置、所依赖的软件、基础设施以及所需的外部服务；
* 将你的应用程序的正确版本安装在其之上；
*  配置你的应用程序，包括它所需要的任何数据以及状态。

### 将几乎所有事情自动化

​	看上去自动化发布流程是一个令人怯步的工作，而手工完成这些事情显得更容易一些。如果我们只需要做一次这样的工作，通过手工执行的确非常容易，但如果需要执行这个流程数十次的话，就不是那么容易的事了，而且很可能在第三次或第四次的时候就感觉不那么容易了。

### 把所有的东西都纳入版本控制

​	将构建、部署、测试和发布的整个过程中所需的东西全部保存在某种形式的版本存储库中，包括需求文档、测试脚本、自动化测试用例、网络配置脚本、部署脚本、数据库创建、升级、回滚和初始化脚本、应用程序所依赖的软件集合的配置脚本、库文件、工具链以及技术文档等。所有这些内容都应该受到版本控制，与每次构建结果相关的版本都应可以识别。也就是说，这些变更集（change set）都应该有唯一标识，比如构建号、版本控制库中的版本号。

### 提前并频繁地做让你感到痛苦的事

​	这是最通用的原则，也是最有启发性的。在软件交付这个领域，它可能是最有用的一个启发式原则，我们所说的一切都可以归结到这一点上。集成通常是一个非常痛苦的过程。如果你的项目也是如此，那么就应该在每次有人提交代码后立刻进行集成，而且应该从项目一开始就这么做。如果测试是发布之前最痛苦的事情，那么就别拖到最后，而是应从项目一开始就不断地进行测试。

### 内建质量

​	越早发现缺陷，修复它们的成本越低。如果在没有提交代码到版本控制之前，我们就能发现并修复缺陷的话，代价是最小的。

​	“内建质量”还有另外两个推论

* 测试不是一个阶段，当然也不应该开发结束之后才开始。如果把测试留在最后，那就为时晚矣，因为可能根本没有时间修复那些刚被发现的问题。
* 测试也不纯粹或主要是测试人员的领域。交付团队的每个人都应该对应用程序的质量负责。

### “DONE”意味着“已发布”

​	我们认为，一个特性只有交到用户手中才能算“DONE”。这是持续部署实践背后的动机之一。

​	对于一些敏捷交付团队来说，“DONE”意味着软件已经部署到生产环境上。对于软件项目来说，这是一种理想状态。将其作为衡量是否完成的标准，并不总是合适的。对于那些第一次发布的软件系统来说，它可能需要一段时间才能达到“让外部用户真正从该软件身上获益”的状态。因此，我们可以暂且退让一步，只要某个功能在类生产环境上向客户代表做过演示，并且客户代表试用之后就认为是完成了。

​	根本没有“已经完成了80%”这一说法。任何事情要么是完成了，要么就是没完成。我们可以估计尚未完成的某件工作还需要多少工作量，但仅仅是估计而已。

### 交付过程是每个成员的责任

​	很多项目都是开发者开发后将困难转交给测试者，而测试者又在发布时将困难转嫁到运维团队。当出现问题时，人们花费大量的时间来修复错误，并用同等的时间来互相指责。

​	假如你工作于小规模团队或相对独立的部门，也许对发布软件所需的资源有绝对的控制能力。如果是这样，当然非常好啦。假如不是这样的话，你就要有思想准备，很可能需要长期的艰苦工作才能打破不同角色之间的壁垒。

​	这是DevOps运动的核心原则之一。DevOps运动的焦点和我们这本书的目标一致：为了更加快速且可靠地交付有价值的软件，鼓励所有参与软件交付整个过程中的人进行更好的协作。

### 持续改进

​	应用程序的首次发布只是其生命周期中的第一个阶段。随着应用程序的演进，更多的发布将会接踵而来。更重要的是，你的交付过程应该随之不断演进。

​	在交付过程中，整个团队应该定期地坐在一起，召开回顾会议，反思一下在过去一段时间里哪些方面做得比较好，应该继续保持，哪些方面做得不太好，需要改进，并讨论一下如何改进。每个改进点都应该有一个人负责跟踪，确保相应的改进活动能够被执行。当下一次团队坐在一起时，他们应该向大家汇报这些活动的结果。这就是众所周知的戴明环：计划-执行-检查-处理（PDCA）。

​	关键在于组织中的每个人都要参与到这个过程当中。如果只在自己所在角色的内部进行反馈环，而不是在整个团队范围内进行的话，就必将产生一种“顽疾”：以整体优化为代价的局部优化，最终导致互相指责。

# 配置管理

## 引言

​	假如项目中有良好的配置管理策略，那么你对下列所有问题的回答都应该是“YES”。

* 你能否完全再现你所需要的任何环境（这里的环境包括操作系统的版本及其补丁级别、网络配置、软件组合，以及部署在其上的软件应用及其配置）？
* 你能很轻松地对上述内容进行增量式修改，并将修改部署到任意一种或所有环境中吗？
* 你能否很容易地看到已被部署到某个具体环境中的某次修改，并能追溯到修改源，知道是谁做的修改，什么时候做的修改吗？
* 你能满足所有必须遵守的规程章则吗？
* 是否每个团队成员都能很容易地得到他们所需要的信息，并进行必要的修改呢？这个配置管理策略是否会妨碍高效交付，导致周期时间增加，反馈减少呢？



在本章中，我们将讨论三个问题。

* 为管理应用程序的构建、部署、测试和发布过程做好准备。我们从两个方面解决这个问题：对所有内容进行版本控制；管理依赖关系。
* 管理应用软件的配置信息。
* 整个环境的配置管理，这包括应用程序所依赖的软件、硬件和基础设施。另外还有环境管理背后的原则，包括操作系统、应用服务器、数据库和其他COTS（商业现货）软件。

## 使用版本控制

​	本质上来讲，版本控制系统的目的有两个。首先，它要保留每个文件的所有版本的历史信息，并使之易于查找。这种系统还提供一种基于元数据（这些元数据用于描述数据的存储信息）的访问方式，使元数据与某个单个文件或文件集合相链接。其次，它让分布式团队（无论是空间上不在一起，还是不同的时区）可以愉快地协作。

* 对于我们开发的应用软件，某个特定的版本是由哪些文件和配置组成的？如何再现一份与生产环境一模一样的软硬件环境？
* 什么时候修改了什么内容，是谁修改的，以及为什么要修改？因此，我们很容易知道应用软件在何时出了错，出错的过程，甚至出错的原因。

### 对所有内容进行版本控制

​	每个与所开发的软件相关的产物都应被置于版本控制之下。开发人员不但要用它来管理和控制源代码，还要把测试代码、数据库脚本、构建和部署脚本、文档、库文件和应用软件所用的配置文件都纳入到版本控制之中，甚至把编译器以及工具集等也放在里面，以便让新加入项目的成员可以很容易地从零开始工作。

​	为了重新搭建测试环境和生产环境，将所有必需的信息保存起来也是很重要的。这里必需的信息包括应用程序所需的支撑软件的配置信息、构成对应系统环境的操作系统配置信息、DNS区域文件和防火墙配置等。你至少要将那些用于重新创建应用程序的安装文件和安装环境所必需的所有信息保存在版本控制存储库之中。

​	我们的目标是能够随时获取软件在整个生命周期中任意时间点的文件状态。这样我们就可以选择从开发环境至生产环境整个环节中的任意时间点，并将系统恢复到该时间点的状态。我们甚至可以把开发团队所需的开发环境配置也置于版本控制中，如此一来，团队中的每个成员都能够轻松使用完全相同的设置。分析人员应该把需求文档保存到版本控制存储库中。测试人员也应该将自己的测试脚本和过程保存在版本控制存储库中。项目经理则应该将发布计划、进度表和风险日志也保存在这里。总之，每个成员都应该将与项目相关的任何文件及其修订状态保存在版本控制存储库之中。

​	除了存储源代码和配置信息，很多项目还将其应用服务器、编译器、虚拟机以及其他相关工具的二进制镜像也放在版本控制库中。

​	但我们并不推荐将源代码编译后得到的二进制文件也纳入到版本控制中，有以下几个理由。首先，它们通常比较大，而且（与编译程序不同）会让存储所需要的空间快速膨胀，因为我们每次签入代码，在编译和自动提交测试通过后，都会生成新的二进制文件。其次，如果有自动化构建系统，那么只要重新运行构建脚本，就可以利用源代码重新生成需要的二进制文件。这样的话，根本没有必要把这类二进制产物放在版本控制库中。请注意，我们并不推荐在同一个自动化构建过程中进行重复编译。因为如果需要二进制产物的话，我们只要通过构建系统把源代码再重新打包生成一次就可以了。最后，我们使用修订版本号来标识产品的版本。如果我们把构建生成的二进制文件也储存在版本控制库中，那么在存储库中的一个版本就会有两个不同的源，一个是源代码，另一个是二进制文件。尽管看上去这有点儿含糊，但创建部署流水线（本书的主要议题之一）时就显得极为重要了。

**版本控制：“删除”的自由**

​	版本控制库中包含每个文件的每一个版本，它的好处就是：可以随时删除你认为不必要的文件。只要有版本控制系统，对于“是否可以删除这个文件？”这个问题，你可以轻松地回答“Yes”。如果事实证明你的删除决定是错的，只要从早期版本中把它再找回来就行了。

​	这种“自由删除”是维护大型配置集合向前迈进的重要一步。保证大型团队能高效工作的关键就在于一致性和良好的组织性。“打破陈规”的能力使团队可以勇敢地尝试新的想法或实现方式，提高代码质量。

### 频繁提交代码到主干

​	首先，只有频繁提交代码，你才能享受版本控制所带来的众多好处，比如能够轻松地回滚到最近某个无错误的版本。

​	如果你频繁提交，其他人可以看到你的修改且可与之交互，你也可以清楚地知道你的修改是否破坏了应用程序，而且每次合并工作的工作量会一直很小，易于管理。

​	有些人解决这个两难问题的方法是，在版本控制系统中为新功能建立单独的分支。到某个时间点后，如果这些修改的质量令人满意，就将其合并到主干。这类似于“两阶段提交”。实际上，有些版本控制系统就是以这种方式工作的。

​	然而，我们对这样的做法持反对意见，除非是第14章提到的那三种例外情况。在这一点上有一些争议，尤其是在使用ClearCase以及相似工具的用户中。我们认为，这种方法存在以下几个问题。

* 它违背了持续集成的宗旨，因为创建分支的做法推迟了新功能的整合，只有当该分支被合并时才可能发现集成问题。
* 如果多个开发者同时分别创建了多个分支，问题会成指数增加，而合并过程也会极其复杂。
* 尽管有一些好用的工具有自动合并功能，但它们无法解决语义冲突。例如，某人在一个分支上重命名了一个方法，而另一个人在另一分支上对该方法增加了一次调用。
* 它让重构代码库变得非常困难，因为分支往往涉及多个文件，会让合并变得更加困难。



​	一个更好的解决方案是尽量使用增量方式开发新功能，并频繁且有规律地向版本控制系统提交代码。这会让软件能一直保持在集成以后的可工作状态。而且，你的软件会一直被测试，因为每次提交代码时，持续集成服务器就会从代码主干上运行自动测试。这会减小因重构引起的大规模合并导致冲突的可能性，确保集成问题能够被及时发现，此时修复这些问题的成本很低，从而提高软件开发质量。

​	为了确保提交代码时不破坏已有的应用程序，有两个实践非常有效。

* 一是在提交代码之前运行测试套件。这个测试套件应该是一个快速运转（一般少于10分钟）且相对比较全面的测试集合，以验证你没有引入明显的回归缺陷。很多持续集成服务器都提供名为“预测试提交”（pretested commit）的功能，让你在提交之前可以在类生产环境中执行这些测试。
* 增量式引入变化。我们建议每完成一个小功能或一次重构之后就提交代码。如果能正确地使用这一技术，你每天最少可以提交一次，通常能达到每天提交多次。如果你还未习惯于这种技术的话，肯定会以为是“天方夜谭”。但我们向你保证，这种技术能够带来相当高效的软件交付过程。

### 使用意义明显的提交注释

​	当构建失败以后，你知道是谁破坏了构建，以及他为什么破坏了构建。当然，这并不是唯一原因。很多时候，提交人没有写足够的描述信息，其原因通常是由于正在抓紧解决某个非常复杂的问题。我们可能常常遇到下面的场景。

* 你发现了一个缺陷，结果追溯到一行相当晦涩的代码。
* 你通过查看版本控制系统的日志，查找放入这行代码的人，以及他是什么时候放入的。
* 可是，放入这行代码的人去度假或者回家了，而他写的提交注释只有简单的几个字，即“已修复令人费解的缺陷”。
* 为了修复这个缺陷，你修改了这行晦涩代码。
* 但是却把其他功能破坏了。
* 你只能再花几个小时的时间，让软件恢复到可工作状态。

## 依赖管理

### 外部库文件管理

​	那么是否一定要把外部依赖库文件放在版本控制库中呢？其实，放与不放，各有利弊。如果放了，那我们更容易将软件的版本与正确的库文件版本相关联，但它也可能使源代码库的体积更大，并且签出时间也会变长

### 组件管理

​	将整个应用软件分成一系列的组件进行开发（小型应用除外）是个不错的实践。这能让某些变更的影响范围比较小，从而减少回归缺陷。另外，它还有利于重用，使大项目的开发过程更加高效

## 软件配置管理

### 配置与灵活性

​	灵活性也是有代价的。

​	对于软件灵活性的期望常常导致一种反模式，即“终极配置”，而这种反模式常被表述为对一个软件项目的需求。如果做得好，它没有什么坏处，但是如果搞不好的话，它会毁了一个项目。

​	根据我们的经验，“修改配置信息的风险要比修改代码的风险低”这句话就是个错觉。就拿“停止一个正在运行的应用系统”这个需求来说，通过修改代码或修改配置都很容易办到。如果使用修改源代码的方式，可以有多种方式来保证质量，比如编译器会帮我们查语法错误，自动化测试可以拦截很多其他方面的错误。然而，大多数配置信息是没有格式检查，且未经测试的。在大多数系统中，没有什么机制能阻止我们将一个URI“http://www.asciimation.co.nz/”改为“this is not a validURI”。大多数系统只有在运行时，才能发现这样的更改，此时用户不是惊喜地看到ASCII版的Star Wars，而是看到一堆系统异常报告，因为URI这个类无法解析“this is not a valid URI”。

在构建高度可配置的软件的道路上有很多陷阱，而最糟糕的可能莫过于下面这些。

* 经常导致分析瘫痪，即问题看上去很严重，而且很棘手，以至于团队花费很多时间思考如何解决它，但最终还是无法解决。
* 系统配置工作变得非常复杂，以至于抵消了其在灵活性上带来的好处。更有甚者，可能在配置灵活性上花费的成本与定制开发的成本相当。



​	可配置的软件并不总是像它看起来那么便宜。更好的方法几乎总是先专注于提供具有高价值且可配置程度较低的功能，然后在真正需要时再添加可配置选项。

*  在生成二进制文件时，构建脚本可以在构建时引入相关的配置，并将其写入新生成的二进制文件。
* 在打包时将配置信息一同打包到软件中，比如在创建程序集，以及打包ear或gem时。
* 在安装部署软件程序时，部署脚本或安装程序可以获取必要的配置信息，或者直接要求用户输入这些配置信息。
* 软件在启动或运行时可获取配置。



​	一般来说，我们并不赞同在构建或打包时就将配置信息植入的做法，而是应使用相同二进制安装包向所有的环境中部署，以确保这个发布的软件就是那个被测试过的软件。根据这一个原则，我们可以推出：在相临的两次部署之间，任何变更都应该作为配置项被捕获和记录，而不应该在编译或打包时植入。

### 配置的分类

* 在生成二进制文件时，构建脚本可以在构建时引入相关的配置，并将其写入新生成的二进制文件。
* 在打包时将配置信息一同打包到软件中，比如在创建程序集，以及打包ear或gem时
* 在安装部署软件程序时，部署脚本或安装程序可以获取必要的配置信息，或者直接要求用户输入这些配置信息。
* 软件在启动或运行时可获取配置。



​	一般来说，我们并不赞同在构建或打包时就将配置信息植入的做法，而是应使用相同二进制安装包向所有的环境中部署，以确保这个发布的软件就是那个被测试过的软件。根据这一个原则，我们可以推出：在相临的两次部署之间，任何变更都应该作为配置项被捕获和记录，而不应该在编译或打包时植入。

​	通常来说，能够在部署时对软件进行配置是非常重要的，这样就可以告诉应用程序在哪儿能找到所需服务，比如数据库、邮件服务器或外部系统。比如，当应用程序运行时的配置信息被存储在数据库中，你可能要在部署应用程序时将数据库的连接参数传入，使应用程序启动时可以从数据库中取到这些信息。

​	如果你有权限完全控制生产环境，就通常能让部署脚本自行获取这些配置并提供给应用。对于套装软件来说，安装包中通常都有默认的配置信息。做软件测试时，我们仍需要用某种方法在部署过程中修改某些配置信息。

​	当然，我们还可能要在启动或运行应用程序时修改某些配置。在系统启动时，我们可以通过命令参数或环境变量等形式提供配置信息。另外，你还可以使用同样的机制来做运行时的配置，比如注册表设置、数据库、配置文件，或者使用外部配置服务（比如通过SOAP或REST风格的接口访问）。

### 应用程序的配置管理

​	在管理应用程序的配置这个问题上，需要回答三个问题。

（1）如何描述配置信息？

（2）部署脚本如何存取这些配置信息？

（3）在环境、应用程序，以及应用程序各版本之间，每个配置信息有什么不同？



​	小提示：不要把密码签入到版本控制系统中，也不要把它硬编码到应用程序中。要是让运维人员知道你这么做，一定会让你卷铺盖走人的。所以，别给他们这样的机会。如果你坚持要将密码存在某处而不是自己记住的话，可以试着把它加密后放在用户主目录下。

​	这种方法的另一种极糟的使用方式是，将应用程序某一层上的密码保存在需要访问它的那层代码或文件系统中。实际上，用户在部署时应该每次都手工输入密码。对于多层应用系统来说，有多种方式来处理验证问题。比如，你可以使用证书、目录服务，或者一个单点登录系统。

**获取配置信息**

​	管理配置最有效的方法是让所有的应用程序通过一个中央服务系统得到它们所需要的配置信息。

**为配置项建模**

​	每个配置都是一个元组，所以应用程序的配置信息由一系列的元组构成。然而，这些元组及其值取决于三方面，即应用程序、该应用程序的版本、该版本所运行的环境（例如开发环境、用户验收测试环境、性能测试环境、试运行环境或生产环境）。

​	下面列举了一些在对配置信息建模时需要考虑的用例。

* 新增一个环境（比如一个新的开发工作站，或性能测试环境）。在这种情况下你要能为这个配置应用的新环境指定一套新的配置信息。
* 创建应用程序的一个新版本，通常需要添加一些配置设置，删除一些过时的配置设置。此时应该确保在部署新版本时，可以使用新的配置设置，但是一旦需要回滚时，还能够使用旧版本的配置设置。
* 将新版本从一个环境迁移到另一个环境，比如从测试环境挪到试运行环境。此时应该确保新环境上的新配置项都有效，而且为其设置了正确的值。
* 重定向到一个数据库服务器。应该只需要简单地修改所有配置设置，就能让它指向新的数据库服务器。
* 通过虚拟化技术管理环境。应该能够使用虚拟技术管理工具创建某种指定的环境，并且配置好所有的虚拟机。你也许需要将这种虚拟环境中的配置信息作为某特定版本的应用软件在虚拟环境中的标准配置信息。

**系统配置的测试**

​	与应用程序和构建脚本一样，配置设置也需要测试。对于系统配置测试来说，包括以下两部分。

​	一是要保证配置设置中对外部服务的引用是良好的。比如，作为部署脚本的一部分，我们要确保消息总线（messaging bus）在配置信息中所指定的地址已启动并运行，并确保应用程序所用的模拟订单执行服务在功能测试环境中能够正常工作。最起码，要保证能够与所有的外部服务相连通。如果应用程序所依赖的任何部分没有准备好，部署或安装脚本都应该报错，这相当于配置设置的冒烟测试。

​	二是当应用程序一旦安装好，就要在其上运行一些冒烟测试，以验证它运行正常。对于系统配置的测试，我们只要测试与配置有关的功能就可以了。在理想情况下，一旦测试结果与预期不符，这些测试应该能够自动停止软件的运行，并显示安装或部署失败。

### 跨应用的配置管理

​	大中型组织中，通常会同时管理很多应用程序，而软件配置管理的复杂性也会大大增加。这类组织中一般都会有遗留系统，而且很可能某个遗留系统的配置项让人很难搞得清楚明白。这种情况下，最重要的任务之一就是，要为每个应用程序维护一份所有配置选项的索引表，记录这些配置保存在什么地方，它们的生命周期是多长，以及如何修改它们。

​	如果应用程序之间有依赖关系，部署有先后次序的话，实时存取配置信息的能力就特别重要。很容易因配置信息设置不当而浪费很多时间，甚至导致整套服务无法正常运行，而这类问题是极难诊断的。

### 管理配置信息的原则

* 在应用程序的生命周期中，我们应该在什么时候注入哪类配置信息。是在打包的时候，还是在部署或安装的时候？是在软件启动时，还是在运行时？要与系统运维和支持团队一同讨论，看看他们有什么样的需求。
* 应该总是通过自动化的过程将配置项从保存配置信息的存储库中取出并设置好，这样就能很容易地掌握不同环境中的配置信息了。
* 配置系统应该能依据应用、应用软件的版本、将要部署的环境，为打包、安装以及部署脚本提供不同的配置值。每个人都应该能够非常容易地看到当前软件的某个特定版本部署到各种环境上的具体配置信息。
* 对每个配置项都应用明确的命名习惯，避免使用晦涩难懂的名称，使其他人不需要说明手册就能明白这些配置项的含义
* DRY（Don't Repeat Yourself）原则。定义好配置中的每个元素，使每个配置元素在整个系统中都是唯一的，其含义绝不与其他元素重叠。
* 最少化，即配置信息应尽可能简单且集中。除非有要求或必须使用，否则不要新增配置项。
* 避免对配置信息的过分设计，应尽可能简单。
* 保测试已覆盖到部署或安装时的配置操作。检查应用程序所依赖的其他服务是否有效，使用冒烟测试来诊断依赖于配置项的相关功能是否都能正常工作。

## 环境管理

​	没有哪个应用程序是孤岛。每个应用程序都依赖于硬件、软件、基础设施以及外部系统才能正常工作。

 	环境的配置和应用程序的配置同样重要。例如，如果应用程序需要用到消息总线，那么只有正确配置了这个消息总线，应用程序才能正常工作。操作系统的配置也同样重要。

​	这里把不良环境管理可能带来的问题总结如下。

* 配置信息的集合非常大；
*  一丁点变化就能让整个应用坏掉，或者严重降低它的性能。
*  一旦系统出现问题，需要资深人员花费不确定的时间来找到问题根源并修复它。
* 很难准确地再现那些手工配置的环境，因此给测试验证带来很大困难。
* 很难维护一个不使用配置信息的环境，因此维护这种环境下的行为也很难，尤其是不同的节点有不同的配置时。



​	重现环境的能力是非常必要的，原因如下。

* 可以避免知识遗失问题。比如某人离职且无法与他联系上，但只有他明白某个配置项所代表的意思。一旦这类配置项不能正常工作，通常都意味着较长的停机时间。这是一个很大却不必要的风险。
* 修复某个环境可能需要花费数小时的时间。所以，我们最好能在可预见的时间里重建环境，并将它恢复到某个已知的正常状态下。
* 创建一个和生产环境相同的测试环境是非常必要的。对于软件配置而言，测试环境应该和生产环境一模一样。这样，配置问题更容易被在早期发现。



​	需要考虑的环境配置信息如下：

* 环境中各种各样的操作系统，包括其版本、补丁级别以及配置设置；
* 应用程序所依赖的需要安装到每个环境中的软件包，以及这些软件包的具体版本和配置；
* 应用程序正常工作所必需的网络拓扑结构；
* 应用程序所依赖的所有外部服务，以及这些服务的版本和配置信息；
* 现有的数据以及其他相关信息（比如生产数据库）。



​	其实高效配置管理策略的两个基本原则是：

（1）将二进制文件与配置信息分离；

（2）将所有的配置信息保存在一处。如果应用了这两个基本原则，你就能将“在系统不停机的情况下，创建新环境、升级系统部分功能或增加新的配置项”等工作变成一个简单的自动化过程。

​	当评估第三方产品或服务时，应该问自己如下问题。

* 我们可以自行部署它吗？
* 可以自行部署它吗？
* 如何使它适应我们的自动化部署策略？

### 环境管理的工具

​	在以自动化方式管理操作系统配置的工具中，Puppet和CfEngine是两个代表。使用这些工具，你能以声明方式来定义一些事情，如哪些用户可以登录你的服务器，应该安装什么软件，而这些定义可以保存在版本控制库中。运行在系统中的代理（agent）会从版本控制库中取出最新的配置，更新操作系统以及安装在其之上的软件。对于应用了这些工具的系统来说，根本没必要登录到服务器上去操作，所有的修改都可能通过版本控制系统来发起，因而你也能够得到每次变化的完整记录，即谁在什么时候做了什么样的修改。

​	虚拟化技术也可以提高环境管理过程的效率。不必利用自动化过程从无到有地创建一个新环境，你可以轻易地得到一份环境副本，并把它作为一个基线保存起来。

### 变更过程管理

​	最后要强调的是，对环境的变更过程进行管理是必要的。应该严格控制生产环境，未经组织内部正式的变更管理过程，任何人不得对其进行修改。

​	如果配置管理流程比较好的话，对于下面的问题，你的回答都应该是肯定的。

* 是否仅依靠保存于版本控制系统中的数据（除了生产数据），就可以从无到有重建生产系统？
* 是否可以将应用程序回滚到以前某个正确的状态下？
* 是否能确保在测试、试运行和正式上线时以同样的方式创建部署环境？



​	如果回答是否定的，那么你的组织正处于风险之中。我们建议为下面的内容制定出一个保存基线和控制变更的策略:

* 应用程序的源代码、构建脚本、测试、文档、需求、数据库脚本、代码库以及配置文件；
* 用于开发、测试和运维的工具集；
* 用于开发、测试和生产运行的所有环境；
* 与应用程序相关的整个软件栈，包括二进制代码及相关配置；
* 在应用程序的整个生产周期（包括构建、部署、测试以及运维）的任意一种环境上，与该应用程序相关联的配置。

# 持续集成

## 引言

​	持续集成背后的思想是：既然经常对代码库进行集成对我们有好处，为什么不随时做集成呢？就集成而言，“随时”意思是指每当有人提交代码到版本控制库时。

## 实现持续集成

### 准备工作

​	在开始做持续集成之前，你需要做三件事情。

**版本控制**

​	与项目相关的所有内容都必须提交到一个版本控制库中，包括产品代码、测试代码、数据库脚本、构建与部署脚本，以及所有用于创建、安装、运行和测试该应用程序的东西。

**自动化构建**

​	你要能在命令行中启动构建过程。无论是通过命令行程序启动IDE来构建应用程序，然后再运行测试，还是使用多个复杂的构建脚本通过互相调用的方式来完成都行，但无论采用哪种机制，必须满足如下条件：人和计算机都能通过命令行自动执行应用的构建、测试以及部署过程。

* 要能在持续集成环境中以自动化的方式来执行整个构建过程，以便出现问题时能够审计。
* 应将构建脚本与代码库同等对待。应该对它进行测试，并不断地重构，以使它保持整洁且容易理解，而集成开发环境自动生成的构建过程基本上无法做到这一点。项目越复杂，这项工作就越重要。
* 使理解、维护和调试构建过程更容易，并有利于和运维人员更好地协作。

**团队共识**

​	持续集成不是一种工具，而是一种实践。它需要开发团队能够给予一定的投入并遵守一些准则，需要每个人都能以小步增量的方式频繁地将修改后的代码提交到主干上，并一致认同“修复破坏应用程序的任意修改是最高优先级的任务”。

### 一个基本的持续集成系统

​	现在的持续集成工具其安装和运行都极其简单。有几个开源工具可供选择，比如Hudson和受人尊敬的CruiseControl家族（CruiseControl、CruiseControl.NET和CruiseControl.rb）。其中，Hudson和CruiseControl.rb的启动和运行尤其简单。CruiseControl.rb是很轻量级的，而且掌握一些Ruby知识的人很容易对它进行扩展。Hudson的插件很多，这使它可以与构建和部署领域中的很多工具集成。

​	在此书编写之际，还有两种商业化持续集成服务器为小团队提供了免费版本，它们是ThoughtWorks Studios开发的Go以及JetBrains的TeamCity。其他流行的商业化持续集成服务器还包括Atlassian的Bamboo和Zutubi的Pulse。高端的发布管理以及构建加速系统还有UrbanCode的AntHillPro、ElectricCloud的ElectricCommander，以及IBM的BuildForge，它们都可以用于简单的持续集成。还有很多其他产品，完整列表可参见CI feature matrix[插图]。

​	第一次在持续集成工具上执行构建时，你很可能发现在运行持续集成工具的机器上缺少一些必需的软件和设置。这是一个独一无二的学习机会，请将接下来你所做的工作全部记录下来，并放在自己项目的知识共享库中。你应该花上一些时间将应用程序所依赖的所有软件和配置项提交到版本控制系统中，并将重建全新环境的整个活动变成一个自动化的过程。

​	一旦准备好要提交最新修改代码时，请遵循如下步骤。

* 查看一下是否有构建正在运行。如果有的话，你要等它运行完。如果它失败了，你要与团队中的其他人一起将其修复，然后再提交自己的代码。
* 一旦构建完成且测试全部通过，就从版本控制库中将该版本的代码更新到自己的开发环境上
* 在自己的开发机上执行构建脚本，运行测试，以确保在你机器上的所有代码都工作正常。当然你也可以利用持续集成工具中的个人构建功能来完成这一步骤。
* 如果本地构建成功，就将你的代码提交到版本控制库中。
* 然后等待包含你的这次提交的构建结果。
* 如果这次构建失败了，就停下手中做的事，在自己的开发机上立即修复这个问题，然后再转到步骤（3）。
* 如果这次构建成功，你可以小小地庆祝一下，并开始下一项任务。

## 持续集成的前提条件

### 频繁提交

​	对于持续集成来说，我们最重要的工作就是频繁提交代码到版本控制库。每天至少应该提交几次代码。

### 创建全面的自动化测试套件

​	如果没有一系列全面的自动化测试，那么构建成功只意味着应用程序能够编译并组装在一起。虽然对于某些团队来说，这已经是非常大的一个进步了，但是，假如能够有一定程度的自动化测试，会让你更有信心说：“我们的应用程序是可以工作的。”

​	单元测试用于单独测试应用程序中某些小单元的行为（比如一个方法、一个函数，或一小组方法或函数之间的交互）。

​	组件测试用于测试应用程序中几个组件的行为。与单元测试一样，它通常不必启动整个应用程序，但有可能需要连接数据库、访问文件系统或其他外部系统或接口（这些可以使用“桩”，即stub技术）。

​	验收测试的目的是验证应用程序是否满足业务需求所定义的验收条件，包括应用程序提供的功能，以及其他特定需求，比如容量、有效性、安全性等。验收测试最好采用将整个应用程序运行于类生产环境的运作方式。当然，验收测试的运行时间也较长。一个验收测试套件连续运行一整天是很平常的事儿。

###  保持较短的构建和测试过程

* 大家在提交代码之前不愿意在本地环境进行全量构建和运行测试，导致构建失败的几率越来越大。
* 持续集成过程需要花太长时间，从而导致再次运行构建时，该构建会包含很多次提交，所以很难确定到底是哪次提交破坏了本次构建。
* 大家提交的频率会变少，因为每运行一次构建和测试，都要坐在那儿等上一阵子。



​	理想情况下，提交前的预编译和测试过程，以及持续集成服务器上的编译和测试过程应该都能在几分钟内结束。我们认为，十分钟是一个极限了，最好是在五分钟以内，九十秒内完成是最理想的。十分钟对于那些惯于操作小项目的人来说，应该算是比较长的时间了，但对于那些经历过需要花数小时的编译的老前辈来说，却是非常短的时间。这段时间长度应该恰好能泡杯茶，快速聊几句，看一眼邮件，或伸展一下身体。

​	有很多技术可以帮助你减少构建时间。首先要考虑的事情是让测试执行得更快。

​	有时候需要将测试分成几个阶段，首先将其分成两个阶段。第一个阶段用于编译软件，运行所有类级别的单元测试，并创建用于部署的二进制文件。这个阶段叫做“提交阶段”。

​	第二个阶段应该利用第一个阶段所生成的二进制文件进行验收测试、集成测试。假如你有性能测试的话，也要一并运行。利用现代持续集成工具，很容易创建这种分阶段的构建流程，它们能够同时运行多个任务，并将运行结果收集在一起，以便很容易看到运行状态和结果。

​	另外，有时候把一个简单的冒烟测试套件加入到提交阶段，也是非常有用的。这个冒烟测试套件应该执行一些简单的验收和集成测试，用于确保最常见的功能没有被破坏。假如这些基本功能被破坏了，就能得到很快的反馈。

### 管理开发工作区

​	对于保证开发人员的开发效率与明晰思路来说，开发环境的管理是特别重要的。当开发人员刚开始新任务时，应该总是从一个已知正确的状态开始。他们应该能够运行构建、执行自动化测试，以及在其可控的环境上部署其开发的应用程序，通常是在他们自己的开发机上。只有在特殊的情况下，才应使用共享环境开发。在本地开发环境上运行应用程序时，应确保所使用的自动化过程与持续集成环境中的一致，与测试环境中也是一样的，且生产环境中也是一样的。

## 使用持续集成软件

​	持续集成工具最基本的功能就是轮询版本控制系统，查看是否有新的版本提交，如果有的话，则签出最新版本的软件，运行构建脚本来编译应用程序，再运行测试，最后将运行结果告知你。

### 基本操作

​	本质上，持续集成软件包括两个部分。第一部分是一个一直运行的进程，它每隔一定的时间就执行一个简单的工作流程。第二部分就是提供展现这个流程运行结果的视图，通知你构建和测试成功与否，让你可以找到测试报告，拿到生成的安装文件等。

### 铃声和口哨

​	这种可视化的唯一缺点就是，如果开发团队和客户在一起工作的话（对于大多数敏捷项目来说，的确是这样的），构建失败（流程中很自然的一部分）可能被认为是应用程序质量存在问题的信号。事实也正是如此，每次构建失败都表明发现了一个问题，但如果没有发现的话，它就会被带到生产环境中。然而，有时候很难向客户解释“为什么构建总是失败”。我们曾遇到过好几次这种状况，其中有一次构建失败持续了很长时间，期间我们与客户进行了一些艰难的对话，但唯一能做的事情就是让它高度可视化，并努力工作，向客户解释这样做的好处。当然，最佳解决方案是努力工作，让构建一直成功。

​	你还可以在构建过程中对源代码进行一些分析工作，包括分析测试覆盖率、重复代码、是否符合编码标准、圈复杂度，以及其他一些健康指标，并将结果显示在每个构建的总结报告中。你也可以运行一些程序来生成与代码相对应的对象模型图或数据库结构图。所有这些都是可视化的一部分。

​	持续集成前身:

* 每日构建。
* 增加自动化测试。
* rolling builds”过程，即持续不断地运行构建过程，而不是在夜间定时执行批处理过程。

## 必不可少的实践

### 构建失败之后不要提交新代码

​	续集成的第一忌就是明知构建已经失败了，还向版本控制库中提交新代码。如果构建失败，开发人员应该尽快找出失败的原因，并修复它。

### 提交前在本地运行所有的提交测试，或者让持续集成服务器完成此事

​	正如之前提过的，我们希望每次提交都可以产生一个可发布的候选版本。任何人以任何形式公布某个东西之前，都会检查一下自己的工作成果，而候选版本也是一个发行物，所以每次提交前也要做一下检查。

​	我们希望提交过程是一件轻量级的事儿，这样就可以每隔二十分钟左右提交一次了，但它也应该是一件非常严肃的事儿，这样在每次提交之前，我们都会停下来，仔细想一想是否应该提交。提交前在本地运行一次提交测试，就是做一下健全性检查（sanity check）。它也让我们能确信新增的代码的确是按期望的方式运行的。

​	你可能会问：“为什么在提交前还要运行本地提交测试呢？这样的话，我们的编译和提交测试不是要运行两次了吗？”这么做，有两个理由。

* 如果在你根据版本控制进行更新之前，其他人已经向版本控制库中提交了新代码，那么你的变更与那些新代码合并后，可能会导致测试失败。如果你自己先在本地更新代码并运行提交测试的话，假如有问题，就会在本地提前发现，提前修复，从而不会令持续集成服务器上的构建失败，不至于影响其他人及时提交。
* 在提交时经常犯的错误是，忘记提交那些刚刚新增加的东西到存储库中。如果遵守这个流程的话，当本地构建成功，而持续集成系统中的提交阶段失败了的话，那么你就知道要么是由于别人与你同时提交了代码，要么就是你遗漏了一部分类或配置文件没有提交到版本控制系统中。



​	很多现代持续集成服务器还提供这样一种功能，名字叫做预测试提交（pretestedcommit），也称为个人构建（personal build）或试飞构建（preflight build）。使用这种特性，就不必自己进行提交，持续集成服务器将拿到你的本地变更，把它放在构建网格中运行提交测试。一旦构建成功通过，持续集成服务器就替你将变更提交到版本控制库中。如果构建失败的话，它会通知你哪里出错了。

​	Pulse、TeamCity和 ElectricCommander这三种持续集成服务器都已经提供了这个功能。如果使用分布式版本控制系统的话，这个实践就更容易了，因为你可以将代码存储到自己的本地代码控制库中，而无需提交到团队的中央版本控制库中。通过这种方式，一旦个人构建失败的话，很容易通过创建补丁的方式将自己提交的修改搁置，恢复到你刚刚提交到持续集成服务器的那个版本上，将构建修复，再把补丁放上去。

### 等提交测试通过后再继续工作

​	在提交代码时，做出了这一代码的开发人员应该监视这个构建过程，直到该提交通过了编译和提交测试之后，他们才能开始做新任务。在这短短几分钟的提交阶段结束之前，他们不应该离开去吃午饭或开会，而应密切注意构建过程并在提交阶段完成的几秒钟内了解其结果。

### 回家之前，构建必须处于成功状态

​	不建议你工作到很晚来修复失败的构建，而是希望你有规律地尽早提交代码，给自己足够的时间处理可能出现的问题。或者，你可以第二天再提交。很多有经验的开发人员在下班前一小时内不再提交代码，而是把它作为第二天早上的第一件事情。

​	如果位于印度的团队破坏构建后就回家了，那么位于伦敦的团队一整天的工作都会受到极大影响。同样，如果位于伦敦的团队做了同样的事，那么位于美国的同事可能在接下来的八小时之内一直在他们的阴影下工作。

### 时刻准备着回滚到前一个版本

​	如果某次提交失败了，无论采取什么样的行动，最重要的是尽快让一切再次正常运转起来。如果无法快速修复问题，无论什么原因，我们都应该将它回滚到版本控制库中前一个可工作的版本上，之后再在本地环境中修复它。

### 在回滚之前要规定一个修复时间

​	建立一个团队规则：如果因某次提交而导致构建失败，必须在十分钟之内修复它。如果在十分钟内还没有找到解决方案的话，就将其回滚到版本控制系统中前一个好的版本。如果团队能够忍受，有时候也可以延长一段时间来修复它。

### 不要将失败的测试注释掉

​	一旦你决定执行前面所说的规则，有些开发人员常常为了能够提交代码，而将那些失败的测试注释掉。这种冲动是可以理解的，但却是无法被容忍的一种错误行为。那些已经成功运行了一段时间的测试失败时，失败的原因可能很难找。

### 为自己导致的问题负责

​	假如提交代码后，你写的测试都通过了，但其他人的测试失败了，构建结果还是会失败。通常这意味着，你引入了一个回归缺陷。你有责任修复因自己的修改导致失败的那些测试。在持续集成环境中这是理所当然的，但可惜的是，在很多项目中事实并不是这样的。

### 测试驱动的开发

​	关于测试驱动开发的话题超出了本书的范围。但值得注意的是，和所有其他此类实践一样，测试驱动开发也需要纪律性和实效性。在这里我们向读者推荐两本相关的书藉：Steve Freeman和Nat Pryce合著的Growing Object-Oriented Software,Guided by Tests,以及Gerard Meszaros写的xUnit Test Patterns:RefactoringTest Code。

## 推荐的实践

### 极限编程开发实践

​	对于任何团队，即使不采用其他实践，只用持续集成也会给项目开发带来很大改善，而若与其他实践相结合的话，它的作用会更大。尤其是，除了测试驱动开发和我们前面讲到的代码集体所有权，你还应该考虑把重构作为高效软件开发的基石。

​	重构是指通过一系列小的增量式修改来改善代码结构，而不会改变软件的外部行为。通过持续集成和测试驱动开发可以确保这些修改不会改变系统的行为，从而使重构成为可能。这样，你的团队就可以自由自在地修改代码，即使偶尔涉及较大范围的代码修改，也不用担心它会破坏系统了。这个实践也让频繁提交成为了可能，即开发人员在每次做了一个小的增量式修改后就提交代码。

### 若违背架构原则，就让构建失败

​	开发人员有时很容易忘记系统架构的一些原则。我们曾经使用过一种手段来解决这个问题，那就是写一些提交时测试，用于证明这些原则没有被破坏。

### 若测试运行变慢，就让构建失败

​	持续集成需要小步频繁提交。如果提交测试要运行很长时间的话，这种长时间的等待会严重损害团队的生产效率，他们将花费很长的时间等待构建和测试过程完成。而且，这样也无法做到频繁提交，结果会导致团队成员开始把每次要提交的内容都存在本地，而每多增加一次本地保存就会增加一些复杂性，同时也增加了与版本控制库的代码出现合并冲突的可能性，增加了引入错误的几率，最终可能导致测试失败。所有这些最终都会导致生产率下降。

​	为了让开发团队注意到快速测试的重要性，可以这样做：当某个测试运行超过一定时间后，就让这次提交测试失败。我们在上一个项目中使用的这一时间是两秒。

### 若有编译警告或代码风格问题，就让测试失败

​	编译器发出警告时，通常理由都足够充分。我们曾经用过一个比较成功的策略，即只要有编译警告，就让构建失败，但我们的开发团队常常把它叫做“纳粹代码”。这在某些场合可能有点儿苛刻，但作为强迫写好代码的一种实践，还是很有效的。你可以通过添加代码检查尽可能地强化这一技术。

​	我们成功使用过很多关于代码质量检查的开源工具，如下所示：

* Simian是一种可以识别大多数流行语言（包括纯文本）中重复代码的工具。
* JDepend是针对Java的免费版本，它有一个．NET的商业版本NDepend，它们拥有大量对设计质量进行评估的实用（和不太实用）的度量指标。
* CheckStyle可以对“烂代码”做一些检查，比如工具类中的公共构造函数、嵌套的代码块和比较长的代码行。它也能找到缺陷和安全漏洞的一些常见根源。它还很容易被扩展。FxCop是它的．NET版本。
* FindBugs是一个Java软件，它是CheckStyle的替代品，有一些相似的校验功能。

## 分布式团队

### 对流程的影响

​		对在同一时区内的分布式团队来说，持续集成流程基本是一样的。当然，你无法以实物的形式使用提交令牌。虽然有些持续集成服务器支持虚拟令牌，但它不具有人性化特点，所以当你提醒某人去修复构建时，容易导致大家的抵触心理。同时，类似“个人构建”这种功能会变得更加有用。但总地来说，流程是一样的。

​	对分布在不同时区的分布式团队来说，就需要多处理一些事情啦。如果在旧金山的团队在破坏构建以后回家了，那么，这对北京的团队可能就是个严重的阻碍。因为当旧金山的团队下班后，北京才刚上班。尽管流程没有什么变化，但不良影响会被放大。

### 集中式持续集成

​	一些功能更强大的持续集成服务器提供像“集中管理构建网格”和“高级授权机制”这种功能，用于把持续集成作为一个集中式服务，为大型分布式团队提供服务。这样的服务器让团队很容易建立自服务式的持续集成服务，而不需要自己管理硬件。它也会让运维团队将持续集成作为集中式服务，统筹服务器资源，管理持续集成和测试环境的配置，以确保这些环境的一致性以及与生产环境的相似性，还能巩固一些好的实践，比如第三方库的配置管理，预安装一些工具（用于收集代码覆盖率和质量的统一度量数据。最终，我们可以做到项目之间的统一度量数据的收集和监控，为管理者和交付团队提供程序级的代码质量监控方式。

​	虚拟化技术可以与集中式持续集成服务很好地结合，只需要单击一下按钮就能利用已保存好的基线镜像重建一个新的虚拟机。利用虚拟化技术，可以为开发团队提供一键式搭建新环境这样的自服务功能。这也可以确保构建和部署一直运行在一致的基线版的环境中。	

### 技术问题

​	当分布于世界各地的团队之间网络状况不佳时，依据选择的不同版本控制系统，团队间共享版本控制系统、构建和测试资源的做法有时候也会有很多麻烦。在持续集成运转良好时，整个团队都会有规律地提交代码。这意味着，与版本控制系统之间的交互通常保持在一个较高的合理水平上。由于提交和更新比较频繁，虽然每次交互通常都较小（甚至可以用字节来计算），劣质的通信仍会严重拖生产效率的后腿。因此，加大投入在各开发中心之间建立起足够高带宽的通信机制是非常必要的。考虑将集中式的版本控制库迁到某种分布式版本控制系统（比如Git或Mercurial）也是不错的选择。闻名知意，即使无法连接到主服务器，分布式版本控制系统也能让大家提交代码。

### 替代方法

​	如果由于某些不可克服的原因，无法再增加投入在开发中心间建立更高带宽的通信机制，各地团队还可以使用本地持续集成和测试系统（当然这不太理想），甚至在某些极端情况下，不得不用本地的版本控制系统。我们并不建议使用这种方法，但这种情况在现实中还是很有可能的。所以，我们要尽一切可能避免使用这种方法。这种方法在时间和人力上的成本都很高，而且根本无法做到团队间的共享访问和控制。

​	对于分布式团队来说，主要有两种方式来解决本地化版本控制系统的存取问题：一是将应用程序分成多个组件；二是使用那些分布式或支持多主库拓扑结构的版本控制系统。

## 分布式版本控制系统

​	DVCS（Distributed Version Control System，分布式版本控制系统）的兴起是团队合作方式的革命性改进。很多开源项目曾经使用电子邮件或论坛发帖的方式来提交补丁，而像Git和Mercurial这种工具让开发人员之间、团队之间以及分支与合并工作流时的打补丁变得极其简单。DVCS使你能够离线工作、本地提交，或在将修改提交给其他人之前把这些代码搁置起来或对其做rebase操作。DVCS的核心特性是每个仓库都包括项目的完整历史，这意味着除了团队约定之外，仓库是没有权限控制功能的。所以，与集中式系统相比，DVCS引入了一个中间层：在本地工作区的修改必须先提交到本地库，然后才能推送到其他仓库，而更新本地工作区时，必须先从其他仓库中将代码更新到本地库。

​	持续集成的以上这些替代方案可以创建高质量可工作的软件。然而，这必须满足以下条件才能成为事实。

* 有一个成员比较少，但都非常有经验提交团队。他们可以取每个补丁、照管自动化测试并确保软件的质量。
* 频繁地从分支上取被修改过的代码，以避免由于积累太多的代码使变更很难合并。如果发布的时间计划非常严格，则这个条件就非常重要，因为人们倾向于临在近发布时刻再合并，而此时的合并是极其痛苦的——这正是持续集成要解决的问题。
* 相对较少的核心开发人员，可能有一个贡献频率较低但人员较多的社区作为补充。这会让合并具有可追溯性。

## 小结

​	总之，一个好的持续集成系统是基石，在此之上你可以构建更多的基础设施：

* 一个巨大的可视化指示器，用于显示构建系统所收集到的信息，以提供高质量的反馈；
* 结果报告系统，以及针对自己测试团队的安装包；
* 为项目经理提供关于应用程序质量的数据的提供程序；
* 使用部署流水线，可以将其延展到生产环境，为测试人员和运维团队提供一键式部署系统。

# 测试策略的实现

## 引言

​	戴明14条之一就是：“停止依赖于大批量检查来保证质量的做法。改进过程，从一开始就将质量内嵌于产品之中。”

​	测试策略的设计主要是识别和评估项目风险的优先级，以及决定采用哪些行动来缓解风险的一个过程。好的测试策略会带来很多积极作用。测试会建立我们的信心，使我们相信软件可按预期正常运行。也就是说，软件的缺陷较少，技术支持所需的成本较低，客户认可度较高。测试还为开发流程提供了一种约束机制，鼓励团队采用一些好的开发实践。一个全面的自动化测试套件甚至可以提供最完整和最及时的应用软件说明文档，这个文档不仅是说明系统应该如何运行的需求规范，还能证明这个软件系统的确是按照需求来运行的。

## 测试的分类

![](https://pic.imgdb.cn/item/60c9b645844ef46bb227e617.jpg)

### 业务导向且支持开发过程的测试

​	这一象限的测试通常称作功能测试或验收测试。验收测试确保用户故事的验收条件得到满足。在开发一个用户故事之前，就应该写好验收测试，采取完美的自动化形式。

​	像验收条件一样，验收测试可以测试系统特性的方方面面，包括其功能（functionality）、容量（capacity）、易用性（usability）、安全性（security）、可变性（modifiability）和可用性（availability）等。关注于功能正确性的验收测试称作功能验收测试，而非功能验收测试归于图中的第四象限。如果对于功能与非功能测试有模糊认识且常常搞不清它们的区别，请参见技术导向且评估项目的象限。

​	时新的自动化功能测试工具，比如 Cucumber、JBehave、Concordion以及Twist，都旨在把测试脚本与实现分离，以达到这种理想状态，并提供某种机制方便地将二者进行同步。在这种方式下，由用户来写测试脚本是可能的，而开发人员和测试人员则要致力于实现这些测试脚本。

**自动化验收测试**

自动化验收测试有很多很有价值的特性。

* 它加快了反馈速度，因为开发人员可以通过运行自动化测试，来确认是否完成了一个特定需求，而不用去问测试人员。
* 它减少了测试人员的工作负荷。
* 它让测试人员集中精力做探索性测试和高价值的活动，而不是被无聊的重复性工作所累。
* 这些验收测试也是一组回归测试套件。当开发大型应用或者在大规模团队中工作时，由于采用了框架或许多模块，对应用某一部分的更改很可能会影响其余特性，所以这一点尤其重要。
* 就像行为驱动开发（BDD）所建议的那样，使用人类可读的测试以及测试套件名，我们就可以从这些测试中自动生成需求说明文档。像Cucumber和Twist这样的工具，就是为让分析人员可以把需求写成可执行的测试脚本而设计的。这种方法的好处在于通过验收测试生成的需求文档从来都不会过时，因为每次构建都会自动生成它。



​	自动化验收测试的维护成本可能很高。如果写得不好，它们会使交付团队付出极大的维护成本。由于这个原因，有些人不建议创建大而复杂的自动化测试集合，比如James Shore[插图][dsyXYv]就持这种观点。然而，通过使用正确的工具，并遵循好的实践原则，完全可以大大降低创建并维护自动化验收测试的成本，从而令收益大于付出。

​	同样需要记住的是，并不是所有的东西都需要自动化。对于某些方面的测试来说，用手工方法做更好。易用性测试及界面一致性等方面很难通过自动化测试来验证。尽管有时候测试人员会将自动操作作为探索性测试的一部分，比如初始化环境、准备测试数据等，但探索性测试不可能被完全自动化。很多情况下，手工测试就足够了，甚至优于自动化测试。总之，我们倾向于将自动化验收测试限于完全覆盖Happy Path的行为，并仅覆盖其他一些极其重要的部分。

​	更多关于何时做自动化的内容，参见BrianMarick的文章“When Should a Test Be Automated? ”[90NC1y]。

​	然而，大多数界面测试工具与界面本身总是紧紧耦合在一起，其后果就是，一旦界面改变了（哪怕是一点儿），测试也会被破坏。这会导致很多的假阳性，因为你会经常遇到这种情况，即测试被破坏的原因并不是应用功能不正确，而只是由于某个复选框的名字被修改了。在这种情况下，仅将这些测试与应用程序同步就会消耗相当多的时间，但却不会交付任何价值。最好不断地问自己这样一个问题：“我的验收测试有多少次是由于真正的缺陷才失败的，有多少次是因为需求的变更才失败的？”

​	有几种方法来解决这个问题。一种方法是在测试与用户界面之间增加一个抽象层，以便减少因用户界面变更而导致的工作量。另一种方法是通过公共API来运行这些验收测试，这些API就在用户界面层之下，而且用户界面也会使用这些API来执行真正的操作（当然，这就要求你的UI层不应该包含业务逻辑）。我们并不是说不需要用户界面测试了，而是说可以将用户界面本身的测试减少到最低限度，而不是减少对业务逻辑的测试。这样，验收测试套件可以直接验证业务逻辑。

### 技术导向且支持开发过程的测试

​	这些自动化测试单独由开发人员创建并维护。这些自动化测试单独由开发人员创建并维护。有三种测试属于这一分类：单元测试、组件测试和部署测试。

​	单元测试不应该访问数据库、使用文件系统、与外部系统交互。或者说，单元测试不应该有系统组件之间的交互。这会让单元测试运行非常快，因此可以得到更早的反馈，了解自己的修改是否破坏了现有的任何功能。这些测试也应该覆盖系统中每个代码分支路径（最少达到80%）。

​	然而，为了获得高速度，也有一些代价，即可能会错过应用系统不同部分之间交互时产生的一些缺陷。比如，通常某些对象（面向对象编程中的概念）或者应用程序数据的生命周期是非常不同的。此时，只有当对更大范围的代码进行测试时才能发现一些缺陷，这些缺陷出现的原因是你没有正确处理某些数据或对象的生命周期。

### 业务导向且评价项目的测试

​	这类手工测试可以验证我们实际交付给用户的应用软件是否符合其期望。这并不只是验证应用是否满足需求规格说明，还验证需求规格说明的正确性。我们从来没有接触或听说过哪个项目的需求规格说明在开发项目之前就已经写得非常完美。不可避免地，每当在现实生活中有用户试用一个应用，他们就会发现这个应用还有改进的空间。用户会破坏一些东西，因为他们会尝试执行从前没有人执行过的一系列操作。用户也会抱怨，认为应用程序应该能更好地帮助他们完成他们要经常做的工作。他们可能会从应用软件里得到一些启发，发现某种新功能能帮助他们更好地完成工作。软件开发是一个很自然的迭代过程，它建立在一个有效的反馈环之上，而我们却骗自己是否有其他方式来预见它。

​	一种非常重要的面向业务且评价项目的测试是演示。在每个迭代结束时敏捷开发团队都向用户演示其开发完成的新功能。

​	探索性测试被James Bach描述为一种手工测试，他说：“执行测试的同时，测试人员会积极地控制测试的设计并利用测试时获得的信息设计新的更好的测试。”

​	易用性测试是为了验证用户是否能很容易地使用该应用软件完成工作。在开发过程当中很容易发现问题，甚至那些定义软件需求的非技术人员也能轻易发现问题。因此，易用性测试是验证应用程序是否能交付价值给用户的最终测试。

### 技术导向且评价项目的测试

​	验收测试分为两类：功能测试和非功能测试。非功能测试是指除功能之外的系统其他方面的质量，比如容量、可用性、安全性等。

​	这类测试（用于检查这类验收条件是否都被满足了）和运行这类测试的工具可能与特定于功能验收条件的测试和工具有很大不同。这类测试常常需要很多的资源，比如需要比较特殊的环境来运行测试，并且可能需要专业知识来建立和实现测试，另外它们还通常需要花更长时间来运行（无论这些测试是否是自动化测试）。因此，这类测试的实现一般会比较靠后。即使所有非功能测试都被自动化了，与功能验收测试相比，其运行频率也会更低一些，而且很可能是在部署流水线的最后阶段进行。

### 测试替身

​	自动化测试的一个关键是在运行时用一个模拟对象来代替系统中的一部分。这样，应用程序中被测试的那部分与系统其他部分之间的交互可以被严格地掌控，从而更容易确定应用程序中这一特定部分的行为。这样的模拟对象常常就是mock、stub和dummy等。

* 哑对象（dummy object）是指那些被传递但不被真正使用的对象。通常这些哑对象只是用于添充参数列表。
* 假对象（fake object）是可以真正使用的实现，但是通常会利用一些捷径，所以不适合在生产环境中使用。一个很好的例子是内存数据库。
* 桩（stub）是在测试中为每个调用提供一个封装好的响应，它通常不会对测试之外的请求进行响应，只用于测试。
* spy是一种可记录一些关于它们如何被调用的信息的桩。这种形式的桩可能是记录它发出去了多少个消息的一个电子邮件服务。
* 模拟对象（mock）是一种在编程时就设定了它预期要接收的调用。如果收到了未预期的调用，它们会抛出异常，并且还会在验证时被检查是否收到了它们所预期的所有调用。

## 现实中的情况与应对策略

### 新项目

​	新项目有机会实现我们在本书中所描述的理想国。此时，变化的成本比较低，通过建立一些相对简单的基本规则，并创建一些相对简单的测试基础设施，就可以很顺利地开始你的持续集成之旅。在这种情况下，最重要的事情就是一开始就要写自动化验收测试。为了能做到这一点，你需要：

* 选择技术平台和测试工具；
*  建立一个简单的自动化构建；
* 制定遵守INVEST原则[即独立的（Independent）、可协商的（Negotiable）、有价值的（Valuable）、可估计的（Estimable）、小的（Small）且可测试的（Testable）]的用户故事[ddVMFH]及考虑其验收条件。

然后就可以严格遵守下面的流程：

* 客户、分析师和测试人员定义验收条件；
* 测试人员和开发人员一起基于验收条件实现验收测试的自动化；
* 开发人员编码来满足验收条件；
* 只要有自动化测试失败，无论是单元测试、组件测试还是验收测试，开发人员都应该把它定为高优先级并修复它。



​	当然，必须让团队的每个人（包括客户和项目经理在内）都接受这种做法。我们曾看到过一些项目取消这种做法，因为客户觉得写自动化验收测试花费了太多的时间。假如客户真的愿意以牺牲自动化验收测试套件的质量为代价达到快速将软件推向市场的目标，那么，作出这样的决定也无可厚非。当然，其后果也应该非常明显啦。

### 项目进行中

​	引入自动化测试最好的方式是选择应用程序中那些最常见、最重要且高价值的用例为起点。这就需要与客户沟通，以便清楚地识别真正的业务价值是什么，然后使用测试来做回归，以防止功能被破坏。基于这些沟通，你应该能把那些Happy Path的测试自动化，用于覆盖高价值的场景。

### 遗留系统

​	这种遗留系统的特点在于：代码通常没有标准组件化，结构比较差。所以修改系统某部分的代码却影响了另一部分代码的事情经常发生。此时，通常比较有效的策略是在测试结束后仔细地验证系统的状态。如果时间来得及，你可以再测试一下这个用户故事的Alternate Path。最后，你还可以写更多的验收测试来检查一些异常条件，或防御一些常见的失效模式（failure mode），或防止不良的副作用。

​	切记，只写那些有价值的自动化测试就行。基本上，可以将应用程序分成两部分。一部分是实现系统功能的具体代码，另一部分则是在这些代码之下，为实现系统功能提供支撑的框架代码。

### 集成测试

​	你可以利用写一般验收测试的方式来写集成测试。通常来说，集成测试应该在两种上下文中运行：首先是被测试的应用程序使用其真正依赖的外部系统来运行时，或者是使用由外部服务供应商所提供的替代系统；其次是应用程序运行于你自己创建的一个测试用具（test harness）之上，而且这些测试用具也是代码库的一部分。

* 在测试环境中使用一个“防火墙”将该应用程序与外部系统隔离开来，而在开发过程中，越早这么做越好。当外部系统不可用时，这也是测试应用程序行为的一个好方法
* 在应用程序中使用一组配置信息，让其与外部系统的模拟版本进行交互。



​	在理想情况下，服务提供商会提供一个复制版的测试服务，除了性能以外，它可以提供与真正的服务完全相同的行为。你可以在此之上进行测试。然而，在现实世界中，你常常需要开发一个测试用具。比如当：

* 外部系统还没有开发完成，但接口已经提前定义好了（此时你需要有心理准备，因为这些接口很可能会发生变化）
* 外部系统已经开发完了，但是还不能为了测试而部署它，或者用于测试目的的外部系统运行太慢，或缺陷太多，无法支持正常自动化测试的运行；
* 虽然有测试系统，但它的响应具有不确定性，从而导致无法对自动化测试结果进行验证（比如，某个股票市场的实时数据）；
* 外部系统很难安装或者需要通过用户界面进行手工干预；
* 自动化持续集成系统需要承担的工作量太大且其所需要的服务水平太高，远不是一个仅用于做手工探索性测试的轻量级测试环境所能承受或提供的。



每当增加一个外部系统集成点时，项目风险就会增加，集成风险如下。

* 测试服务是否准备好了？它是否能正常运行？
*  外部服务供应商是否有足够的资源和人力来回答我们遇到的问题、修改缺陷，添加我们提出的一些定制化功能？
* 我们是否能直接访问真实的生产环境，以便验证外部系统是否满足我们的容量要求或可用性要求？
* 外部服务提供的API是否很容易与我们自己开发应用软件时所采用的技术进行集成，我们的团队是否需要某些专业技能才能使用这些API？
* 是否要编写并维护我们自己的测试服务？
* 当外部系统的响应与我们所期望的行为不一致时，我们自己的应用程序是否能够正确地处理？

## 流程

​	如果团队成员之间的沟通不畅，写验收测试的成本可能很高，甚至成为一种乏味的体力活。很多项目依靠测试人员来检查收到的需求，遍历所有可能的场景，并设计复杂的测试脚本，作为后续工作的参照。这个流程的产物[插图]会让客户进行审批。批准后，测试人员就会依此来测试。

​	我们可以在该流程中的几个点做一些极简单的优化。最好的解决方案就是在每个迭代开始时，召集所有的项目干系人开个会。假如没有做迭代式开发，那么就在某个用户故事开始开发的前一周召开这样的会议。让客户、分析人员、测试人员坐在一起，找到最高优先级的测试场景。像Cucumber、JBehave、Concordion和Twist这类工具让你能在一个文本编辑器中用自然语言写验收条件，然后再写代码让这些验收条件变成可执行的测试，并且如果对这些测试代码进行重构，它们也会更新相应的测试规范。

​	另一种方法是为测试创立一种DSL（Domain-SpecificLanguage，领域专属语言），并用这种DSL来书写验收条件。

​	这些验收测试以及测试目标的简短描述就可以成为开发人员开发用户故事的起点。测试人员和开发人员在开发前应该尽早一起讨论这些验收测试。这会让开发人员更好地了解用户故事，并理解最重要的场景是什么样的。与开发完用户故事之后再沟通相比，这会大大减少开发人员和测试人员之间的反馈循环，有助于减小遗漏功能的几率，并有助于减少缺陷。

**管理待修复缺陷列表**

​	如果已经有一个待修复缺陷列表了，那么非常重要的一件事情就是将其可视化，让开发团队的每个人都认识到缩短待修复缺陷列表的责任。尤其当构建常常失败时，仅仅显示验收测试成功与否是不够的，还要显示测试通过的数量、失败的数量以及被忽略掉的测试数量，而且要放在比较显眼的位置。这样，可以让团队都关注这些问题。

​	还一种处理缺陷的方法，那就是像对待功能特性一样来对待缺陷。毕竟，修复缺陷和开发新功能一样，都需要花时间和精力。因此，客户可以将某个缺陷与要开发的新功能进行对比，得出它们的相对优先级。比如，一个出现概率很小的缺陷，只会影响少量用户，而且还有一个已知的临时解决方案，那么修复它的重要性可能要低于那些可以为用户带来收入的新功能。至少，我们可以把缺陷分为严重（critical）、阻塞（blocker）、中（medium）和低（low）四个级别。要想找到更全面的评估方法，我们可能还要考虑缺陷发生的频率，对用户的影响是什么，以及是否有临时解决方案等。

​	根据这种分类方式，就能在待修复缺陷列表中根据优先级将缺陷与用户故事按相同方式来排序，并可将二者一起放置。这样，除了可以避免“这是新功能，还是缺陷”的争论以外，还能一眼就看清楚还有多少工作要做，并相应地调整其优先级。低优先级的缺陷将被放在待修复缺陷列表中靠后的位置，就像对待低优先级的用户故事一样。客户也常常会选择不修复某些缺陷。因此，将缺陷和新特性一起放在待修复缺陷列表中也是管理它们的一种合乎逻辑的方法。

# 部署流水线解析

## 引言

​	持续集成的主要关注对象是开发团队。持续集成系统的输出通常作为手工测试流程和后续发布流程的输入。在软件的发布过程中，很多浪费来自于测试和运维环节。例如，我们常常看到：

* 构建和运维团队的人员一直在等待说明文档或缺陷修复；
*  测试人员等待“好的”版本构建出来；
* 在新功能开发完成几周之后，开发团队才能收到缺陷报告；
* 开发快完成时，才发现当前的软件架构无法满足该系统的一些非功能需求。

## 什么是部署流水线

​	从某种抽象层次上讲，部署流水线是指软件从版本控制库到用户手中这一过程的自动化表现形式。对软件的每次变更都会经历一个复杂流程才能发布。这一流程包括构建软件，以及后续一系列不同阶段的测试与部署，而这些活动通常都需要多人或者多个团队之间的协作。部署流水线是对这一流程的建模，在持续集成和发布管理工具上，它体现为支持查看并控制整个流程，包括每次变更从被提交到版本控制库开始，直到通过各类测试和部署，再到发布给用户的过程。

![](https://pic.imgdb.cn/item/60ced454844ef46bb2a2f923.jpg)

![](https://pic.imgdb.cn/item/60ced4ee844ef46bb2a83ac5.jpg)

​	随着某个构建逐步通过每个测试阶段，我们对它的信心也在不断提高。当然，我们在每个阶段上花在环境方面的资源也在不断增加，即越往后的阶段，其环境与生产环境越相似，其目的就是在这个过程中尽早发现那些不满足发布条件的构建版本，并尽快将失败根源反馈给团队。

![](https://pic.imgdb.cn/item/60ced50d844ef46bb2a944c6.jpg)

​	使用这种模式的话，有些非常重要的积极影响。首先，它可以有效地阻止那些没有经过充分测试或不满足功能需求的版本进入生产环境，也能避免回归缺陷，尤其是对于那些需要紧急修复并部署到生产环境的情况（因为和其他变更一样，这种紧急修复版本也需要走同样的流程）。根据我们的经验，最新发布的软件由于系统组件和其环境之间的未预期交互导致出现故障的事情是很常见的，比如使用了新的网络拓扑结构，或者生产环境的服务器在配置方面有些许不同。部署流水线的纪律会缓解这种现象。

​	其次，当部署和产品发布都被自动化之后，这些活动就变成快速、可重复且可靠的了。一旦被自动化，发布工作会变得非常容易，以至于会变成一件“平常”事，即只要你愿意，就可以做频繁发布。另外，如果支持自动安全回滚，发布风险也会大大降低，那么频繁发布就更不成问题了。一旦具有这种能力，发布就根本不会有什么风险了。最不济也就是引入一个严重缺陷，可这时只要回滚到之前没有缺陷的那个版本，然后在线下修复这个缺陷就可以了，没什么大不了的，详见第10章。

​	为了达到这种令人羡慕的状态，我们必须把那些用于证明某些版本满足业务要求的测试集合进行自动化。而且，我们还要把测试环境、试运行环境和生产环境上的部署过程自动化，这样可以避免那些手工密集型的易出错的步骤。对于很多系统来说，可能还需要其他形式的测试或者阶段，但对所有项目有一些阶段是共同具有的。

* 提交阶段是从技术角度上断言整个系统是可以工作的。这个阶段会进行编译，运行一套自动化测试（主要是单元级别的测试），并进行代码分析。
*  自动化验收测试阶段是从功能和非功能角度上断言整个系统是可以工作的，即从系统行为上看，它满足用户的需要并且符合客户的需求规范。
* 手工测试阶段用于断言系统是可用的，满足了它的系统要求，试图发现那些自动化测试未能捕获的缺陷，并验证系统是否为用户提供了价值。这一阶段通常包括探索性测试、集成环境上的测试以及UAT（User AcceptanceTesting，用户验收测试）。
* 发布阶段旨在将软件交付给用户，既可能是以套装软件的形式，也可能是直接将其部署到生产环境，或试运行环境（这里的试运行环境是指和生产环境相同的测试环境）。

**最基本的部署流水线**

![](https://pic.imgdb.cn/item/60ced82f844ef46bb2c2d63d.jpg)

​	这个流程的起点是开发人员向版本控制库提交代码。此时，持续集成管理系统对这次提交作出响应，触发该流水线的一个实例。第一个（提交）阶段会编译代码，运行单元测试，执行代码分析，创建软件二进制包。如果所有的单元测试都通过了，并且代码符合编码标准，就将可执行代码打包成可执行文件，并放到一个制品库（artifact repository）中。时新的持续集成服务器都提供保存这种过程产物的功能，并让用户和流水线的后续阶段能以某种非常简便的方式获取并使用。另外，还有很多像Nexus和Artifactory这样的工具可帮助管理这类过程产物。在提交阶段，你也许还会执行另外一些任务，比如为验收测试准备测试数据库。时新的持续集成服务器都支持通过构建网格并行执行这些任务。

​	第二个阶段通常由运行时间较长的自动化验收测试组成。因此，持续集成服务器最好支持将测试分成多组的做法，以便在构建网络中并行执行任务，这样会提高执行效率，使你更快地得到反馈（通常要在一两个小时之内返回结果）。这个阶段应该是流水线中第一个阶段成功完成以后自动触发的。

​	在此之后，部署流水线可能会有分支出现，这样就可以将该构建版本独立部署到多个不同的环境中，比如部署到用户验收测试环境、容量测试环境和生产环境。通常情况下，我们并不需要在验收测试阶段成功之后直接自动触发这些阶段。相反，我们希望让测试人员或运维人员可以做到自服务，即自己手工选择需要的某个版本，并将其部署到相应的环境中。为了做到这一点，需要有一个自动化部署脚本来执行这种部署过程。测试人员应当能够看到需要手工测试的所有构建版本，以及它们的状态（即已通过前两个阶段测试的版本，以及每个版本包含哪些修改，提交注释写了什么等）。之后单击一个按钮，运行相应的部署脚本将选定的构建版本部署到选定的环境上。

​	最后，一定要记住，我们所做的这一切都是为了尽快得到反馈。为了加速这个反馈循环，就必须能够看到每个环境中都部署了哪个版本，每个构建版本在流水线中处于哪个阶段。

![](https://pic.imgdb.cn/item/60ced8f2844ef46bb2c8f51b.jpg)

## 部署流水线的相关实践

### 只生成一次二进制包

​	很多构建系统将版本控制库中的源代码作为多个步骤中最权威的源，不同上下文中会重复编译这个源，比如在提交时、做验收测试时或做容量测试时。而且，在每个不同的环境上部署时都要重新编译一次。但是，对于同一份源代码，每次都重新编译的话，会引入“编译结果不一致”的风险。在后续阶段里，其编译器的版本可能与提交阶段所用版本不一致。对于第三方库，你可能会不小心使用了本未打算使用的版本。甚至编译器的配置都会对应用程序的行为产生影响。

>一种相关的反模式就是一直使用源代码，而不是二进制包。关于这种反模式更详细的讨论，请参见14.5.2节中的“ClearCase与从源重建反模式”。

​	这种反模式违反了两个重要原则。第一个原则就是“保证部署流水线的高效性，使团队尽早得到反馈”。重复编译违反了这一原则，因为编译需要花时间，在大型软件系统中进行的编译尤其如此。第二原则就是“始终在已知可靠的基础上进行构建”。被部署到生产环境中的二进制包应该与通过前面验收测试流程的二进制包是完全一样的。在很多实际使用的流水线里，每次生成二进制包时，都会存储其散列，并在后续每个阶段中利用这个散列对二进制包进行验证。

​	总之，二进制包应该只在构建流水线的提交阶段生成一次。这些二进制包应该保存在文件系统的某个位置上，让流水线的后续阶段能够轻松地访问到这个位置，但要注意不要放在版本控制库中，因为它只是一个版本的衍生品，并不是原生态的定义。大多数持续集成服务器能处理这类事情，而且会执行一些关键性的记录操作，让你能追溯到版本控制库中与之相关联的某次代码提交上。没有必要花太多时间和精力对这些二进制包进行备份，因为应该可以在版本控制库中的某个正确版本上，通过运行自动化构建精确地重新生成这个二进制包。

**为什么二进制包应该具有环境无关性**

​	我们认为，为每个环境都创建一个二进制包是一种不好的做法。尽管这种方法比较常见，但的确存在几个严重的缺点，不利于部署的灵活性、方便性和系统的可维护性，而有些工具恰恰鼓励你这么干。

​	如果构建系统是按这种方式组织的，它们很快就会变得非常复杂，最终会导致不得不利用某些特殊手法处理不同部署环境里的差异和特殊行为。我们曾遇到过这样一个项目，其构建系统非常复杂，以至于需要一个由五个人组成的全职团队来维护它。最终，通过重新组织构建流程，我们把与环境相关的配置和与环境无关的二进制包相分离，将他们从“火坑”中拯救了出来。

​	这种构建系统会将原本很简单的事情（比如向一个集群中增加一台服务器）搞得非常复杂，结果导致发布流程变得非常脆弱且成本很高。如果你的构建过程创建的二进制包只能在某些特定机器中运行，那现在就开始计划重新组织它吧！

### 对不同环境采用同一部署方式

​	为了确保构建和部署流程被有效测试，在各种环境中使用相同流程对软件进行部署是非常必要的，这些环境即包括开发人员或分析人员的工作站，也包括测试环境和生产环境。

​	能够使用相同的脚本向开发环境和生产环境部署，是避免“它在我的机器上可以工作”病症的法宝 [c29ETR]。如果能做到这种程度的话，那么在版本即将发布前，部署流程就已经在其他环境中测试过数百次了。这是我们所知道的缓解软件发布风险的最好方法之一。

相反，如果使用同一个脚本在所有的环境上进行部署，那么当在某个环境上部署失败时，就可以确定其原因一定来自以下三个方面：

* 与该环境相关的配置文件中，某项配置有问题；
* 基础设施或应用程序所依赖的某个服务有问题；
* 环境本身的配置有问题。

### 对部署进行冒烟测试

​	当做应用程序部署时，你应该用一个自动化脚本做一下冒烟测试，用来确保应用程序已经正常启动并运行了。这个测试应该非常简单，比如只要启动应用程序，检查一下，能看到主页面，并在主页面上能看到正确的内容就行了。这个冒烟测试还应该检查一下应用程序所依赖的服务是否都已经启动，并且正常运行了，比如数据库、消息总线或外部服务等。

### 向生产环境的副本中部署

​	很多团队实际部署应用上线时可能遇到的另一个主要问题是，生产环境与他们的开发环境或测试环境有非常大的差异。为了对系统上线充满信心，你要尽可能在与生产环境相似的环境中进行测试和持续集成。

​	另外，要想确保所有的环境都一样，需要有很多纪律保障良好的配置管理实践。你要确保：

* 基础设施是相同的，比如网络拓扑和防火墙的配置等；
* 操作系统的配置（包括补丁版本）都是相同的；
* 应用程序所用的软件栈是相同的；
* 应用程序的数据处于一个已知且有效的状态。系统升级过程中需要进行的数据迁移是部署活动的一个痛点，我们将在第12章讲这个问题。

### 每次变更都要立即在流水线中传递

​	在持续集成出现之前，很多项目都有一个各阶段的执行时间表，比如每小时构建一次，每天晚上运行一次验收测试，每个周末运行一次容量测试。部署流水线则使用了不同的方式：每次提交都要触发第一个阶段的执行，后续阶段在第一个阶段成功结束后，立即被触发。当然，假如某些阶段需要花较长的时间，而开发人员（尤其是在大型团队中）的提交又非常频繁，就很难做到这一点了。

![](https://pic.imgdb.cn/item/60cedfa2844ef46bb2010f34.jpg)

​	另一种构建策略是，一旦代码构建和单元测试结束，持续集成系统就去检查版本库中是否有新的提交。如果有的话，就将最近还没有构建过的所有变更全部拿来进行构建，即对版本4进行构建。假设这次构建和单元测试失败了，那么构建系统是无法知道究竟是哪个版本（版本3还是版本4）引起的，但开发人员自己可以很容易发现问题在哪儿。

### 只要有环节失败，就停止整个流水线

​	为了达到本书所描述的目标（迅速、可重复且可靠的发布），对于团队来说，最重要的是要接受这样的思想：每次提交代码到版本控制系统中后，都能够构建成功并通过所有的测试。对于整个部署流水线来说，都适用这一要求。假如在某个环境上的某次部署失败了，整个团队就要对这次失败负责，应该停下手头的工作，把它修复后再做其他事情。

## 提交阶段

在提交阶段，我们需要做以下几件事。这些任务通常作为一个工作集合运行在构建网格上（大多数持续集成服务器都提供类似功能），这样，提交阶段就能够在一个可接受的时间之内完成（最好在五分钟之内完成，最多不能超过十分钟）。一般来说，提交阶段包含以下步骤：

* 编译代码（如果所用开发语言需要的话）；
* 运行一套提交测试；
* 为后续阶段创建二进制包；
* 执行代码分析来检查代码的健康状况；
* 为后续阶段做准备工作，比如准备一下后续测试所用的数据库。

测试非功能特性（比如容量）可能比较困难，但仍旧可以通过一些分析工具，收集一些关于当前代码库的测试覆盖率、可维护性以及安全漏洞方面的信息。为这些度量项设定一个阈值，并像对待测试一样，一旦不满足阈值条件，就让提交阶段失败。比较有用的度量项包括：

* 测试覆盖率（如果提交测试只覆盖了代码库的5%，那么这些测试发挥不了太大的作用）；
* 重复代码的数量；
* 圈复杂度（cyclomatic complexity）；
* 输入耦合度（afferent coupling）和输出耦合度（efferent coupling）；
* 编译警告的数量；
* 代码风格。

**提交阶段最佳实践**

​	在理想情况下（无限的处理能力和无限的网络带宽），我们希望开发人员能够一直等到所有测试（甚至是手工测试）全部通过，这样一旦出现问题，就可以马上修复。然而，这并不现实，因为部署流水线的后续阶段（自动化验收测试、容量测试和手工验收测试）都需要相对较长的时间。这也是规范测试流程的一个理由，因为当缺陷还比较容易修复时，尽快得到反馈是非常重要的，而不应花更大的代价得到全面的反馈。

## 自动化验收测试之门

**为什么仅有单元测试是不够的**

​	单元测试过了，但是系统可能运行不起来。

**自动化验收测试最佳实践**

​	仔细考虑应用程序所要被部署到的生产环境是非常重要的。如果生产环境能完全在开发团队的控制之中，那么这个开发团队真的很幸运。此时，只要在这一环境的副本上运行验收测试就可以了。如果生产环境非常复杂或者非常昂贵，我们可能就要使用它的简化版了，比如仅使用两个中间件服务器，尽管生产环境中可能会有很多个。如果应用程序对外部服务有依赖，可以使用测试替身来模拟所依赖的外部基础设施。

## 后续的测试阶段

### 手工测试

​	在迭代开发过程中，验收测试之后一定会有一些手工的探索性测试、易用性测试和演示。在此之前，开发人员可能已经向分析师和测试人员演示了应用程序的功能，但一定是在自动化测试通过之后。在这个过程中，测试人员所扮演的角色并不是回归测试该系统，而是首先通过手工证明验收条件已被满足，从而确保这些验收测试的确是验证了系统行为。

### 非功能测试

​	根据我们的经验，如果需要的话，完全可以在部署流水线中创建一个阶段，用于运行这些自动化的非功能测试。

## 发布准备

​	缓解这类风险非常简单，只要把这个发布环节视为部署流水线的一个自然结果就行。实际上，我们只需要：

* 让参与项目交付过程的人共同创建并维护一个发布计划（包括开发人员和测试人员，以及运维人员，基础设施和支持人员）；
* 通过尽可能多的自动化过程最小化人为错误发生的可能性，并从最容易出错的环节开始实现自动化；
* 在类生产环境中经常做发布流程演练，这样就可以对这个流程及其所使用的技术进行调试；
* 如果事情并没有按计划执行，要有撤销某次发布的能力；
* 作为升级和撤销过程的一部分，制定配置迁移和数据迁移的策略。

### 自动部署与发布

​	对生产环境的控制权越小，遇到意外情况的可能性就越大。因此，无论何时发布软件系统，我们都希望有完全的控制权。然而，这里至少有两方面的约束。首先，对于很多应用程序来说，你根本不能完全控制应用程序所在的运行环境。对于由用户自行安装的软件（比如游戏或者办公软件）来说，这一点是必然的。通常解决这个问题的办法就是选择一些具有代表性的目标环境，并分别在这些样本环境上执行自动化验收测试套件。这样就能通过收集结果数据发现哪些测试在哪些平台上无法正常运行了。

​	第二个约束就是，人们通常认为为了达到完全控制环境所付出的成本会高于因此得到的收益。然而，事实常常恰好相反。生产环境中的大多数问题往往是由不充分的控制导致的。正如我们在第11章中所讲的，生产环境应该是完全受控的，即对生产环境的任何修改都应该通过自动化过程来完成。这不仅包括应用程序的部署，还包括对配置、软件栈、网络拓扑以及状态的所有修改。只有在这种方式下，我们才可能对它们进行可靠地审计和问题诊断，并在可预计的时间内修复它们。随着系统复杂性的增加，不同类型服务器的增多，以及不断提高的性能需求，我们就更需要这种程度的控制力。

### 变更的撤销

​	传统上，人们对新版本的发布常常存在着恐惧心理，原因有两个。一是害怕引入问题，因为手工的软件发布过程很可能引入难以发现的人为错误，或者部署手册本身就隐藏着某个错误。二是担心由于发布过程中的一个问题或新版本的某个缺陷，使你原来承诺的发布失败。无论是哪种情况，你的唯一希望就是足够聪明且非常迅速地解决这个问题。

​	我们可以通过每天练习发布多次来证明自动化部署系统是可以工作的，这样就可以缓解第一种问题。对于第二个问题，可以准备一个撤销策略。最糟的情况也就是回滚到发布之前的状态，这样你就有足够的时间评估刚发现的问题，并找到一个合理的解决方案。

​	最好的撤销策略是在发布新版本时，让旧版本仍旧处于可用状态，并在发布后保持一段时间。这是我们将在第10章讨论的一些部署模式的基础。对于很简单的应用程序来说，这是可以做到的（忽略数据和配置信息的迁移），只要把每个版本都放在一个单独的目标中，再使用符号链接指向当前版本就行了。最复杂的情况就是在部署和撤销中涉及生产数据的迁移。

​	另一种比较好的撤销策略是从头开始重新部署旧版本。为此，与部署流水线中的其他环境一样，我们就应当能通过单击按钮的方式来发布已通过所有测试阶段的任意一个版本。某些软件完全可以达到这种理想状态，甚至那些数据量相当大的系统也可以做到这一点，而对另外一些系统来说，即使不差钱儿，对于某些个别的变更，提供这种具有版本无关性的撤销也是相当耗时的。无论怎样，有目标、有理想总是好的，因为它为每个项目都设定了一个努力方向。即使在某些方面做得不够好，但你的方法越接近这种理想状态，部署就会越容易。

​	撤销流程绝不应该与部署流程、增量部署流程或回滚流程有什么不同。然而，这些流程可能很少被测试，所以也就不可靠。

### 在成功的基础上构建

​	当一个候选发布版本能够部署到生产环境时，我们就确信：

* 代码可以编译；
* 代码能够按开发人员的预期运行，因为它通过了单元测试；
* 系统能够满足分析人员或用户预期，因为它通过了所有的验收测试；
* 基础设施的配置和基线环境被恰当地管理了，因为应用程序在模拟的生产环境上通过了测试；
* 系统所有的正确组件都就绪了，因为它是可以部署的；
* 部署脚本也是可以工作的，因为在该版本到这一阶段之前，部署脚本至少在开发环境中用过一次，在验收测试阶段用过一次，在测试环境中用过一次；
* 我们需要部署的所有内容都在版本控制库中，而且不需要手工干预，因为我们已经部署这个系统好几次了。

## 实现一个部署流水线

​	接下来，我们将描述如何从无到有，建立一个完整流水线的策略。一般来说，步骤是这样的：

* 对价值流建模，并创建一个可工作的简单框架；
* 将构建和部署流程自动化；
* 将单元测试和代码分析自动化；
* 将验收测试自动化；
* 将发布自动化。

### 对价值流进行建模并创建简单的可工作框架

​	第一步就是画出从提交到发布整个过程的价值流图。如果项目已经建好并开始运行，你在半个小时内就能画完。然后和参与其中的每个人聊一下，记录下流程中的每个步骤，包括对经历时间（elapsed time）和增值时间（value-added time）的最佳估计值。如果是还没有启动的新项目，就要先设计一个合适的价值流，可以在同一组织中找个与你的项目相似的项目，思考它的价值流，也可以从最简单的价值流开始，即第一个阶段是提交阶段，用来构建应用程序并运行基本的度量和单元测试，第二个阶段用来运行验收测试，第三个阶段用来向类生产环境部署应用，以便用它来做演示。

​	一旦有了价值流图，就可以用持续集成和发布管理工具对流程建模了。如果所用工具不支持直接对价值流建模的话，可以使用“项目[插图]间依赖”来模拟它。首先，这些项目应该什么也不做，而只是作为可以被依次触发的占位符。如果是使用“最简单模型”，每当有人提交代码到版本控制系统时，就应该触发提交阶段。当提交阶段通过以后，验收测试阶段就应该被自动触发，并使用提交阶段刚刚创建的二进制包。为手工测试或发布应用而向类生产环境部署二进制包的阶段，都应该会要求你具有通过单击按钮来选择到底部署哪个版本的能力，而这种能力通常都需要授权。

### 构建和部署过程的自动化

​	每当有人提交后，持续集成服务器就应执行构建——使用3.2节所列出的某个工具。持续集成服务器应该监视版本控制系统，每当发现有新提交的代码时，就签出或更新源代码，运行自动化构建流程，并将生成的二进制包放在文件系统的某个地方，使整个团队都能通过持续集成服务器的用户界面获取。

​	一旦持续构建流程建立并运行起来了，接下来就要做自动化部署了。首先，要找到能够部署应用程序的机器。对于刚启动的新项目，用持续集成服务器所在的机器也行。如果项目已比较成熟，可能就需要找几台专用机器了。这些环境可以称作试运行环境或者用户验收测试（UAT）环境（这在各组织中的叫法不同）。

​	部署活动可能包含：（1）为应用程序打包，而如果应用程序的不同组件需要部署在不同的机器上，就要分别打包；（2）安装和配置过程应该实现自动化；（3）写自动化部署测试脚本来验证部署是否成功了。部署流程的可靠性是非常重要的，因为它是自动化验收测试的前提条件。

### 自动化单元测试和代码分析

​	流水线的验收测试阶段可以重用向测试环境部署的脚本。唯一的不同之处就是在冒烟测试之后，就要启动验收测试框架，并在结束之后，为进行分析收集所有的测试结果报告。另外，最好也保存一下应用程序的运行日志文件。如果应用程序有图形用户界面的话，也可以在验收测试运行时使用一个像Vnc2swf这样的软件来进行屏幕录像，这对于诊断问题比较有用。

### 部署流水线的演进

​	我们发现，每个价值流图和流水线中几乎都有上面描述的步骤。通常这些是自动化的第一个目标。随着项目越来越复杂，价值流图也会演进。另外，对于流水线来说，还有两个常见的外延：组件和分支。大型应用程序最好由多个组件拼装而成。在这样的项目中，每个组件都应该有一个对应的“迷你流水线”，然后再用一个流水线把所有组件拼装在一起，并运行整个验收测试集（包括自动化的非功能测试），然后再部署到测试环境、试运行环境和生产环境中。

## 度量

​	反馈是所有软件交付流程的核心。改善反馈的最佳方法是缩短反馈周期，并让结果可视化。你应该持续度量，并把度量结果以一种让人无法回避的方式传播出去，比如使用张贴在墙上的海报或者用一个专门的计算机显示器以大号粗体字显示结果，这些设备就是信息辐射器。

​	对于软件交付过程来说，最重要的全局度量指标就是周期时间（cycle time）。它指的是从决定要做某个特性开始，直到把这个特性交付给用户的这段时间。正如Mary Poppendieck所问的那样：“你所在的组织中，如果仅仅修改一行代码，需要多长时间才能把它部署到生产环境中？你们是否以一种可重复且可靠的方式做这类事情？”[插图]这个指标很难度量，因为它涉及软件交付过程中的很多环节（从分析到开发，直至发布）。然而，这个指标比其他任何度量项都更能反映软件交付过程的真实情况。

​	一旦知道了应用程序的周期时间，就能找到最佳办法来缩短它。你可以利用约束理论，按照下面的流程来做优化。

（1）识别系统中的约束，也就是构建、测试、部署和发布这个流程中的瓶颈。随便举个例子，比如手工测试部分。

（2）确保供应，即确保最大限度地提高流程中这部分的产出。在我们的例子中（手工测试），就是保证总是有用户故事在等待手工测试，并确保手工测试所需的资源不会被其他工作占用。

（3）根据这一约束调整其他环节的产出，即其他资源都不会100%满负荷工作。比如，开发人员全力开发用户故事时，等待测试的用户故事会越积越多。因此，只要开发人员开发用户故事的速度能及时供应手工测试就可以了，其他时间他们可以写些自动化测试来捕获缺陷，这样测试人员就不需要在手工测试上花太长时间了。

（4）为约束环节扩容。如果周期时间还是太长（换句话说，第（2）步和第（3）步都没有什么太多的帮助），就要向该瓶颈环节增加资源了，比如聘用更多的测试人员，或者在自动化测试方面投入更多的精力。

（5）理顺约束环节并重复上述步骤，即在系统中找到下一个约束，并重复第（1）步。



​	尽管周期时间是软件交付中最重要的度量项，但还有一些其他度量项可以对问题起到警报作用。这些度量项如下所示。

* 自动化测试覆盖率。
* 代码库的某些特征，比如重复代码量、圈复杂度、输入耦合度、输出耦合度、代码风格问题等。
* 缺陷的数量。
* 交付速度，即团队交付可工作、已测试过并可以使用的代码的速率。
* 每天提交到版本控制库的次数。
* 每天构建的次数。
* 每天构建失败的次数。
* 每次构建所花的时间，包括自动化测试的时间。



​	如何呈献这些度量项是值得斟酌的。上面这些报告会产生很多数据，而如何解析这些数据就是一门艺术。比如程序经理可能想在一个项目健康报告中以非常简单的红黄绿交通信号灯方式看到已分析的聚合数据，而不是看到一页又一页的报告。相比之下，一个团队中资深的软件工程师会希望看到更详细的情况，但也不会乐意查看多页的报告。我们的同事Julias Shaw创建了一个叫做Panopticode的项目，可以在Java代码上运行一系列这样的报告，生成丰富的密集的可视化报告（如图5-8所示），使你一眼就能知道代码库是否存在问题，以及问题在哪儿。我们所要强调的是，一定要创建一个聚合所有信息，并且人脑可以直接通过其无比的模式匹配能力识别流程或代码库中问题的可视化报告。

![](https://pic.imgdb.cn/item/60ceeddb844ef46bb28d25db.jpg)

## 小结

略

# 构建与部署的脚本化

## 引言

​	一旦项目变得复杂了，比如有多个组件或者不太常见的打包方式，你就需要撸起袖子，动手构建脚本了。

​	自动化部署则稍微麻烦一点儿。向测试环境和生产环境部署软件的过程不可能是“复制一个二进制文件到生产环境，然后就坐在那里等着就了事儿”那么简单。大多数情况下，它需要一系列的步骤，比如配置应用程序、初始化数据、配置基础设施、操作系统和中间件，以及安装所需的模拟外部系统等。项目越复杂，这样的步骤就越多，所需时间越长，而且（如果没有自动化的话）就越容易出错。

## 构建工具概览

​	例如，假如你想运行测试，就需要编译自己的代码和测试，并设置测试数据，以及编译与初始化环境相关的所有东西。图6-1显示了一个依赖网络的简单例子。

![](https://pic.imgdb.cn/item/60d00083844ef46bb256e8ed.jpg)

​	每个任务都包括两点内容，一是它做什么，二是它依赖于什么。在每个构建工具中都会对这两点进行建模。

​	构建工具会遍历整个网络，调用（但并不一定执行）每个任务。

​	面向产品的构建工具将状态以时间戳的形式保存在每个任务执行后生成的文件中（SCons使用MD5签名）。这在编译C或C++程序时非常好，因为Make会保证只编译那些自上次构建后发生过修改的源代码文件。在大型项目中，这种特性（称为增量式构建）会比全量构建节省数小时。在C/C++项目中，通常编译会花较长的时间，因为编译器会做很多优化代码的工作。对于运行于虚拟机上的语言来说，编译器只创建字节码就行了，虚拟机运行时（JIT）编译器会在运行时进行这种优化。

​	下面，我们简单总结一下当前流行的构建工具。本书网站[dzMeNE]上有很多使用这些技术的构建脚本的例子和参考。

### Make

​	Make和它的变种仍旧活跃在系统开发领域。它是一种强大的产品导向的构建工具，能在单次构建中追踪依赖关系，还能只构建那些受到本次修改影响的组件。

​	Make也有很多缺点。随着应用程序复杂程度和组件之间依赖关系的增加，这种复杂性会让Make变得越来越难以调试。

​	在某些情况下，空白字符的影响非常大，所以很容易在Makefile中引入一些难以发现的缺陷。比如在一个命令脚本中，那些传给shell的命令必须有一个制表符在前面。如果相反地使用了空格，这个脚本就无法正常工作了。

​	Make的另一个缺点是，它依赖于shell做所有的事情。结果，Makefile就不得不与操作系统绑定在一起了。（的确，很多工作就由Make周边的一堆工具来承担，以便构建脚本可以在UNIX的多种变种系统中运行。）由于Makefile是一种外部的DSL（Domain-Specific Language，领域特定语言），并不提供对核心系统的扩展能力（除非定义新的规则）。在无法使用Make的内部数据结构的前提下，所有的扩展都必须重建公共解决方案。

​	现在很多C/C++的项目中，开发人员更倾向于使用SCons，而不是Make。SCons本身和它的构建文件都是用Python写的，这让它成为了比Make更强大和更适用的工具。它有很多非常有用的特性，比如支持Windows和并行构建。

## Ant

​	Java社区也先后经历了几种解决方案，先是将Make本身移到Java上。与此同时，XML作为构建结构化文档的方便方法开始崭露头角。二者的融合就产生了Apache的构建工具Ant。

​	Ant是一个任务导向的构建工具。Ant的运行时组件也是用Java写的，但Ant脚本是用XML书写的一种外部DSL。这种结合使Ant具有了强大的跨平台能力。它也是极其灵活和强大的系统，因为Ant的任务几乎可以让你做任何想做的事情。

​	然而，Ant也有几个缺点。

* 你要用XML写构建脚本，可XML的脚本既不简洁，又不易阅读。
* Ant是一个贫血领域模型。任务上没有真正的领域概念，所以要花大量的时间为编译、生成Jar、运行测试等编写样板文件。
* Ant是声明式语言，而非命令式语言，但提供了少量的命令式标签（比如糟糕可怕的<antcall>）给用户使用。
* 关于Ant 任务，它没法回答类似下面这样的问题，比如“运行了多少个测试”和“它们花了多长时间”。你能做的就是找一个工具把这些信息输出到命令行窗口中，然后对其进行解析，或者写一些Java代码做个钩子，放在Ant中。
* 尽管Ant通过import和macrode任务支持重用，但对新手用户来说，它们很难理解。



​	由于这些局限性，Ant文件会很长，也很难重构（数千行的Ant文件很常见）。当使用Ant时，非常值得一读的文章就是ThoughtWorks公司的咨询师JulianSimpson写的“Refactoring Ant Build Files”，它发表在了ThoughtWorks文集《软件开发沉思录》中。

### NAnt 与 MSBuild

​	略

### Maven

​	Maven通过为Java项目的代码组织结构定义一些假设前提，形成一个比较复杂的模型，试图以此消除Ant文件中大量的样板文件。这种流行的“惯例胜于配置”（convention over configuration）的原则意味着，只要项目按Maven指定的方式进行组织，它就几乎能用一条命令执行所有的构建、部署、测试和发布任务，却不用写很多行的XML。这包括为项目创建网站，用来默认宿主应用软件的所有Javadoc。

​	Maven另一个重要的特性是，它能自动管理Java库和项目间的依赖，而这正是大型Java项目的一个痛点。Maven还支持一种复杂且严格的软件分区方案，使你能将复杂的解决方案分解成较小的组件。

​	Maven的问题有三个。首先，如果项目没有按Maven规定的结构和生命周期来组织的话，你很难（甚至不可能）使用Maven。当然，在一些组织中，这也可能被认为是一种特点，它迫使开发团队根据Maven的规范组织项目结构。对于缺乏开发经验或有很多项目的组织，这是一件好事，但如果想要做一些“打破常规”的事（比如在执行测试之前加载一些定制测试数据），你就要颠覆Maven的生命周期和领域模型，而这个过程相当痛苦，而且难以维护，但通常是不可避免的。Ant比Maven灵活得多。

​	Maven的第二个问题是，它也需要用XML写的外部DSL。也就是说，为了扩展它，你要写代码。尽管写Maven插件并不很复杂，但绝对不可能在几分钟之内搞定。你要学习Mojos、插件描述符，以及Maven所用的控制反转（inversion-of-control）框架。幸运的是，Maven有很多插件，对于一般的Java项目，你几乎能找到所有想要的插件。

​	Maven的第三个问题是，在默认配置中，它是自更新的。Maven的内核非常小，为了让自己能够工作，它要从因特网上下载它自己的插件。Maven每次运行时都会尝试更新自己，而这种插件的自动升降级有可能导致不可预期的失败。更严重的结果是，你很可能无法重现某次构建。与之相关的一个问题是，Maven的库和依赖管理功能允许在多个项目之间使用组件的快照。如果使用这种快照依赖的话，就更难重现某次构建了。

​	对于某些团队来说，Maven的约束可能过于严格了，或者需要很多精力才能将项目整理成符合Maven的规定的结构。所以，他们宁可使用Ant。最近，出现了叫做Ivy的工具，它可以在多个组件之间管理库文件和依赖，而不需要使用Maven。将它与Ant结合使用，在某种程度上，可以得到与使用Maven一样的效果。

### Rake

​	可是XML令这些语言很难编写、阅读、维护和扩展。主流的Ruby构建工具Rake作为一个试验品出现了，它是否能够通过在Ruby中创建内部DSL来轻松完成Make的相应功能呢？答案是肯定的。Rake和Make一样是产品导向的工具，但也可以用作任务导向的工具。

​	像Make一样，Rake只能理解任务和依赖。然而，由于Rake脚本是纯Ruby的，所以你可以用Ruby的API来执行任何任务。因此，用Rake可以轻松写出强大且与平台无关的构建文件，因为你能使用通用编程语言的所有本地化功能。

​	Rake也有两个不便之处：首先，要确保在你的平台上装有适当的Ruby运行时环境（作为最方便最可靠的平台，JRuby势头强劲）；其次，要组合使用RubyGems。

### Buildr

​	Rake的简单和强大令“构建脚本应该用一个真正的编程语言编写”有了一个令人信服的理由。新一代构建工具，比如Buildr、Gradle和 Gantt都使用了这种方式。它们都以内部DSL的形式构建软件。然而，它们试图让复杂的依赖管理和多项目构建变得简单。

​	如果刚开始一个Java项目，或是想找Ant或Maven的替代品，我们强烈推荐Buildr，如果你喜欢Groovy中的DSL，就用Gradle吧。

### Psake

​	略

## 构建部署脚本化的原则与实践

### 为部署流水线的每个阶段创建脚本

​	我们是DDD（Domain-Driven Design，领域驱动设计）的忠实粉丝，所以，在我们设计的任何软件中都会使用这一技术，对于设计构建脚本也不例外。如果想让构建脚本的结构清晰地表达构建流程，这可能有点儿不切实际。使用这种方法，我们可以确保在维护构建部署系统和最小化组件间依赖的过程中，还能令脚本具有良好的结构。幸运的是，部署流水线提供了一种优秀的组织原则，可使构建脚本间的职责清晰明确。

​	当项目刚开始时，可以将部署流水线中的每个操作都放在同一个脚本文件中，即使是那些还没有被自动化的步骤，也可以有对应的哑操作。但是，一旦脚本变得太长，就要将它们分成独立的脚本，让部署流水线中的每个阶段分别使用单独的脚本。这样，一个提交阶段的脚本就可以完成编译、打包、运行提交测试套件和执行代码静态分析的工作。功能验收测试脚本会调用部署工具，将应用程序部署到适当环境中，并准备相关数据，之后再运行验收测试。你还可再用一个脚本运行任何非功能测试，比如压力测试和安全测试。

### 使用恰当的技术部署应用程序

​	在典型的部署流水线里，提交阶段之后的大多数阶段（比如自动化的验收测试阶段和用户验收测试阶段）都需要把应用程序部署到类生产环境中，所以部署自动化也是非常关键的。然而，在做自动化部署工作时，应该使用恰当的工具，而不是通用脚本语言（除非部署流程十分简单）。几乎每种中间件都有相应的工具来配置和部署它，那就使用它们吧。

​	最重要的是，开发人员（至少可以在他们自己的开发机器上）、测试人员和运维人员都要做应用程序的部署工作。因此，他们要共同判定如何部署应用程序。这件事也要在项目一开始就做。

**运维人员和开发人员必须合作规划部署流程**

​	部署脚本应该能够完成应用程序的安装和升级任务。在部署之前，它要能够关闭当前运行的版本，而且既支持在当前的数据库上升级，又能够从头创建数据库。

### 使用同样的脚本向所有环境部署

​	使用同样的流程部署应用程序到每个环境是非常必要的，这样就能确保构建和部署流程能经过有效测试。也就是说，“使用同样的脚本部署每个环境”和“环境配置信息的不同（比如服务URI或IP地址）”这两件事应该分开管理，即将配置信息从脚本中分离出来，并将其保存在版本控制库中。

​	（1）构建和部署脚本在开发机器和类生产环境上都能运行；

​	（2）开发人员使用这些脚本进行所有的构建和部署活动。对于并行构建系统来说，很容易变成“只有开发人员使用这些脚本”，但这就丢失了可以令构建部署脚本保持灵活性、很好地被重构和测试的关键因素。如果应用程序还依赖于公司内部开发的其他组件，就要确保能很方便地将其正确版本（已知与我们的应用程序相匹配的版本）放到开发机器上，这时Maven和Ivy这样的工具就能够派上用场。

### 使用操作系统自带的包管理工具

​	如果只有一种目标操作系统，或者一组相似的操作系统，我们强烈推荐使用操作系统自身的包管理技术把需要部署的文件打包在一起。例如，Debian和Ubuntu都使用Debian的包管理系统，RedHat、SuSE和很多其他Linux发行版都使用RedHat包管理系统，Windows用户可以使用Microsoft Installer系统等。所有这些包管理系统都相对容易使用，并有很好的工具支持。

​	如果在部署过程中需要把文件放在多个文件夹中或向注册表中增加键，那么就用一个包管理系统完成这样的任务吧。这会带来很多好处，不但令应用程序的维护变得非常简单，而且在部署流程中就可以使用像Puppet、CfEngine和Marimba这样的环境管理工具。只要将包放到组织级的代码库中，让这些工具来安装正确版本的包就可以了，就像让它们安装Apache的正确版本一样。假如要把不同的文件安装到不同的机器上（比如当使用N层架构时），你就可为每一层或每一类机器分别创建一个安装包。对二进制文件进行打包的工作也应该是部署流水线中需要实现自动化的部分。	

​	当然，并不是所有的部署都能用这种方式来管理。比如商业化中间件服务器就经常需要使用特定的工具来执行部署。此时，就必须使用混合方法了。准备好所有并不需要那些特定工具的东西，然后再使用这些特定工具执行部署过程的后续部分就行了。

当然，并不是所有的部署都能用这种方式来管理。比如商业化中间件服务器就经常需要使用特定的工具来执行部署。此时，就必须使用混合方法了。准备好所有并不需要那些特定工具的东西，然后再使用这些特定工具执行部署过程的后续部分就行了。

### 确保部署流程是幂等的（Idempotent）

​	无论开始部署时目标环境处于何种状态，部署流程应该总是令目标环境达到同样（正确）的状态，并以之为结束点。

​	做到这一点的最简单方法就是，将已知状态良好的基线环境作为起点，要么是通过自动化，要么是通过虚拟化方式准备好的。这里所说的环境包括所有需要用到的中间件，以及让应用程序能正常工作的任何软硬件。然后，部署流程可以获取指定的应用程序版本，并使用（对于中间件来说）适当的部署工具将其部署到该环境中。

​	对于这一原则，也有一些例外情况。首先，对于集群系统来说，总是将整个集群系统同时重新部署就不可取。

​	其次，如果应用程序是由多个组件构成的，而这些组件来源于不同的源代码库，那么二进制包就由这些源代码库中的一系列修正版本（x、y、z……）来定义。此时，如果你知道仅有一个组件发生了变更，而且将要部署到生产环境的所有组件的组合都已经测试通过了的话，那么只部署这个发生变更的组件就行了。这里的关键区别在于从上一个状态更新到新状态的过程已被测试过。这一原则也适用于面向服务架构的服务部署上。

​	最后，还有一种方法，那就是使用效果幂等的工具进行部署。比如，无论目标目录中的文件处于什么状态，Rsync都会使用一种强大的算法，仅通过网络传输目标目录与源目录中不同的部分，确保某系统上的目标目录与另一个系统中的源目录是完全一样的。版本控制的目录更新也能达到相似的结果。

### 部署系统的增量式演进

​	每个人都能看到一个完全自动化的部署过程的魅力，即“单击按钮即可发布软件”。当某个大型企业应用系统以这种方式部署时，看起来就像变魔术一般。但魔术有一个问题，即从外部看会显得极为复杂。事实上，当你查看我们的部署系统时会发现，它只是由一组非常简单的、增量的步骤组成的复杂系统，而这些步骤也是随着项目的进行不断完善的。

## 面向JVM的应用程序的项目结构

​	因为尽管有一些有用的惯例，但如果不使用Maven[插图]的话，这些就只是惯例，而不是规定。如果开发人员能够遵守这些标准结构的话，生活会更美好一些。另外，花一点儿精力也可以将下面的知识用到其他技术平台上。尤其是对于．NET项目来说，可以卓有成效地使用完全相同的结构，只是要把“/”换成“\”。

**源代码管理**

​	请坚持遵循标准的Java实践，将文件放在以包名为目录名的目录中，每个文件保存一个类。Java编译器和所有时新的开发环境都会使用这种惯例，但仍有人会违反它。如果不遵循它或语言的其他惯例，有可能引入很难被发现的缺陷。

**测试管理**

​	请将所有要测试的源代码都放在test/[language]目录中。单元测试应该放在与包名相对应的目录中。也就是说，某个类的测试应该与该类放在同一个包中。

**构建输出的管理**

​	当用Maven做构建时，它把所有的东西都放在项目根目录中一个叫做target的文件夹中，包括生成的代码、元数据文件（如Hibernate映射文件）等。将这些内容放在一个单独的目录中能让我们更容易清除前一次构建结果，因为只要把整个目录删除就行了。不要把这个目录中的东西提交到版本控制库中，而如果打算把二进制文件提交到版本控制库中，请将它们先复制到另一个存储库中再提交。源控制系统应该忽略target目录。

​	无论使用什么样的策略，你都要记住，创建多个JAR文件的目的有两个：一是令应用程序的部署更简单；二是令构建流程更加高效，并将构建依赖图的复杂性最小化。这些是应用程序打包的指导方针。

**库文件管理**

​	库文件的管理有几种不同的选择。一是完全交给工具来管理，比如Maven或Ivy工具。这时就不需要将库文件提交到版本控制库中，只需要声明一下项目中所依赖的库文件就可以了。另一个极端是把库文件（包括构建、测试和运行时必需的所有库文件）都提交到版本控制库中，最常见的做法是将它们放在项目根目录下的lib文件夹中。我们喜欢根据其用途，将这些库放在不同的目录中，比如构建时、测试时和运行时。

​	一种比较高级的做法是建立组织级的第三方依赖库，将所有项目需要的所有依赖库文件都放在其中。Ivy和Maven都支持仓库自定义。在强调纪律的组织中，通常用这种方式。

## 部署脚本化

​	环境管理的核心原则之一就是：对测试和生产环境的修改只能由自动化过程执行。也就是说，我们不应该手工远程登录到这些环境上执行部署工作，而应该将其完全脚本化。有三种方式执行脚本化的部署。首先，如果系统只运行在一台机器上，我们就可以写一个脚本，让它在那台机器上本地执行所有的部署活动。

​	有三种方法做远程部署。第一种方法就是写个脚本，让它登录到每台机器上，运行适当的命令集。第二种方法是写个本地运行的脚本，在每台远程机器上安装一个代理（agent），由代理在其宿主机上本地运行该脚本。第三种方法就是利用操作系统自身的包管理技术打包应用程序，然后利用一些基础设施管理或部署工具拿到新版本，运行必要的工具来初始化你的中间件。第三种方式最为强大，理由如下。

* 像ControlTier和BMC BladeLogic这类部署工具，以及像MarionetteCollective、CfEngine和Puppet这样的基础设施管理工具都是声明式的而且是等效的，即使在部署时某些机器停机了，或者新增机器或VM时，它们都能确保将正确版本的二进制包安装到所有机器上。关于这此工具的更多信息，参见第11章。
* 你还可以使用同一套工具管理应用程序的部署以及基础设施。由于同一组人（运维团队）同时负责这两件事情，而这两件事情关系紧密，所以使用相同的工具就更有必要了。



如果你无法使用这种方法的话，使用支持代理模式的持续集成服务器（现代的持续集成服务器几乎都支持这种模式）会让第二种方式变得更简单。这种方法有以下几种好处。

* 你的工作更少。只要写一些本地运行的脚本，把它们提交到版本控制库中，让持续集成服务器在指定的远程机器上运行这些脚本就可以了。
* 持续集成服务器提供了管理任务（job）的整套基础设施，比如失败后重新执行，显示控制台输出，提供信息辐射显示板，让你能看到部署状态，以及每个环境中部署的版本号。
* 如果有安全性需求，可以让自己机器上的持续集成代理从持续集成服务器上得到部署所需的所有内容，而不必用脚本远程登录到测试或生产环境中。



​	最后，假如由于某种原因，你无法用上述任何一种工具的话，也完全可以从头到尾自己定制一个部署脚本。如果远程机器是UNIX，你可以使用原始的Scp或Rsync复制二进制包和数据，然后通过Ssh执行相关命令来进行部署。如果你使用Windows操作系统，也有两种选择：PsExec和PowerShell。当然，还有高层次的工具（如Fabric、Func和Capistrano等）让你绕过底层操作，直接将部署脚本化。

### 多层的部署和测试

​	对于软件交付或某个复杂系统的构建和部署，假如说有一个基础的核心原则的话，那就是应该总是把根基扎在已知状态良好的基础之上。我们不去测试那些没有编译成功的代码，也不会对没有通过提交测试的代码进行验收测试等。

​	当把候选版本发布到类生产环境中时更应该如此。在将应交付的二进制包复制到文件系统的某个正确位置之前，我们就要确保环境已经准备好了。为了做到这一点，我们喜欢把部署看做是一个层级沉积序列。

![](https://pic.imgdb.cn/item/60d01732844ef46bb2f05b3e.jpg)

### 测试环境配置

​	任何一个层级的部署出错，都可能导致应用程序无法正常运行。所以，当准备每一层级时，都要对其进行测试（参见图6-3）。如果发现问题，就要让环境配置流程快速失败，而测试结果也应该给出清晰指示，指出错误出现在哪里。

![](https://pic.imgdb.cn/item/60d017a0844ef46bb2f40b7a.jpg)

​	这些测试不必非常详尽，它们只需要捕获常见错误或昂贵的潜在错误，应该只是一些非常简单的“冒烟测试”，断言某些关键资源是否存在。我们的测试目标是为“刚部署的层级是可以工作的”提供一定的信心指数。

​	你写的基础设施冒烟测试针对每个具体系统应该是各不相同的，但测试目标是一致的，即证明环境的配置与我们的期望相符。关于基础设施监控在11.9节有详细阐述。为了给读者一些感觉，下面列出了我们认为比较有用的测试示例：

*  确认能从数据库中拿到一条记录；
* 确认能连上网站；
* 断言消息代理中的已注册的消息集合是正确的；
* 透过防火墙发送几次“ping”命令，证明线路是通的，且各服务器之间提供了一个循环负荷分配。

## 小贴士

### **总是使用相对路径**

​	构建中最常见的错误就是默认使用绝对路径。这会让构建流程和某台特定机器的配置形成强依赖，从而很难被用于配置和维护其他服务器。

​	当然偶尔也会使用绝对路径，这是很难完全避免的。但是，一定要尝试用一些更有创造力的方法尽量避免。如果不得不使用绝对路径的话，应该确保这一定是构建中的特例，而不是常规用法。确保把这些绝对路径放在属性文件或其他配置机制中，使其与构建系统相互独立。当然，有时绝对路径是必要的。

### 消除手工步骤

​	我们什么时候应该考虑将流程自动化呢？最简单的回答就是：“当你需要做第二次的时候。”到第三次时就应该采取行动，通过自动化过程来完成这件工作了。

### 从二进制包到版本控制库的内建可追溯性

​	能够确定“某个二进制包是由版本控制库中的哪个具体版本生成的”是非常必要的。假如在生产环境中出了问题，能够轻松确定机器上每个组件的版本号，以及它们的来源，你的生活会轻松很多。Bob Aiello写的Configuration ManagementBest Practices一书中有个很好的例子。

### 不要把二进制包作为构建的一部分放到版本控制库中

​	有时候，把二进制包或结果报告当做构建的一部分放到版本控制库中看起来是一个不错的主意。可是，一般来说，我们应该避免这种做法，原因如下

​	首先，版本控制标识的最重要作用之一就是能够追踪到某次提交中修改了什么。通常我们会将一个版本控制ID与一个构建标签相关联，用于在各种环境中（直至生产环境）追踪每次变更。假如把构建生成的二进制包和结果报告也提交到版本控制库中，那么与版本标识对应的这些二进制包就会有属于它们自己的版本标识了，有时这会令人感到迷惑。

​	取而代之的是，我们可以把二进制包和结果报告放在一个共享的文件系统中存储。如果你把它们弄丢了或者需要重新生成它们的话，最好是从源代码中重新构建一份。假如你无法根据源代码重新构建出一份一模一样的副本，这说明你的配置管理没达到标准，需要加以改进。

​	一般的经验法则是不要将构建、测试和部署过程中生成的任何产物提交到版本控制库中，而要将这些产物作为元数据，与触发该次构建的版本的标识关联在一起。大多数时新的持续集成和发布管理服务器都有制品库和元数据管理功能，如果没有的话，你也可以使用像Maven、Ivy或Nexus这样的工具。

### “test”不应该让构建失败

​	在某些构建系统中，一旦某个任务失败，便默认令本次构建立即失败。也就是说，假如你有一个“test”任务，如果在其运行时，任何测试失败了，整个构建就将立即失败。通常来说，这种做法是不好的。相反，应该将当前失败的任务记录下来，然后继续构建流程的后续部分。最后，在过程结束时，如果发现有任意一个任务失败了，就退出并返回一个失败码。

### 用集成冒烟测试来限制应用程序

​	交互设计师常常通过界面约束来避免那些未预期的用户输入。你可以使用同样的方式来限制应用程序，使得当程序本身发现自己处于非正常状态时，它就会停止运行。比如，可以在部署之前令部署脚本先检查一下是否被部署在了正确的机器上。对于测试和生产环境配置来说，这尤其重要。

###  .NET小贴士

​	略

##  小结

略

# 提交阶段

## 引言

​	当更改项目状态（向版本控制库的一次提交）时，提交阶段就开始了。当它结束时，你要么得到失败报告，要么得到后续测试和发布阶段可用的二进制产物和可部署程序集，以及关于当前应用程序状态的报告。理想情况下，提交阶段的运行应该少于五分钟，一定不会超过十分钟。

![](https://pic.imgdb.cn/item/60d1cb9d844ef46bb22ba8e6.jpg)

* 编译（如果需要的话），并在集成后的源代码上运行提交测试；
* 创建能部署在所有环境中的二进制包（如果使用需要编译的语言，则包括编译和组装）；
* 执行必要的分析，检查代码库的健康状况；
* 创建部署流水线的后续阶段需要使用的其他产物（比如数据库迁移或测试数据）。

## 提交阶段的原则和实践

​	如果说部署流水线的目标之一是消除无法在生产环境运行的构建的话，那么提交阶段就是“门卫”。提交阶段的目标是在那些有问题的构建引起麻烦之前，就把它们拒之门外。提交阶段的首要目标是要么创建可部署的产物，要么快速失败并将失败原因通知给团队。

### 提供快速有用的反馈

​	提交测试的失败通常是由以下三个原因引起的：（1）由于语法错误导致编译失败；（2）由于语义错误导致一个或多个测试失败；（3）由于应用程序的配置或环境方面（包括操作系统本身）的问题引起。

​	因此，为了得到高效的部署流水线，我们要尽早捕获错误。在大多数项目中，我们实际上在提交阶段之前就开始做这些事儿了。比如充分利用新式开发环境，只要开发环境中发现编译警告（如果适用）或语法错误，就尽快修复它们。很多时新的持续集成服务器也提供称为预测试提交或试飞构建的功能，即在提交之前就运行一下提交测试。如果没有这样的环境或设备，在提交之前必须在本地运行一下编译和提交测试。

​	提交阶段是第一个将质量视角从个体开发人员扩大到更多人的正式步骤。提交阶段的第一件事儿就是把提交者的修改与主线合并，然后对集成后的应用程序执行某种自动化的“验证”。既然“尽早识别错误”是我们的目标，那么就要做到“有问题就尽早失败”，所以提交阶段要捕获开发人员引入到应用程序中的大多数错误。

​	在采纳持续集成实践的早期，常见的错误是对“有问题就尽早使之失败”只按字面理解，即一旦发现错误，就让构建立即失败。这基本上是正确的，但优化过了头儿。我们一般会把提交阶段分成一系列的任务（具体包括哪些任务就因项目而异了），比如编译、运行单元测试等。只有在某个错误让提交阶段的其他任务无法执行时，我们才会让提交阶段停下来，比如编译错误，否则就直至提交阶段全部运行完后，才汇总所有的错误和失败报告，以便可以一次性地修复它们。

### 何时令提交阶段失败

​	传统上讲，当出现下列任一情况时，提交阶段就应该失败，即出现编译错误、测试失败，或者环境问题，否则就应该让提交阶段成功通过并报告一切OK。但是，假如测试通过是由于仅执行了一小部分测试呢？如果代码质量不高呢？如果编译成功，但有很多编译警告，我们也能满足吗？一个绿色（表示成功通过）的提交阶段很容易变成一个假象，即看上去应用程序的质量是不错的，但事实却不是这样的。

​	有人认为，在提交阶段结束时，应该提供更丰富的信息，比如关于代码覆盖率和其他度量项的一些图表。实际上，这些信息可以使用一系列阈值聚合成一个“交通灯信号”（红色、黄色、绿色），或者浮动的衡量标度。比如，当单元测试覆盖率低于60%就令提交阶段失败，但是如果它高于60%，低于80%的话，就令提交阶段成功通过，但显示成黄色。

​	但要记住的是，我们的纪律是如果提交阶段失败，交付团队就要立即停下手上的工作，把它修复。如果全团队尚未就某个原因[插图]达成一致意见，就不要让提交测试失败，否则大家会不拿失败当回事儿，而持续集成就渐渐会失去其应有的作用。我们强烈建议在提交阶段持续检查应用程序的质量，并在恰当的时候考虑加强代码质量的度量。

### 精心对待提交阶段

​	提交阶段中有构建用的脚本和运行单元测试、静态分析等的脚本。这些脚本需要小心维护，就像对待应用程序的其他部分一样。和其他所有软件系统一样如果构建脚本设计得很差，还没得到很好维护的话，那么保持它能够正常工作所需投入的精力会呈指数级增长。这相当于双重打击。一个较差的构建系统不但会把昂贵的开发资源从创造业务功能的工作中拖走，而且会令那些仍在创建业务功能的开发人员的工作效率降低。

​	随着项目的进行，要不断努力地改进提交阶段脚本的质量、设计和性能。一个高效、快速、可靠的提交阶段是提高团队生产效率的关键，所以只要花点儿时间和精力在这上面，让它处于良好的工作状态，就会很快收回这些投入成本。要想令提交阶段在较短时间内完成，并尽早捕获任何问题的话，就要有一些创造性，比如仔细地选择和设计测试用例。与应用程序的代码相比，若不太看重脚本，很快就会令脚本变得很难理解和维护。

### 让开发人员也拥有所有权	

​	在某些组织中会有一支专家团队，团队成员都精通创建有效且模块化的构建流水线，并且擅长管理这些脚本的运行环境。本书的两位作者都曾经担当过这样的角色。但是，如果真的只有那些专家才有权维护持续集成系统的话，那就是一种失败的管理方式。

​	交付团队对提交阶段（也包括流水线基础设施的其他部分）拥有所有权是至关重要的，这与交付团队的工作和生产效率是紧密联系在一起的。如果你设置了人为障碍，使开发人员不能快速有效地作出修改，就会减缓他们的工作进程，并在其前进的道路上埋下地雷。

​	如果必要的话，即使是很普通的变更（比如增加新的库文件和配置文件等）也都应该由一起工作的开发人员和运维人员来执行。这类活动不应该由构建专家完成，除非是在项目初期团队刚开始建立构建脚本时。

###  在超大项目团队中指定一个构建负责人	

​	但在大团队中，这并不总是一件容易的事。此时，让某个（或多个）人扮演构建负责人的角色是必要的。他们不但要监督和指导对构建的维护，而且还要鼓励和加强构建纪律。如果构建失败，构建负责人要知会当事人并礼貌地（如果时间太长的话，不礼貌也没问题）提醒他们为团队修复失败的构建，否则就将他们的修改回滚。

​	这个角色能起作用的另一种情况是，当团队刚开始接触持续集成时。在这样的团队中，构建纪律还没有建立起来，有个人能不断提醒大家，会令事情走向正轨。

​	构建负责人不应该是由固定的人担任。团队成员应该轮流担当，比如每星期轮换一次。这个纪律不错，能让每个人都学到一些经验。无论怎么说，想一直做这项工作的人还是不多的。

## 提交阶段的结果

**制品库**

​	提交阶段的输出（结果报告和二进制包）需要保存在某个地方，以便部署流水线的后续阶段能重用它们，并使团队也能使用它们。最容易想到的地方就是版本控制库，但它却不是一个正确的选择，因为这会让你的硬盘空间很快被吃掉，而且有些版本控制系统对二进制文件支持不佳。除此之外，还有几个理由。

* 制品库算是一个不同寻常的版本控制系统，它仅保存某些版本，而不是全部。如果候选发布版本在部署流水线的某个阶段失败了，就不再需要保留它了。如果有必要的话，我们完全可以将这类二进制包和报告从制品库中彻底删除。
* 还有一点也至关重要，那就是能够追溯已发布的软件究竟是由版本控制库中的哪个版本产生的。为了能够做到这一点，部署流水线的一个实例应该与版本控制库中触发它的那个版本相关联。作为部署流水线的一部分，我们已经把所有东西都提交到版本控制库了，而将更多修订版本与相应的流水线实践关联在一起会让这个流程更加复杂。
* 对于良好的配置管理策略，其标准之一就是二进制文件的创建过程应该是可重复的。也就是说，如果我不小心删除了二进制包，只要在同一个版本上再次触发提交阶段，就能再次得到一模一样的二进制包。在配置管理的范畴内，二进制包不那么重要，但我们会永久保存二进制包的散列，来验证重新生成的二进制包是否与生产环境上使用的一模一样。

**创建自己的制品库**

​	显示了一个制品库在典型安装中的使用方式。它是为每个候选发布版本保存二进制包、结果报告和元数据的关键资源。

![](https://pic.imgdb.cn/item/60d1d228844ef46bb250d804.jpg)

​	下面是一个候选发布版本在理想情况下在部署流水线中成功走向生产环境的每一步，其序号与图7-2中各阶段相对应。

1. 交付团队的某个人提交了一次修改。
2. 持续集成服务器运行提交阶段。
3. 成功结束后，二进制包和所有报告和元数据都被保存到制品库中。
4. 持续集成服务器从制品库中获取提交阶段生成的二进制包，并将其部署到一个类生产测试环境中。
5. 持续集成服务器使用提交阶段生成的二进制包执行验收测试。
6. 成功完成后，该候选发布版本被标记为“已成功通过验收测试”。
7. 测试人员拿到已通过验收测试的所有构建的列表，并通过单击一个按钮将其部署到手工测试环境中。
8. 测试人员拿到已通过验收测试的所有构建的列表，并通过单击一个按钮将其部署到手工测试环境中。
9. 测试人员执行手工测试。
10. 一旦手工测试也通过了，测试人员会更新这个候选发布版本的状态，指示它已经通过手工测试了。
11. 持续集成服务器从制品库中拿到通过验收测试（根据部署流水线的配置，也可能是手工测试）的最新候选发布版本，将其部署到生产测试环境。
12. 对这个候选发布版本进行容量测试。
13. 如果成功了，将这个候选版本的状态更新为“已通过容量测试”。
14. 如果部署流水线中还有后续阶段的话，一直重复这种模式。
15. 一旦这个候选发布版本通过了所有相关阶段，把它标记为“可以发布”，并且任何被授权的人都能将其发布，通常是由质量保证人员和运维人员共同批准。
16. 一旦发布以后，将其标记为“已发布”。

## 提交测试套件的原则与实践

​	对于提交测试套件的管理，有一些重要的原则和实践。提交测试中，绝大部分应由单元测试组成，这也是本节中我们主要讲的内容。单元测试最重要的特点就是运行速度非常快。有时候，我们会因为测试套件运行不够快而令构建失败。第二个重要的特点是它们应覆盖代码库的大部分（经验表明一般为80%左右），让你有较大的信心，能够确定一旦它通过后，应用程序就能正常工作。

​	Mike Cohn找到了一种很好的可视化方法指出自动化测试套件应该如何组织。在他的自动化测试金字塔（图7-3）中，单元测试占了自动化测试中相当大的比例。但由于它们执行得非常快，所以单元测试套件应该能在几分钟内就结束。即便验收测试比较少（可进一步分成服务和用户界面测试），它们也会花较长时间，因为这些测试需要启动应用程序。所有层次的测试对于确保应用程序可以工作并交付预期的业务价值都是至关重要的。这个测试自动化金字塔覆盖了4.2节中的那个测试象限图的左半边（支持开发过程的）。

![](https://pic.imgdb.cn/item/60d1d90c844ef46bb2795e17.jpg)

​	设计能快速运行的提交测试并不总是那么简单的事情。下面我们会介绍几种策略，其中大部分都是为了达到一个共同的目标：将指定测试的范围最小化，并让它尽可能聚焦于系统的某个方面。尤其要注意的一点是，运行的单元测试不应该与文件系统、数据库、库文件、框架或外部系统等打交道。所有对这些方面的调用都应该用测试替身代替，比如模拟对象（mock）和桩等。

### 避免用户界面

​	根据定义，用户界面是用户最容易找到缺陷的地方。这让大家自然而然地想到，要把测试焦点放在用户界面上，这有时还会吃掉其他测试的成本。

​	然而，对于提交测试来说，我们建议根本不要通过用户界面进行测试。用户界面测试的困难来自两方面。首先，它会涉及很多组件或软件的多个层次。这样是容易出问题的，因为要花很多时间和精力去准备各种各样的组件或数据，才能让测试运行起来。其次，用户界面是提供给用户手工操作的，而手工操作的速度与计算机操作的运行速度相比，是相当慢的。

### 使用依赖注入

​	依赖注入（或控制反转）是一种设计模式，用于描述如何从对象外部建立对象间的关系。显然，只有在使用面向对象语言时才能用上它。

​	这种技术不但是构建灵活的模块化软件的很好的方法，而且它还能让测试变得很容易，只需要测试必要的类，那些依赖包就不再是包袱了。

### 避免使用数据库

​	刚接触自动化测试的人常常写出一些需要与代码中的某一层进行交互的测试，并将结果写入数据库，然后再验证该结果的确被写到了数据库中。尽管这种方法简单，容易理解，但从其他方面来说，它不是一个很有效的方法。

​	首先，这种测试运行得非常慢。当想重复测试，或者连续运行几次相似的测试时，这种有状态的测试就是个障碍。其次，基础设施准备工作的复杂性令这种测试方法的建立和管理更加复杂。最后，如果从测试中很难消除数据库依赖的话，这也暗示着，你的代码在通过分层进行复杂性隔离方面做得不好。这也使得可测试性和CI在团队身上施加了一种微妙的压力，迫使其开发出更好的代码。

​	提交测试套件的这些单元测试根本不应该依赖于数据库。为了达到这一点，你就要把被测试的代码与其存储分离开来。这就要求对代码实现良好的分层，也需要使用像依赖注入这样的技术。实在做不到的话，也至少要使用内存数据库。

​	然而，在提交测试中，也应该有一两个非常简单的冒烟测试。这些测试应该是端到端的测试，并选自那些高价值的、常用功能的验收测试套件，用来证明应用程序可以真正运行起来。

### 在单元测试中避免异步

​	在单个测试用例中的异步行为会令系统很难测试。最简单的办法就是通过测试的切分来避免异步，这样就能做到：一个测试运行到异步点时，切分出来的另一个测试再开始执行。

​	比如，当系统需要发出一条消息，再根据这个消息作出反应，那么可以自己实现一个接口封装原生的消息发送机制。然后你可以利用一个简单的实现了消息接口的桩或者下一节讲的模拟技术，先在一个测试用例中验证这种调用与你所期望的相同。然后，再增加第二个测试，只要通过消息接口调用一下原来的那个调用点，验证一下消息处理程序（message handler）的行为就可以了。当然这也依赖于你的架构，有时候可能需要很多工作才能做到这一点。

### 使用测试替身

​	理想的单元测试集中在很小且紧密相关的代码组件上，典型的就是单个类或一小组极其相关的类。

​	打桩是指利用模拟代码来代替原系统中的某个部分，并提供已封装好的响应。桩并不对外界作出响应。这是个极其有用且灵活的方法，可以用在任何软件层次上，从模拟被测试代码依赖的一个非常简单的类，到模拟一个完整的系统。

**使用桩代替消息系统**

​	模拟技术恰好做到了这一点。现在有几种模拟技术工具集，比如Mockito、Rhino、EasyMock、JMock、NMock和Mocha等。使用模拟技术，你就可以说：“给我构建一个对象，让它假装就是某某类型的一个类。”

### 最少化测试中的状态

​	理想情况下，单元测试应聚焦于断言系统的行为。然而，特别对于那些刚接触有效测试设计的新手来说，常见的问题是测试中状态的不断增加。实际上问题包括两个方面。首先，很容易想到的是，测试就是为系统中的某个组件提供一些输入信息，然后得到一定的返回结果。所以在写测试时，你就会组织一下相关的数据结构，以便以正确的形式提交输入信息，然后再把结果与你期望的进行比较。事实上，所有的测试或多或少都是这种形式。问题是，如果处理不当的话，这个系统及其相关的测试会变得越来越复杂。

​	这样就很容易落入一个陷阱，即为了支撑测试，精心地建立起一堆难以理解和维护的数据结构。理想的测试应该能很容易和快速地进行测试准备，而清理工作也应该更快、更容易。对于结构良好的代码来说，其测试代码往往也非常整洁有序。如果测试看起来繁琐复杂，那可能是系统设计有问题。

​	然而，这是个很难定性的问题。我们的建议是设法让测试中的这种对状态的依赖最小化。你可能无法从根本上消除它，但为了运行测试，持续关注“如何降低要构造的测试环境的复杂性”是合理的。如果测试变得越来越复杂，很可能是由于代码结构问题引起的。

### 时间的伪装

​	时间问题是自动化测试需要面对的问题，原因有以下几个。你的系统可能需要在每天晚上八点触发一个处理过程，也可能在启动下一步前要等上500毫秒，也可能要在每个闰年的二月二十九号做一些特殊的处理。

​	如果你将这些时间和真正的系统时间绑定的话，这些情况处理起来可能会有点儿棘手，且对单元测试策略说，很有可能是灾难性的。

​	对于所有基于时间的系统行为，我们的做法是将对时间的请求抽象到一个你能够控制的类中。通常，我们使用依赖注入把用到的系统时间行为注入到包装类中（wrapper）。

​	通过这种方法，我们就可以为Clock这个类的行为进行打桩或模拟，或做一些我们认为合理的抽象。在我们的测试中，如果我们能设定当前是闰年，或要延时500毫秒的话，那么它就完全在我们的控制之下了。

### 蛮力

​	开发人员总是为最快的提交周期争论不休。然而，事实上，这要与在提交阶段识别最常见错误的能力平衡考虑。这是个只能通过不断试错才能找到的优化过程。有时候，运行速度稍慢一点儿的提交测试可能优于通过优化测试或减少发现的缺陷数来追求运行速度的提交测试。

​	通常我们会让提交测试在十分钟内完成。这基本上是我们能够承受的上限。这个时间比我们期望的理想时间（少于五分钟）还要长一些。大型项目中的开发人员可能无法接受“十分钟以内”这个限制，认为他们就目前的情况来说无法达到这一标准。其他开发团队可能会把这看做是一种太离谱的妥协，认为最高效的提交测试要比十分钟短得多。根据对很多项目上的观察，我们建议把这个数字作为指导。当这一限制被打破时，开发人员会开始做两件事，而这两件事对于开发流程来说都是极其糟糕的：（1）提交频率变低；（2）如果提交阶段的用时远远超过十分钟，他们可能就不再关注提交阶段通过与否了。

​	有两招儿能加快测试套件的运行。首先，将它分成多个套件，在多台机器上并行执行这些套件。时新的持续集成服务器都有“构建网格”功能，直接支持这种做法。记住，计算能力是廉价的，而人力是昂贵的。及时得到反馈比准备几台服务器的成本要有价值得多。第二招儿就是，作为构建优化过程的一部分，将那些运行时间比较长且不经常失败的测试放到验收测试阶段运行。然而，需要注意的是，这会导致需要更长的时间才能知道这些测试是否失败了。

## 小结

略







# 《Jenkins 2.x实践指南》

​	https://jenkins.io

# 关于软件工程生产力

## 从另一个角度看"提高软件工程生产力"

​	如果将软件工程看成软件的生产过程，软件工程师是这个生产过程中的一种劳动者，知识是这个生产过程中的劳动对象，我们就会发现，这就是马克思的生产力理论三要素。

​	生产力三要素是劳动力、劳动资料、劳动对象，其中劳动资料和劳动对象构成生产资料。

​	生产力三要素分别指的是什么呢？

**劳动力**：一般意义，指工作人群，通常指在一家公司、各个产业乃至某个社会工作的人，多指体力劳动者，但通常不包括雇佣者（老板）和管理层。

**劳动资料**：也称劳动手段，是在劳动过程中所运用的物质资料或物质条件。

**劳动对象**：是指劳动本身所作用的客体，比如耕作的土地、纺织的棉花等。

​	在软件工程领域，生产力三要素又分别指的是什么呢？

**劳动力**：通常将软件开发工程师、测试工程师认为是劳动力。然而，当他们不在工作状态时，就不能称其为劳动力，只能称为劳动者

**劳动资料**：严格意义来说，办公场所、座椅、生产工具等都被称为劳动资料。本书主要讨论的是生产工具。笔者从硬件、软件的角度对生产工具进行了分类。****

* 硬件：开发时使用的电脑、机械键盘、灵敏的鼠标、网络速度等。
* 软件：IDE（如Eclipse、IntelliJ IDEA）、构建工具（如Webpack、Maven）、协作工具（如Jira）、部署工具（如Ansible、Puppet）等。

**劳动对象**：不像制造汽车，在开发软件时，劳动对象则是看不见、摸不着的知识。笔者将软件工程中的知识分为业务知识和技术知识。

### 从劳动力要素考虑提高软件工程生产力

​	如果能招到比一般程序员生产力高10倍的程序员，并好好利用，就可以提高生产力。如果这个程序员的生产力比一般程序员高10倍，那么通常意味着其工资也高10倍。

​	另外，不论招到什么样的程序员，管理者都要关心的是，如何帮助劳动者达到最佳工作状态，以产出更多的劳动力。不在工作状态，就不能称之为劳动力，只能称为劳动者。也许，那些经常随意打断程序员的管理者需要反思一下了。

### 从劳动对象要素考虑提高软件工程生产力

​	如果将软件生产过程看成是无形的知识具化成有形软件的过程，那么产品经理需要将想法（一种知识）具化成原型，美工和交互设计师理解产品经理的想法后，将自己的想法具化成设计稿，然后再将自己的理解及想法（又是一种知识）传达给前端开发人员。接着，前端开发人员和后端开发人员又沟通接口的设计（还是一种知识）……可以看出，要提高软件工程生产力，知识的流通效率起着很关键的作用。所谓知识的流通效率，指的是让知识从一个人的大脑流动到另一个（群）人的大脑的准确性和速度。

​	所以说，沟通能力在软件工程领域十分重要。

### 从生产工具要素考虑提高软件工程生产力

​	程序员笑话一则：程序员在椅子上打斗，经理叫他们回去，其中一位说：正在编译呢！

​	经理回答：哦，那你们继续。

​	我们算算账。假如一个20 000元/月工资的程序员，工作22天，每天8小时，那么每小时就是113.6元。假如程序员每天因为打开程序慢、网络慢、编译慢等而等待的时间总和为0.5小时，那么这0.5小时就属于浪费的，总共约57元。这意味着一个月会浪费1254元。

### 生产力三要素的意义

​	从生产力三要素的角度看，你要问平均编译时间是多久、为什么这么久，进而从三个要素发问：

* 生产工具：是电脑太慢了？是编译工具本身太慢了？
* 劳动力（程序员的能力）：是构建逻辑写得不合理？是编译过程中的某个阶段的问题影响了整体编译速度？
* 劳动对象：是不是缺少对当前构建工具（技术知识）的了解？

## Jenkins介绍

​	Jenkins是一款使用Java语言开发的开源的自动化服务器。我们通过界面或Jenkinsfile告诉它执行什么任务，何时执行。理论上，我们可以让它执行任何任务，但是通常只应用于持续集成和持续交付。

​	从生产力三要素来看，Jenkins属于劳动资料要素下的生产工具。

​	使用Jenkins能提升软件工程生产力的根本原因就在于它提供的是一个自动化平台。一个团队引入了Jenkins就像原来手工作坊式的工厂引入了生产流水线。由于知识的特殊性，它还能帮助我们将知识固化到自动化流水线中，在一定程度上解决了知识被人带走的问题。

​	我们使用Jenkins的过程，有如设计软件生产流水线的过程。

## Jenkins与DevOps

​	在行业内，DevOps的标杆Amazon WebServices（AWS）这样定义DevOps（https：//aws.amazon.com/cn/devops/what-is-devops/）：

​	DevOps集文化理念、实践和工具于一身，可以提高组织高速交付应用程序和服务的能力，与使用传统软件开发和基础设施管理流程相比，能够帮助组织更快地发展和改进产品。这种速度使组织能够更好地服务于客户，并在市场上更高效地参与竞争。

​	是不是可以理解为能帮助组织更快地发展和改进产品，可以提高组织高速交付应用程序和服务能力的都可以称自己为DevOps？

​	AWS给出的定义似乎没有可操作性。而维基百科（https：//zh.wikipedia.org/wiki/DevOps）给出的定义，可操作性或许多一些：

​	DevOps（Development和Operations的组合）是一种重视软件开发人员（Dev）和IT运维技术人员（Ops）之间沟通合作的文化、运动或惯例。通过自动化软件交付和架构变更的流程，使得构建、测试、发布软件能够更加快捷、频繁和可靠。

# Jenkins安装

https://www.jenkins.io/doc/book/installing/war-file/

```sh
wget https://get.jenkins.io/war-stable/2.289.1/jenkins.war --no-check-certificate
java -jar jenkins.war --httpPort=9090
```

https://www.cnblogs.com/ajianboke/p/10945522.html

**插件报错**

https://aflyun.blog.csdn.net/article/details/103338558

**SSL过不了**

​	调整时区，系统重新校验实践

**update site**

http://mirror.xmission.com/jenkins/updates/update-center.json

# pipeline入门

## pipline是什么

​	从某种抽象层次上讲，部署流水线（Deploymentpipeline）是指从软件版本控制库到用户手中这一过程的自动化表现形式。——《持续交付——发布可靠软件的系统方法》[1]（下称《持续交付》）

​	Jenkins 1.x只能通过界面手动操作来“描述”部署流水线。Jenkins 2.x终于支持pipeline as code了，可以通过“代码”来描述部署流水线。

* 更好地版本化：将pipeline提交到软件版本库中进行版本控制。
* 更好地协作：pipeline的每次修改对所有人都是可见的。除此之外，还可以对pipeline进行代码审查。
* 更好的重用性：手动操作没法重用，但是代码可以重用。



​	本书全面拥抱pipeline as code，放弃依赖手动操作的自由风格的项目（FreeStyle project）。

## Jenkinsfile又是什么

​	Jenkinsfile就是一个文本文件，也就是部署流水线概念在Jenkins中的表现形式。像Dockerfile之于Docker。所有部署流水线的逻辑都写在Jenkinsfile中。

​	Jenkins默认是不支持Jenkinsfile的。我们需要安装pipeline插件，本书使用的插件版本为2.27，其安装方式和普通插件的安装方式无异。安装完成后，就可以创建pipeline项目了，如图2-1所示。

![](https://pic.imgdb.cn/item/60d1fa2b844ef46bb29c6f2c.jpg)

## pipeline语法的选择

​	Jenkins团队在一开始实现Jenkins pipeline时，Groovy语言被选择作为基础来实现pipeline。所以，在写脚本式pipeline时，很像是（其实就是）在写Groovy代码。这样的确为用户提供了巨大的灵活性和可扩展性，我们还可以在脚本式pipeline中写try-catch。示例如下：

![](https://pic.imgdb.cn/item/60d3229a844ef46bb2cac661.jpg)

​	以上写法被称为脚本式（Scripted）语法。Jenkins pipeline还支持另一种语法：声明式（Declar-ative）语法。pipeline插件从2.5版本开始，才同时支持两种格式的语法。

​	脚本式语法的确灵活、可扩展，但是也意味着更复杂。再者，Groovy语言的学习成本对于（不使用Groovy的）开发团队来说通常是不必要的。所以才有了声明式语法，一种提供更简单、更结构化（more opinionated）的语法。示例如下：

​	![](https://pic.imgdb.cn/item/60d32528844ef46bb2d9e2ce.jpg)

​	本书所有的示例都将使用声明式语法。因为声明式语法更符合人类的阅读习惯、更简单。声明式语法也是Jenkins社区推荐的语法。

## 创建第一个pipeline

​	首先在Jenkins中新建一个pipeline项目，如图2-2所示。

![](https://pic.imgdb.cn/item/60d3265a844ef46bb2e0e63c.jpg)

​	在pipeline-hello-world项目的设置页面中，在Pipeline节点下填入pipeline的内容，如图2-3所示。

```
pipeline {
    agent any
    stages {
        stage("build") {
            steps {
                echo "Hello World"
            }
        }
    }
}
```



![](https://pic.imgdb.cn/item/60d328c5844ef46bb2f00ac2.jpg)

执行后，结果如图2-4所示。

![](https://pic.imgdb.cn/item/60d32968844ef46bb2f43336.jpg)

​	和大多数Hello world示例一样，以上示例只是为了让大家对pipeline有一个感性的认识。

## 从版本控制库拉取pipeline

https://www.cnblogs.com/dotnet261010/p/12393917.html

​	在Hello world示例中，我们是直接在Jenkins界面上填入pipeline内容的。在试验时可以这么做，但是不推荐，因为这样无法做到pipeline的版本化。

​	首先需要安装Git插件，然后使用SSH的clone方式拉取代码。所以，需要将Git私钥放到Jenkins上，这样Jenkins才有权限从Git仓库拉取代码。

​	将Git私钥放到Jenkins上的方法是：进入Jenkins→Credentials→System→Globalcredentials页，然后选择Kind为“SSHUsername with private key”，接下来按照提示设置就好了，如图2-5所示。关于Credential的更多内容，我们会在第9章中进行详细介绍。目前只需要理解：Jenkins从Git仓库拉取代码时，需要SSH key就可以了，然后Jenkins本身提供了这种方式让我们设置。

![](https://pic.imgdb.cn/item/60d33852844ef46bb263d4da.jpg)

​	另外，需要注意的是，我们需要提前将SSH的公钥放到Git仓库中。关于这方面内容网络上有很多教程，本书不再赘述。现在，我们来看看项目结构，只有一个Jenkinsfile文件。

​	在Hello world示例中，在Pipeline节点下，在“Definition”中选择“Pipelinescript from SCM”，并在“SCM”中选择“Git”，然后根据选项填入信息内容就可以了，如图2-6所示。

​		现在，我们来看看项目结构，只有一个Jenkinsfile文件。

​		Jenkinsfile文件中的内容就是Hello world示例的内容。接下来，我们将项目推送到GitLab。

![](https://pic.imgdb.cn/item/60d33aad844ef46bb27599b5.jpg)

这里有两点需要注意：

* 在“Credentials”中选择我们刚刚创建的用于拉取代码的凭证。
* “Script Path”就是pipeline的文件名，默认是Jenkinsfile。保存并创建成功后，执行，在日志中除了Hello world被打印出来，git clone过程的日志也被打印出来。

![](https://pic.imgdb.cn/item/60d33d43844ef46bb28a16b0.jpg)

​	Maven是非常流行的一个Java应用构建工具。下面我们再来看一个使用Maven构建Java应用的例子。Jenkins默认支持Maven。首先在本地创建一个Maven项目，目录结构如下：

![](https://pic.imgdb.cn/item/60d341f7844ef46bb2b4d719.jpg)

​	接下来，需要在Jenkins上安装JDK和Maven。我们可以登录Jenkins服务器手动安装，也可以让Jenkins自动安装。这里选择后者。方法如下：

​	（1）进入Manage Jenkins→Global Tool Configuration→Maven页，设置如图2-7所示。

​		图略

​	留意Name输入框中的值，这里填的是mvn-3.5.4。在后面的pipeline中会使用到。

（2）进入Manage Jenkins→Global Tool Configuration→JDK页，设置如图2-8所示。

​	略

Jenkinsfile内容如下：

```
pipeline {
    agent any
    tools {
        maven 'mvn-3.5.4'
    }
    stages {
        stage("build") {
            steps {
                sh "mvn clean package spring-boot:repackage"
                sh "printenv" // 将环境变量打印
            }
        }
    }
}
```

​	当Jenkins执行到tools时，就会根据Maven的设置自动下载指定版本的Maven，并安装。tools是pipeline中的一个指令，用于自动安装工具，同时将其路径放到PATH变量中。通过命令sh"printenv"，可以看到tools将MAVEN_HOME放到了当前任务的环境变量中。

​	关于tools的更多信息，我们会在第4章中进行详细介绍。单击构建后，通过Jenkins执行日志，我们看到指定版本的Maven被下载和安装，mvn执行打包。

​	![](https://pic.imgdb.cn/item/60d3439b844ef46bb2c5559d.jpg)

## 本章小结

​	由于历史原因，Jenkins pipeline支持两种语法。node为根节点的是脚本式语法，而pipeline为根节点的是声明式语法。本书使用的是Jenkins社区推荐的声明式语法。

